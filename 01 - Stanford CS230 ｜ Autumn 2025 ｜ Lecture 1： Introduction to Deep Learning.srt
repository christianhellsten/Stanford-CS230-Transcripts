1
00:00:05,200 --> 00:00:08,000
What I want to do today is, um,

2
00:00:08,000 --> 00:00:10,400
give an overview of this class.

3
00:00:10,400 --> 00:00:13,199
Uh, I'm- I'm actually curious before we get started.

4
00:00:13,199 --> 00:00:17,679
Um, this is now September 2025.

5
00:00:17,679 --> 00:00:19,800
Um, how many of you, you know,

6
00:00:19,800 --> 00:00:21,600
just started at Stanford?

7
00:00:21,600 --> 00:00:24,039
Raise your hand. Wow, cool, awesome.

8
00:00:24,039 --> 00:00:27,879
So others, pay attention to who just raised their hands and do,

9
00:00:27,879 --> 00:00:29,640
say hi to them and, you know,

10
00:00:29,640 --> 00:00:33,640
welcome all of the people that just joined Stanford and whatever program.

11
00:00:33,920 --> 00:00:40,520
Um, CS 230 is a class that we offer in the flipped classroom format.

12
00:00:40,520 --> 00:00:45,079
And what that means is that instead of listening to me or Kian,

13
00:00:45,079 --> 00:00:48,280
uh, my co-instructor that you meet- that you meet next week,

14
00:00:48,280 --> 00:00:51,320
instead of listening to us lecture at you for an hour,

15
00:00:51,320 --> 00:00:53,560
hour 20 minutes or whatever, um,

16
00:00:53,560 --> 00:00:58,439
we actually ask you to watch a lot of the video lectures online so that we

17
00:00:58,439 --> 00:01:02,679
can then make use of the precious in-classroom time for much richer,

18
00:01:02,679 --> 00:01:04,359
deeper discussions.

19
00:01:04,359 --> 00:01:08,040
So both today and for the entire quarter, um,

20
00:01:08,040 --> 00:01:12,840
I would really warmly welcome anyone raising questions, uh, raise your hand.

21
00:01:12,840 --> 00:01:15,560
And in fact, I- I- I find that, um,

22
00:01:15,560 --> 00:01:17,159
instead of you sitting there- oh,

23
00:01:17,159 --> 00:01:20,760
and even though we have a longer session scheduled by the registrar,

24
00:01:20,760 --> 00:01:25,719
uh, we'll use usually only up to an hour and 20 minutes for this course.

25
00:01:25,719 --> 00:01:30,599
Um, and the goal is to- it- it turns out that a lot of Stanford students

26
00:01:30,599 --> 00:01:33,000
were watching, you know, the lectures, um,

27
00:01:33,000 --> 00:01:36,599
on, uh, Seagull or on the online videos anyway.

28
00:01:36,599 --> 00:01:41,159
So rather than us delivering that lecture, same lecture, year after year,

29
00:01:41,159 --> 00:01:46,319
we put a lot more effort to put very high-quality lecture videos online,

30
00:01:46,319 --> 00:01:48,159
and we'll ask you to just watch that online,

31
00:01:48,159 --> 00:01:49,359
which people are doing anyway,

32
00:01:49,359 --> 00:01:52,280
but just highly edited for offline watching, um,

33
00:01:52,280 --> 00:01:54,400
spend- and spend the classroom time, you know,

34
00:01:54,400 --> 00:01:58,400
doing the things that make sense for us to get together in person too.

35
00:01:58,439 --> 00:02:02,319
Um, so because you haven't watched any of the lectures yet,

36
00:02:02,319 --> 00:02:03,640
or I assume most of you have not,

37
00:02:03,640 --> 00:02:08,000
today we'll even maybe have a slightly shorter session to introduce the class,

38
00:02:08,000 --> 00:02:09,919
talk over logistics, and so on.

39
00:02:09,919 --> 00:02:13,520
Right? Um, as many of you know,

40
00:02:13,520 --> 00:02:16,120
deep learning is one of the latest,

41
00:02:16,120 --> 00:02:20,240
hottest trends technologies of computer science and AI.

42
00:02:20,240 --> 00:02:22,639
Um, if we look at, you know,

43
00:02:22,639 --> 00:02:26,159
say our PhD admissions or- or even NASA's admissions,

44
00:02:26,159 --> 00:02:29,719
there's a very large fraction of all students that come to Stanford

45
00:02:29,719 --> 00:02:32,319
or applying to come to Stanford want to work on AI.

46
00:02:32,319 --> 00:02:33,960
Right? I'm not sure I'm allowed to say the numbers,

47
00:02:33,960 --> 00:02:38,360
but they are, you know, extremely high, um, as you can imagine.

48
00:02:38,360 --> 00:02:42,120
And so, uh, my goal and my- my co-instructor,

49
00:02:42,120 --> 00:02:43,800
Kian's goals, our collective goal,

50
00:02:43,800 --> 00:02:50,400
is through this quarter to help you get to near or at pretty much state of the art

51
00:02:50,400 --> 00:02:52,919
with regard to deep learning, um,

52
00:02:52,919 --> 00:02:55,680
and make sure that all of you walk away from this class,

53
00:02:55,680 --> 00:02:59,080
highly skilled at applying deep learning.

54
00:02:59,080 --> 00:03:06,599
Um, and so it turns out that a lot of progress in AI over the last,

55
00:03:06,599 --> 00:03:08,360
I don't know, decade,

56
00:03:08,360 --> 00:03:12,199
maybe 10-15 years was made by scaling.

57
00:03:12,199 --> 00:03:15,080
And one of the reasons why deep learning was so successful

58
00:03:15,080 --> 00:03:18,199
was because it's good at absorbing a lot of data.

59
00:03:18,199 --> 00:03:21,560
So, you know,

60
00:03:21,560 --> 00:03:25,599
if I draw a figure where on the x-axis,

61
00:03:25,599 --> 00:03:31,680
I plot the amount of data we have for a problem,

62
00:03:31,680 --> 00:03:35,479
um, then using more traditional machine learning algorithms,

63
00:03:35,479 --> 00:03:38,000
so, you know, logistic regression, maybe decision trees,

64
00:03:38,000 --> 00:03:42,000
using all the generations of AI machine learning algorithms,

65
00:03:42,000 --> 00:03:48,229
um, as you gave it more and more data,

66
00:03:48,229 --> 00:03:52,710
the performance or the accuracy of the more traditional algorithms with plateau, right?

67
00:03:52,710 --> 00:03:55,270
It was as if- so take speech recognition.

68
00:03:55,270 --> 00:03:57,389
With all the generations of algorithms,

69
00:03:57,389 --> 00:03:59,629
even as you fed it more and more data,

70
00:03:59,629 --> 00:04:03,550
hundreds and thousands and tens of thousands of hours of speech data,

71
00:04:03,550 --> 00:04:06,710
the accuracy would often plateau,

72
00:04:06,710 --> 00:04:09,349
and it was as if the older generations of algorithms

73
00:04:09,349 --> 00:04:13,349
didn't know what to do with all the data that we now have.

74
00:04:13,349 --> 00:04:17,550
But what we start to find about 10-15 years ago,

75
00:04:17,550 --> 00:04:23,620
um, was that if you train a small neural network,

76
00:04:23,620 --> 00:04:26,180
also known as a small deep learning model,

77
00:04:26,180 --> 00:04:29,740
this performance would kind of maybe get better and better.

78
00:04:29,740 --> 00:04:32,379
And if you train a medium-sized one,

79
00:04:32,379 --> 00:04:36,180
and if you train a very large neural network,

80
00:04:36,180 --> 00:04:39,660
the performance just keeps getting better and better.

81
00:04:39,660 --> 00:04:42,500
And I think the reason that deep learning has

82
00:04:42,500 --> 00:04:47,660
dominated the AIC for the last 10-15 years is because there is

83
00:04:47,660 --> 00:04:50,860
a recipe for training very large neural networks,

84
00:04:50,860 --> 00:04:53,019
um, that we could then shove a lot of data

85
00:04:53,019 --> 00:04:56,660
into that results in exceptional performance.

86
00:04:56,660 --> 00:04:58,459
So I think, um,

87
00:04:58,459 --> 00:05:01,100
we started to see this because of some,

88
00:05:01,100 --> 00:05:03,579
frankly, some Stanford research papers, um,

89
00:05:03,579 --> 00:05:05,899
about 15 years ago when- when, you know,

90
00:05:05,899 --> 00:05:08,100
did the first early work on using

91
00:05:08,100 --> 00:05:11,220
cruder programming and GPUs to scale up deep learning.

92
00:05:11,220 --> 00:05:13,420
Oh, by the way, actually, it's one fun fact.

93
00:05:13,420 --> 00:05:16,939
Um, uh, the first- my first, uh,

94
00:05:16,939 --> 00:05:21,100
GPU machine used to train neural networks using cruder,

95
00:05:21,100 --> 00:05:22,939
which is a controversial thing at the time,

96
00:05:22,939 --> 00:05:25,819
it was built by a Stanford undergrad in his dorm room, right?

97
00:05:25,819 --> 00:05:27,180
His name was Ian Goodfellow.

98
00:05:27,180 --> 00:05:29,620
But, um, I think that compute server

99
00:05:29,620 --> 00:05:31,819
built in the Stanford undergrad dorm room,

100
00:05:31,819 --> 00:05:34,540
um, allowed us at Stanford to lay

101
00:05:34,540 --> 00:05:38,420
the early foundations of using cruder at that time,

102
00:05:38,420 --> 00:05:42,100
a modern language for training GPUs to train large neural networks.

103
00:05:42,100 --> 00:05:43,579
And then, you know, obviously,

104
00:05:43,579 --> 00:05:47,259
that influenced a lot of people and helped scaling up deep learning to take off.

105
00:05:47,259 --> 00:05:49,660
So I- I- I tell that story because, um,

106
00:05:49,660 --> 00:05:52,379
sometimes the work that some of you can do,

107
00:05:52,379 --> 00:05:55,500
you know, in a dorm room or graduate student housing or whatever,

108
00:05:55,500 --> 00:05:58,139
or in a lab at Stanford, um, uh,

109
00:05:58,139 --> 00:06:00,540
looking back over some number of years,

110
00:06:00,540 --> 00:06:02,180
it- it can really have a huge impact.

111
00:06:02,180 --> 00:06:04,379
And maybe in this class, some of you will do

112
00:06:04,379 --> 00:06:08,579
work, um, as impactful as that someday as well.

113
00:06:08,579 --> 00:06:11,939
But so what you start to find was that,

114
00:06:11,939 --> 00:06:14,540
as you train larger and larger neural networks,

115
00:06:14,540 --> 00:06:18,459
they could soak up lots of data and drive exceptional performance.

116
00:06:18,459 --> 00:06:21,660
Um, and then there was a research paper out of Baidu,

117
00:06:21,699 --> 00:06:24,660
which showed that as you scale up neural networks,

118
00:06:24,660 --> 00:06:26,459
as you scale up deep learning algorithms,

119
00:06:26,459 --> 00:06:28,939
the performance gains are actually quite predictable.

120
00:06:28,939 --> 00:06:31,899
So you can forecast, if you buy this many GPUs,

121
00:06:31,899 --> 00:06:33,980
so this would compute and this much data added,

122
00:06:33,980 --> 00:06:35,779
what would the performance be?

123
00:06:35,779 --> 00:06:37,060
Um, and then later,

124
00:06:37,060 --> 00:06:42,620
OpenAI popularized the idea with a really influential paper on scaling laws,

125
00:06:42,620 --> 00:06:47,459
um, and that predictability of how deep learning gets better in performance

126
00:06:47,459 --> 00:06:50,699
then drove a lot of the investments, uh, in, you know,

127
00:06:50,699 --> 00:06:54,500
data centers and- and building very large AI models with lots of data.

128
00:06:54,500 --> 00:06:59,300
Um, and so, let's see.

129
00:06:59,300 --> 00:07:02,060
In terms of where this class sits,

130
00:07:02,060 --> 00:07:03,860
so in computer science,

131
00:07:03,860 --> 00:07:06,540
all of us build on each other's work, right?

132
00:07:06,540 --> 00:07:07,860
A lot of the way that, uh,

133
00:07:07,860 --> 00:07:12,180
computer science and AI has made progress is we build on top of other ideas

134
00:07:12,180 --> 00:07:14,019
that are in turn built on top of other ideas,

135
00:07:14,019 --> 00:07:16,699
they're in turn- they're in turn built on top of other ideas.

136
00:07:16,699 --> 00:07:20,540
So maybe I wanna give you a little map to- to- to show you,

137
00:07:20,540 --> 00:07:22,379
maybe where deep learning sits.

138
00:07:22,379 --> 00:07:29,779
Um, so I think there are,

139
00:07:29,779 --> 00:07:32,660
you know, machine learning is built on top of computer science,

140
00:07:32,660 --> 00:07:35,660
so I think it's actually helpful to learn CS fundamentals.

141
00:07:35,660 --> 00:07:40,579
Uh, and even though I use and I suspect vast majority of use AI-assisted coding,

142
00:07:40,579 --> 00:07:46,540
be it tools like Cloud Code or Gemini CLI or OpenAI Codecs or Cursor or Winserv or whatever,

143
00:07:46,540 --> 00:07:49,819
um, I find that people that know CS fundamentals,

144
00:07:49,819 --> 00:07:51,579
they really understand computer science, uh,

145
00:07:51,579 --> 00:07:54,180
they really understand how computers work rather than like,

146
00:07:54,180 --> 00:07:55,660
I'm gonna vibe code this, you know,

147
00:07:55,660 --> 00:07:57,220
like when you understand CS fundamentals,

148
00:07:57,220 --> 00:07:59,259
you get things to work much better.

149
00:07:59,259 --> 00:08:02,019
But on top of CS fundamentals,

150
00:08:02,019 --> 00:08:06,899
there's a set of, um, machine learning skills.

151
00:08:06,899 --> 00:08:14,389
So how do you build algorithms that can learn from data?

152
00:08:14,389 --> 00:08:20,269
Um, and then deep learning is a special type of machine learning.

153
00:08:20,269 --> 00:08:22,750
Well, that's really the most effective type of machine learning,

154
00:08:22,750 --> 00:08:26,149
as you can tell, in which we train new networks,

155
00:08:26,149 --> 00:08:30,230
we train certain types of algorithms to learn from large amounts of data.

156
00:08:30,230 --> 00:08:32,269
Uh, so far in the last 10 minutes,

157
00:08:32,269 --> 00:08:35,990
you've probably heard me use the words deep learning and neural networks,

158
00:08:35,990 --> 00:08:40,309
and I think today those two terms are almost interchangeable.

159
00:08:40,309 --> 00:08:43,269
Uh, some, some purists will insist on some technical differences.

160
00:08:43,269 --> 00:08:45,070
For all practical purposes, they mean the same thing.

161
00:08:45,070 --> 00:08:50,070
But what happened was the term neural networks happened around for decades.

162
00:08:50,070 --> 00:08:52,389
But around 10, 15 years ago,

163
00:08:52,389 --> 00:08:55,470
a number of us realized that, you know,

164
00:08:55,669 --> 00:08:58,789
deep learning, it was just a much better brand.

165
00:08:58,789 --> 00:09:03,029
Um, and so even though neural networks have been around for decades,

166
00:09:03,029 --> 00:09:05,110
starting about 10, 15 years ago,

167
00:09:05,110 --> 00:09:07,389
it was deep learning that took off,

168
00:09:07,389 --> 00:09:11,990
because who doesn't want learning that is really deep?

169
00:09:11,990 --> 00:09:14,269
Like, it's just a good brand.

170
00:09:14,269 --> 00:09:17,830
Um, but you hear me use those terms kind of interchangeably,

171
00:09:17,830 --> 00:09:21,389
but, um, deep learning algorithms, neural networks,

172
00:09:21,389 --> 00:09:25,350
they give us a way to take advantage of more and more and more compute,

173
00:09:25,350 --> 00:09:29,710
capacity so they can build very large AI models with a lot of parameters

174
00:09:29,710 --> 00:09:32,909
to soak up the large amounts of data to get more and more,

175
00:09:32,909 --> 00:09:35,389
you know, intelligent or to make better and better predictions,

176
00:09:35,389 --> 00:09:38,029
and generate more and more accurate outputs using

177
00:09:38,029 --> 00:09:40,909
large amounts of data that's available to us.

178
00:09:40,909 --> 00:09:43,110
Ever since I was a teenager,

179
00:09:43,110 --> 00:09:46,230
my mom's been trying to convince me to stop mumbling.

180
00:09:46,230 --> 00:09:49,629
But now many years later,

181
00:09:49,629 --> 00:09:50,870
I still struggle with that.

182
00:09:50,870 --> 00:09:52,429
So I'll, I'll, I'll try my best.

183
00:09:52,429 --> 00:09:58,629
So please wave at me or kind of let me know if I start to drift lower again.

184
00:09:58,629 --> 00:10:05,230
Yeah. I think my mother would be very happy that to practice like this now.

185
00:10:05,230 --> 00:10:07,669
Um, all right.

186
00:10:07,669 --> 00:10:11,509
So CS fundamentals, machine learning, deep learning,

187
00:10:11,509 --> 00:10:17,340
and then the recent generative AI revolution.

188
00:10:17,340 --> 00:10:19,820
You know, generative AI, um,

189
00:10:19,820 --> 00:10:22,860
sorry, bad handwriting, generative AI,

190
00:10:23,539 --> 00:10:26,580
which is mostly built by

191
00:10:26,580 --> 00:10:30,379
a specific type of neural network called a transformer neural network,

192
00:10:30,379 --> 00:10:31,620
which you learn about in this class.

193
00:10:31,620 --> 00:10:33,980
You actually learn what is a transformer architecture,

194
00:10:33,980 --> 00:10:36,059
um, later in this quarter as well,

195
00:10:36,059 --> 00:10:40,100
is in turn built on top of deep learning, right?

196
00:10:40,100 --> 00:10:42,659
So I assume all of you, you know,

197
00:10:42,659 --> 00:10:44,460
are regularly prompting LMS,

198
00:10:44,460 --> 00:10:46,980
large language models, to help you get work done.

199
00:10:46,980 --> 00:10:51,980
Um, and what I find is that while I use LMS all the time,

200
00:10:51,980 --> 00:10:53,980
for a lot of applications,

201
00:10:53,980 --> 00:10:56,340
just prompting LMS, it doesn't cut it.

202
00:10:56,340 --> 00:11:00,179
There are a lot of things that I cannot get to work just by prompting an LMS.

203
00:11:00,179 --> 00:11:03,059
Um, and so I'll often have to go a layer

204
00:11:03,059 --> 00:11:05,779
deeper into the deep learning layer of abstraction,

205
00:11:05,779 --> 00:11:09,580
and fill it with deep learning algorithms in order to get certain things to work.

206
00:11:09,580 --> 00:11:13,539
And in fact, so what this class covers is,

207
00:11:13,539 --> 00:11:15,860
we'll try to make sure that you are,

208
00:11:15,860 --> 00:11:20,460
you know, expert, near expert in deep learning by the end of this class.

209
00:11:20,460 --> 00:11:22,539
But we'll also, um,

210
00:11:22,539 --> 00:11:25,980
kind of dip a little bit into machine learning concepts.

211
00:11:25,980 --> 00:11:28,259
We'll talk a lot about objective functions,

212
00:11:28,259 --> 00:11:31,860
and tips and tricks for optimizing parameters in an efficient way.

213
00:11:31,860 --> 00:11:36,940
Um, and then we'll also actually reach up a little bit to cover some GEN.AI.

214
00:11:36,940 --> 00:11:39,340
In particular, we'll talk about what is a transformer network.

215
00:11:39,340 --> 00:11:41,059
And then through this quarter,

216
00:11:41,059 --> 00:11:43,500
Jen and I will also chat a little bit about

217
00:11:43,500 --> 00:11:48,179
the job landscape as it relates to GEN.AI and deep learning,

218
00:11:48,179 --> 00:11:53,899
and how to use- how deep learning is enabling certain types of GEN.AI applications.

219
00:11:53,899 --> 00:11:57,779
Okay. Um, I have more to say about this,

220
00:11:57,779 --> 00:12:01,779
but let me just pause for a second and see if you have any questions.

221
00:12:01,779 --> 00:12:07,620
Yeah, go for it. Oh, good question.

222
00:12:07,620 --> 00:12:09,259
Well, I say pre-wrecked, but, um,

223
00:12:09,259 --> 00:12:11,059
congratulations, you've won the prize for

224
00:12:11,059 --> 00:12:14,059
the first question asked in CS2302035.

225
00:12:14,059 --> 00:12:22,730
So well done. So is machine learning a pre-wrecked to this course?

226
00:12:22,730 --> 00:12:29,169
Not really. So I think two common entry points to AI at Stanford are,

227
00:12:29,169 --> 00:12:33,289
um, CS- well, a few common entry points are CS129,

228
00:12:33,289 --> 00:12:35,570
CS229, and CS230.

229
00:12:35,570 --> 00:12:37,970
Um, if you don't know any machine learning,

230
00:12:37,970 --> 00:12:41,289
this course may end up going a little bit fast,

231
00:12:41,289 --> 00:12:43,490
may seem like it's going a little bit fast in the first,

232
00:12:43,490 --> 00:12:45,490
uh, I don't know, two or three weeks,

233
00:12:45,490 --> 00:12:48,730
but some people do pick things up quickly that way.

234
00:12:48,730 --> 00:12:50,610
Uh, and, um, maybe,

235
00:12:50,610 --> 00:12:52,129
actually, I should just read.

236
00:12:52,129 --> 00:12:54,769
So a few causes that you may hear about.

237
00:12:54,769 --> 00:13:04,970
Um, so 129 is a relatively easy entry point into machine learning

238
00:13:04,970 --> 00:13:08,210
that tends to- it takes a longer time to

239
00:13:08,210 --> 00:13:11,049
go through the core concepts of machine learning, right?

240
00:13:11,049 --> 00:13:12,330
What's the optimization objective?

241
00:13:12,330 --> 00:13:13,769
How do you implement gradient descent?

242
00:13:13,769 --> 00:13:15,769
What is, um, logistic regression?

243
00:13:15,769 --> 00:13:17,169
What's a very basic neural network?

244
00:13:17,169 --> 00:13:22,850
So this is a relatively applied easiest of the- of- of this list.

245
00:13:22,850 --> 00:13:26,409
Um, CS229, which I'm also involved in co-teaching,

246
00:13:26,409 --> 00:13:29,409
is, uh, much more mathematical and theoretical,

247
00:13:29,409 --> 00:13:31,409
very high-paced, very intense,

248
00:13:31,409 --> 00:13:32,730
and very mathematical.

249
00:13:32,730 --> 00:13:36,009
And this is less applied than 129 and 230,

250
00:13:36,009 --> 00:13:38,289
but this will go over, um,

251
00:13:38,289 --> 00:13:41,169
a lot more of the theory and the math derivations

252
00:13:41,169 --> 00:13:43,129
behind machine learning algorithms.

253
00:13:43,129 --> 00:13:45,490
So for example, if you want to learn how to do,

254
00:13:45,490 --> 00:13:48,529
um, calculus, not using real numbers,

255
00:13:48,529 --> 00:13:51,529
but calculus using matrices and vectors, you know,

256
00:13:51,529 --> 00:13:53,210
that's a bunch of sort of, I don't know,

257
00:13:53,210 --> 00:13:55,850
mildly complex math that's worth knowing.

258
00:13:55,850 --> 00:13:58,370
Um, CS239 goes over that.

259
00:13:58,370 --> 00:14:00,809
CS230, this class is relatively

260
00:14:00,809 --> 00:14:04,289
applied and it focuses just on deep learning.

261
00:14:04,289 --> 00:14:05,610
So of all the machine learning,

262
00:14:05,610 --> 00:14:07,809
there are a lot of machine learning algorithms out there, right?

263
00:14:07,809 --> 00:14:09,289
Supervised learning, unsupervised learning,

264
00:14:09,289 --> 00:14:10,970
a lot of machine learning algorithms out there.

265
00:14:10,970 --> 00:14:13,850
And many, many of them are very useful,

266
00:14:13,850 --> 00:14:16,330
but- and so they're all worth learning about.

267
00:14:16,330 --> 00:14:18,330
But of all the machine learning algorithms out there,

268
00:14:18,330 --> 00:14:21,370
the one category that is most useful

269
00:14:21,370 --> 00:14:23,730
is, you know, that's taken off the most is deep learning,

270
00:14:23,730 --> 00:14:25,529
and this class focuses just on that.

271
00:14:25,529 --> 00:14:28,169
But the other one is also worth learning about.

272
00:14:28,169 --> 00:14:31,169
So 129 is the easiest on-ramp.

273
00:14:31,169 --> 00:14:34,370
Um, but if you've done either 229 or 230,

274
00:14:34,370 --> 00:14:36,490
I would probably skip 129 at that point.

275
00:14:36,490 --> 00:14:37,809
But if you are getting started,

276
00:14:37,809 --> 00:14:39,929
there- there are multiple on-ramps. Yeah.

277
00:14:39,929 --> 00:14:43,879
Can you take 229 and 230 together?

278
00:14:43,879 --> 00:14:47,279
Oh, uh, yeah. Can you take 229 and 230 together?

279
00:14:47,279 --> 00:14:49,200
Yeah. Thank you. Price for the second question.

280
00:14:49,759 --> 00:14:51,879
All right. If you'd like to clap,

281
00:14:51,879 --> 00:14:57,230
sure, go for it. Um, yes,

282
00:14:57,230 --> 00:14:59,909
you can take CS230 and CS229 together.

283
00:14:59,909 --> 00:15:04,909
Um, we designed the two curricula to be relatively low in overlap.

284
00:15:04,909 --> 00:15:09,909
So the very small amount of- of all the opportunities to- all right.

285
00:15:09,909 --> 00:15:11,909
All right. We- we won't clap for every single question,

286
00:15:11,909 --> 00:15:13,190
but yeah, go ahead.

287
00:15:13,190 --> 00:15:25,789
Yeah. So will we cover the recent,

288
00:15:25,789 --> 00:15:27,590
um, LM developments?

289
00:15:27,590 --> 00:15:30,549
We will touch on the transformer neural network,

290
00:15:30,549 --> 00:15:33,830
but, um, uh, not the,

291
00:15:33,830 --> 00:15:37,269
uh, latest LM variations in this course.

292
00:15:37,269 --> 00:15:42,350
Um, I think a lot of the- it turns out that when you go to get a job,

293
00:15:42,350 --> 00:15:45,870
well, maybe, right, assuming you're going to work in the industry,

294
00:15:45,870 --> 00:15:50,549
the number of people training LM's is actually very small, right?

295
00:15:50,549 --> 00:15:52,950
Some of those jobs tend to be incredibly well-paid,

296
00:15:52,950 --> 00:15:55,950
so we hear about kind of very high salaries in the news media.

297
00:15:55,950 --> 00:15:59,870
But the vast majority of application builders end up,

298
00:15:59,870 --> 00:16:02,429
um, sometimes work in the gen-EI level,

299
00:16:02,429 --> 00:16:06,149
not that often training a transformer from scratch,

300
00:16:06,149 --> 00:16:09,750
um, but then often using deep learning tools as well.

301
00:16:09,750 --> 00:16:10,950
So maybe one example,

302
00:16:10,950 --> 00:16:14,470
um, something that many of my teams have done is,

303
00:16:14,470 --> 00:16:17,470
um, we have trained transformer model-

304
00:16:17,470 --> 00:16:20,190
foundation models from scratch with relatively small ones in,

305
00:16:20,190 --> 00:16:21,590
in, say, startups.

306
00:16:21,590 --> 00:16:23,870
But one thing we do do quite a lot is,

307
00:16:23,870 --> 00:16:26,950
um, take a pre-trained transformer network,

308
00:16:26,950 --> 00:16:31,549
and then engineer our own data to further fine-tune it, right?

309
00:16:31,549 --> 00:16:34,429
Sorry, if I'm using words that you may not totally understand,

310
00:16:34,429 --> 00:16:35,470
you're a pre-trained fine-tuned,

311
00:16:35,470 --> 00:16:37,549
you know what all those terms are by the end of this quarter.

312
00:16:37,549 --> 00:16:39,429
So those are things that we actually do,

313
00:16:39,429 --> 00:16:41,830
um, uh, kind of day-to-day.

314
00:16:41,830 --> 00:16:43,830
This is important for getting a bunch of problems to work,

315
00:16:43,830 --> 00:16:48,269
so you will gain the foundations needed to do type of work in this course.

316
00:16:48,269 --> 00:16:52,629
Um, the one thing, one thing we don't do is talk a lot about how to train

317
00:16:52,629 --> 00:16:55,870
the largest cutting edge transformer networks.

318
00:16:55,870 --> 00:16:58,269
I think that is a very important skill set,

319
00:16:58,269 --> 00:17:00,950
is a relatively niche one for which some people are,

320
00:17:00,950 --> 00:17:02,669
you know, getting paid really, really well.

321
00:17:02,669 --> 00:17:06,230
But the number of people doing that in the world is actually small,

322
00:17:06,230 --> 00:17:09,309
whereas the number of people building applications with,

323
00:17:09,309 --> 00:17:11,150
you know, this set of skills is,

324
00:17:11,150 --> 00:17:12,430
is, is very large.

325
00:17:12,430 --> 00:17:17,529
Uh, do I know any causes covering that?

326
00:17:17,529 --> 00:17:19,930
I think Percy Liang was thinking about doing something,

327
00:17:19,930 --> 00:17:22,009
but I don't remember what he's doing at this quarter.

328
00:17:22,009 --> 00:17:23,130
Um, few people are thinking,

329
00:17:23,130 --> 00:17:24,849
thinking about doing something like that.

330
00:17:24,849 --> 00:17:38,849
Yeah. Good. So, um,

331
00:17:38,849 --> 00:17:40,650
so I'm just repeating for the, for the, um,

332
00:17:40,650 --> 00:17:42,849
mic for the, uh, uh, home viewers.

333
00:17:42,849 --> 00:17:48,210
What portion is, uh, coding versus what proportion is, um, mathematical analysis?

334
00:17:48,210 --> 00:17:51,170
This course is relatively math-lite.

335
00:17:51,170 --> 00:17:53,970
Um, sorry, maybe that was too strong a statement,

336
00:17:53,970 --> 00:17:56,250
but I think this, this course is very practical.

337
00:17:56,250 --> 00:17:59,809
Um, I, I, I remember many years back,

338
00:17:59,809 --> 00:18:02,849
I was speaking with a mathematician,

339
00:18:02,849 --> 00:18:04,930
um, and, you know,

340
00:18:04,930 --> 00:18:06,930
we were just chatting and he was asking,

341
00:18:06,930 --> 00:18:08,490
he was just talking about his career,

342
00:18:08,490 --> 00:18:10,769
why he chose to be a mathematician.

343
00:18:10,769 --> 00:18:14,130
And I, I still remember, you know,

344
00:18:14,130 --> 00:18:17,890
this, this, he had, he had like stars in his eyes,

345
00:18:17,890 --> 00:18:21,529
when he told me that he chose his career path because he felt

346
00:18:21,529 --> 00:18:25,609
his role is to pursue truth and beauty in the universe,

347
00:18:25,609 --> 00:18:28,130
and that's why he became a mathematician.

348
00:18:28,130 --> 00:18:32,450
In this course, I'm not going to do any truth and beauty stuff, right?

349
00:18:32,450 --> 00:18:36,490
So, um, truth and beauty is good,

350
00:18:36,490 --> 00:18:40,089
but you find that I, I want to take a very practical approach to,

351
00:18:40,089 --> 00:18:45,329
um, talking about how to build applications and build software that works.

352
00:18:45,329 --> 00:18:51,289
Anything else? Awesome.

353
00:18:51,289 --> 00:18:53,210
All right. Thank you for all the questions.

354
00:18:53,210 --> 00:18:54,089
Please keep them coming.

355
00:18:54,089 --> 00:18:55,890
Feel free to interact with me or Kian throughout

356
00:18:55,890 --> 00:18:58,849
this quarter as well with questions. I love it.

357
00:18:58,849 --> 00:19:01,410
Um, so, just to,

358
00:19:01,410 --> 00:19:03,690
just to flesh this out a little bit more.

359
00:19:03,690 --> 00:19:06,130
This is what I see in terms of,

360
00:19:06,130 --> 00:19:09,890
um, teams building practical applications.

361
00:19:09,890 --> 00:19:12,769
And I was talking about applications because with

362
00:19:12,769 --> 00:19:15,569
improving machine learning algorithms, deep learning algorithms,

363
00:19:15,569 --> 00:19:19,650
GenEI algorithms, there are a lot of applications that you can build now

364
00:19:19,650 --> 00:19:21,130
that just were, you know,

365
00:19:21,130 --> 00:19:24,609
impossible or like really inaccessible,

366
00:19:24,609 --> 00:19:29,930
you know, to, to any person to build even a few years ago.

367
00:19:29,930 --> 00:19:34,809
Um, and so I find that when I prompt GenEI,

368
00:19:34,809 --> 00:19:39,849
it works really well for a lot of text-based applications.

369
00:19:39,849 --> 00:19:42,970
Um, and there's work on multi-modal LLMs,

370
00:19:42,970 --> 00:19:44,210
large multi-modal models,

371
00:19:44,210 --> 00:19:46,329
so making inroads into vision,

372
00:19:46,329 --> 00:19:48,009
making inroads into audio,

373
00:19:48,009 --> 00:19:49,609
but really GenEI algorithms,

374
00:19:49,609 --> 00:19:51,250
especially transformer networks,

375
00:19:51,250 --> 00:19:52,650
trained to output text, you know,

376
00:19:52,650 --> 00:19:54,849
like ChaiGPD, Claude, Gemini, and so on.

377
00:19:54,849 --> 00:19:57,930
Really fantastic for text-based applications, right?

378
00:19:57,930 --> 00:20:01,650
Um, and I find myself,

379
00:20:01,650 --> 00:20:08,730
um, regularly working with deep learning algorithms directly when I am working with,

380
00:20:08,769 --> 00:20:15,009
um, audio data, image, and video data,

381
00:20:15,009 --> 00:20:17,569
um, and then also, um,

382
00:20:17,569 --> 00:20:22,940
a lot of structured data.

383
00:20:22,940 --> 00:20:27,299
Sorry, my handwriting is awful, right?

384
00:20:27,299 --> 00:20:32,380
So structured data refers to large tables of numbers, right?

385
00:20:32,380 --> 00:20:33,700
Like giant, you know, Excel,

386
00:20:33,700 --> 00:20:35,220
Google Sheets, spreadsheets,

387
00:20:35,220 --> 00:20:36,859
so that's, that's structured data.

388
00:20:36,859 --> 00:20:40,579
Unstructured data refers to text, audio, images, maybe video.

389
00:20:40,579 --> 00:20:43,859
Um, and because a lot of GenEI, right,

390
00:20:43,859 --> 00:20:47,660
large language models like ChaiGPD had grown up being text-in,

391
00:20:47,660 --> 00:20:50,500
text-out kinds of, um, uh, machines,

392
00:20:50,500 --> 00:20:54,059
they are remarkable for a lot of text processing applications.

393
00:20:54,059 --> 00:20:56,140
But for all the types of data,

394
00:20:56,140 --> 00:20:57,700
I end up often, you know,

395
00:20:57,700 --> 00:21:01,779
dipping down directly to use various deep learning algorithms.

396
00:21:01,779 --> 00:21:06,180
Um, and then it turns out that for text-based data,

397
00:21:06,180 --> 00:21:08,099
if all you do is prompting,

398
00:21:08,099 --> 00:21:09,819
you could usually go quite far.

399
00:21:09,819 --> 00:21:13,220
So a lot of applications are built by prompting OMS.

400
00:21:13,220 --> 00:21:16,339
But, um, uh, but I've been on, you know,

401
00:21:16,339 --> 00:21:20,579
quite a few teams where after fiddling with the prompts for a month,

402
00:21:20,579 --> 00:21:25,180
you just can't get the performance to be better just by tuning the prompts.

403
00:21:25,180 --> 00:21:27,779
Um, or another good problem to have,

404
00:21:27,779 --> 00:21:33,220
it turns out use of GenEI tools are relatively inexpensive when you're prototyping, right?

405
00:21:33,220 --> 00:21:35,099
So, you know, a few dollars per million tokens,

406
00:21:35,099 --> 00:21:36,259
you can do a lot.

407
00:21:36,259 --> 00:21:38,660
Um, but sometimes,

408
00:21:38,660 --> 00:21:42,940
if you're lucky enough to be on a product that, um, uh,

409
00:21:42,940 --> 00:21:46,059
hits product market fit and a lot of users want to use, you know,

410
00:21:46,059 --> 00:21:50,420
multiple times I've been on teams where we basically did not care about our,

411
00:21:50,420 --> 00:21:53,099
um, uh, large language model bill, right?

412
00:21:53,099 --> 00:21:54,220
It was like whatever, you know,

413
00:21:54,220 --> 00:21:56,740
$20 a month or $100 a month was fine.

414
00:21:56,740 --> 00:21:59,660
But when more and more users start using it,

415
00:21:59,660 --> 00:22:02,859
then to your team's kind of positive surprise,

416
00:22:02,859 --> 00:22:05,500
your AI bill really starts to skyrocket.

417
00:22:05,500 --> 00:22:06,900
And then at some point,

418
00:22:06,940 --> 00:22:09,299
you look at how much you're paying for your AI bill,

419
00:22:09,299 --> 00:22:10,859
for the large language models,

420
00:22:10,859 --> 00:22:14,019
and, um, to bend the cost curve back down,

421
00:22:14,019 --> 00:22:17,740
often a lot of the techniques in deep learning become very relevant as well.

422
00:22:17,740 --> 00:22:19,180
So there are, I don't know,

423
00:22:19,180 --> 00:22:22,099
I'm thinking just some of our bills were really breathtaking.

424
00:22:22,099 --> 00:22:23,140
I don't want to say the numbers,

425
00:22:23,140 --> 00:22:25,900
but just kind of definitely more than we want to pay, you know,

426
00:22:25,900 --> 00:22:28,940
as much as we love the companies providing OMS,

427
00:22:28,940 --> 00:22:33,500
our bills that we're paying them were significantly larger than I wanted to pay.

428
00:22:33,500 --> 00:22:36,380
Um, and then knowing how to use deep learning

429
00:22:36,380 --> 00:22:37,980
to fine-tune smaller models,

430
00:22:37,980 --> 00:22:41,660
that was really the critical skill set that just bend the cost curve back

431
00:22:41,660 --> 00:22:45,779
and just made the whole thing affordable to keep on providing a service, right?

432
00:22:45,779 --> 00:22:49,579
So, um, yeah, right.

433
00:22:49,579 --> 00:22:55,180
So that's what- so that's the skill sets I hope you get from this course.

434
00:22:55,180 --> 00:23:00,880
Let's see. All right.

435
00:23:00,880 --> 00:23:07,509
Um, and, um, to give a-

436
00:23:07,509 --> 00:23:12,349
well, actually, sorry, let me use this one.

437
00:23:12,349 --> 00:23:24,779
So to give a fi- to give a quick, um, overview,

438
00:23:24,779 --> 00:23:29,099
this course, the online materials is broken down into five modules.

439
00:23:29,099 --> 00:23:32,700
So just to give you a overview of the five of them.

440
00:23:32,700 --> 00:23:35,220
Uh, first one is on the basics of neural networks,

441
00:23:35,220 --> 00:23:37,819
sorry, NN neural networks and, uh,

442
00:23:37,819 --> 00:23:39,339
DL deep learning, right?

443
00:23:39,339 --> 00:23:44,700
So you learn how to build a neural network or deep learning algorithm from scratch in Python.

444
00:23:44,700 --> 00:23:49,019
Um, I find that sometimes if we use the frameworks like TensorFlow or PyTorch,

445
00:23:49,019 --> 00:23:50,299
it hides a lot of the details.

446
00:23:50,299 --> 00:23:51,980
So we actually work through, um,

447
00:23:51,980 --> 00:23:56,339
how to build a basic neural network and how to build a basic deep learning algorithm

448
00:23:56,339 --> 00:24:00,140
just in raw Python so you really understand it.

449
00:24:00,140 --> 00:24:02,579
Um, and then the second module,

450
00:24:02,579 --> 00:24:05,740
the second mini course will be on,

451
00:24:05,740 --> 00:24:07,259
um, how to improve,

452
00:24:07,259 --> 00:24:09,819
how to tune your neural networks.

453
00:24:09,819 --> 00:24:13,099
So we have heard that when you're training a neural network,

454
00:24:13,099 --> 00:24:16,380
there are a lot of parameters or we call them hyperparameters.

455
00:24:16,380 --> 00:24:18,980
Hyperparameters are parameters that control the parameters, right?

456
00:24:18,980 --> 00:24:20,259
So the weights of parameters,

457
00:24:20,259 --> 00:24:24,700
hyperparameters are things like the learning rates or what's the size of your neural network.

458
00:24:24,700 --> 00:24:28,700
And so there are actually a lot of hyperparameters that we end up tuning.

459
00:24:28,700 --> 00:24:31,380
And, um, try to give you a sense of what are

460
00:24:31,380 --> 00:24:35,539
the most important ones and practical skills for tuning them.

461
00:24:35,539 --> 00:24:37,779
It turns out that, um,

462
00:24:37,779 --> 00:24:39,460
if I look at, you know,

463
00:24:39,460 --> 00:24:41,019
like my PhD students,

464
00:24:41,019 --> 00:24:43,420
I think every one of them that, right?

465
00:24:43,420 --> 00:24:46,420
Well, I think, I think that probably every one of them,

466
00:24:46,420 --> 00:24:51,180
definitely everyone that, every PhD student I know that became great, I think,

467
00:24:51,180 --> 00:24:57,380
um, at some point wound up up at 2 a.m. tuning hyperparameters, right?

468
00:24:57,380 --> 00:25:02,220
Um, and I still have very clear recollections of like being in the office,

469
00:25:02,220 --> 00:25:04,299
you know, 2 a.m., 3 a.m.,

470
00:25:04,299 --> 00:25:06,339
filling the parameters, trying to get it to work.

471
00:25:06,339 --> 00:25:10,579
And it turns out that literally your skill at tuning hyperparameters,

472
00:25:10,619 --> 00:25:11,940
it really makes a difference.

473
00:25:11,940 --> 00:25:16,299
So there were some evenings that I knew my skill at tuning hyperparameters,

474
00:25:16,299 --> 00:25:20,099
you know, frankly, it made the difference between whether I went home to sleep at 3 a.m.

475
00:25:20,099 --> 00:25:22,140
versus where I went home to sleep at 7 a.m.

476
00:25:22,140 --> 00:25:24,460
Maybe there's not, maybe don't do what I do.

477
00:25:24,460 --> 00:25:26,779
I'm not encouraging this type of behavior, uh,

478
00:25:26,779 --> 00:25:29,180
but, but this is just my personal experiences.

479
00:25:29,180 --> 00:25:30,460
But it really makes a big difference,

480
00:25:30,460 --> 00:25:33,819
your practical skill at how quickly you can figure out

481
00:25:33,819 --> 00:25:37,339
the recipe to get these neural networks to train.

482
00:25:37,380 --> 00:25:45,809
Um, uh, and, um, and related to that is,

483
00:25:45,809 --> 00:25:56,910
um, one thing we've talked a lot about in this course

484
00:25:56,910 --> 00:26:00,349
is strategies for building machine learning projects.

485
00:26:00,349 --> 00:26:03,910
So it turns out that if you build a complex system, you know,

486
00:26:03,910 --> 00:26:06,549
let's say you build, there's one example we'll go through later this quarter.

487
00:26:06,549 --> 00:26:08,670
Say you want to build a system that,

488
00:26:08,670 --> 00:26:10,710
um, recognizes your face,

489
00:26:10,710 --> 00:26:12,230
a camera that recognizes your face,

490
00:26:12,230 --> 00:26:13,990
your friend's face, unlock a door, right?

491
00:26:13,990 --> 00:26:15,269
Security, safety, whatever.

492
00:26:15,269 --> 00:26:16,589
So it's something like that.

493
00:26:16,589 --> 00:26:18,829
You know, I've, I've worked on something like that.

494
00:26:18,829 --> 00:26:19,990
Jan's worked on something like that.

495
00:26:19,990 --> 00:26:22,829
These are complex systems with multiple components.

496
00:26:22,829 --> 00:26:24,349
Um, there's a camera,

497
00:26:24,349 --> 00:26:27,150
there's, you know, do you subtract, clean up the image?

498
00:26:27,150 --> 00:26:28,869
Do you cut out the face?

499
00:26:28,869 --> 00:26:30,470
How do you register the face?

500
00:26:30,470 --> 00:26:31,630
How do you compare a face?

501
00:26:31,630 --> 00:26:35,230
How do you decide to take another picture before you unlock the door or just,

502
00:26:35,230 --> 00:26:37,990
you know, or someone trying to fake,

503
00:26:37,990 --> 00:26:39,630
uh, hold up a picture,

504
00:26:39,630 --> 00:26:40,910
print on a piece of paper?

505
00:26:40,910 --> 00:26:42,750
There are actually a lot of decisions.

506
00:26:42,789 --> 00:26:45,150
And so what I find is that, um,

507
00:26:45,150 --> 00:26:51,390
the biggest difference between a team that knows how to drive forward a project like this well,

508
00:26:51,390 --> 00:26:54,710
and get it done in days rather than weeks,

509
00:26:54,710 --> 00:26:56,509
or weeks rather than many months,

510
00:26:56,509 --> 00:27:00,670
is the ability to drive a disciplined development process.

511
00:27:00,670 --> 00:27:02,789
It turns out when you have a complex system,

512
00:27:02,789 --> 00:27:07,829
less experienced teams will often almost pick things at random to work on, right?

513
00:27:07,829 --> 00:27:09,309
They'll read one research paper and say,

514
00:27:09,309 --> 00:27:12,470
oh, I read in the research paper we should get more data.

515
00:27:12,549 --> 00:27:16,430
Yeah, well, because like some newspaper said AI needs lots of data.

516
00:27:16,430 --> 00:27:19,069
So let's go spend six months to collect more data.

517
00:27:19,069 --> 00:27:24,430
Turns out a lot of the time collecting more data does not help your application.

518
00:27:24,430 --> 00:27:27,069
Um, but sometimes it's a huge help.

519
00:27:27,069 --> 00:27:29,269
So given your application,

520
00:27:29,269 --> 00:27:30,309
how do you decide?

521
00:27:30,309 --> 00:27:32,230
Should you spend more time collecting data?

522
00:27:32,230 --> 00:27:33,670
Maybe you should buy more GPUs.

523
00:27:33,670 --> 00:27:37,150
I should definitely know people that read in the news,

524
00:27:37,150 --> 00:27:38,750
a lot of GPUs are helpful, right?

525
00:27:38,750 --> 00:27:40,069
And then I've literally met,

526
00:27:40,230 --> 00:27:44,029
you know, fairly senior business leaders that have, um,

527
00:27:44,029 --> 00:27:48,509
spent a very large amounts of money buying GPUs.

528
00:27:48,509 --> 00:27:52,190
And then, you know, um, some funny stories.

529
00:27:52,190 --> 00:27:54,029
And then I go talk to them and say,

530
00:27:54,029 --> 00:27:55,309
what are you doing with these GPUs?

531
00:27:55,309 --> 00:27:57,309
And then sometimes, you know,

532
00:27:57,309 --> 00:28:02,789
there was one meeting I was in where literally a very large family run

533
00:28:02,789 --> 00:28:05,750
business had bought a lot of GPUs.

534
00:28:05,789 --> 00:28:08,349
And the CTO, um,

535
00:28:08,349 --> 00:28:12,630
then pointed to his nephew, uh, uh, who, who, who, who is a,

536
00:28:12,630 --> 00:28:15,829
who is a current college student undergrad and said,

537
00:28:15,829 --> 00:28:17,509
oh, my nephew knows AI.

538
00:28:17,509 --> 00:28:20,470
I'm giving him this very large budget in GPUs.

539
00:28:20,470 --> 00:28:22,069
And I think he'll do AI for me.

540
00:28:22,069 --> 00:28:25,309
Right. And so, but so I think that, uh, uh,

541
00:28:25,309 --> 00:28:28,109
knowing how to make these decisions and not just buying to the height

542
00:28:28,109 --> 00:28:31,390
that you read about in the newspapers is really important.

543
00:28:31,390 --> 00:28:35,589
Um, and one thing I hope to do in this course is share with you

544
00:28:35,589 --> 00:28:38,630
what driving a disciplined development process looks like,

545
00:28:38,630 --> 00:28:41,789
because this is one of the things that really makes a 10x difference

546
00:28:41,789 --> 00:28:44,710
in the speed with which you can get something to work.

547
00:28:44,710 --> 00:28:46,789
I've literally seen teams, you know,

548
00:28:46,789 --> 00:28:50,750
like take six months or 10 months pursuing an approach

549
00:28:50,750 --> 00:28:54,990
that experienced engineers would go in and go, you know what?

550
00:28:54,990 --> 00:28:56,470
I could have told you six months ago

551
00:28:56,470 --> 00:28:58,430
that spending all this time collecting data,

552
00:28:58,430 --> 00:29:01,750
this was not going to get your application to where you wanted to go.

553
00:29:01,750 --> 00:29:05,509
Right. Um, but so how do you examine an application?

554
00:29:05,509 --> 00:29:07,230
And figure out the diagnostics and figure out

555
00:29:07,230 --> 00:29:09,470
what are the productive things to do for your application?

556
00:29:09,470 --> 00:29:11,470
We actually spend a lot of time on that.

557
00:29:11,470 --> 00:29:16,190
And in fact, um, I'm excited about doing some simulation exercises

558
00:29:16,190 --> 00:29:18,670
in this classroom with you later this quarter,

559
00:29:18,670 --> 00:29:21,950
where, um, I'll invite you later this quarter,

560
00:29:21,950 --> 00:29:26,230
you know, to, to, to say in this, in this scenario,

561
00:29:26,230 --> 00:29:28,789
what would you do and, and see if you could,

562
00:29:28,789 --> 00:29:31,750
you know, make decisions in a more systematic way.

563
00:29:32,710 --> 00:29:37,230
All right. Um, then course four,

564
00:29:37,230 --> 00:29:40,190
we'll talk about convolutional networks.

565
00:29:40,190 --> 00:29:44,309
Um, very useful for computer vision applications.

566
00:29:44,309 --> 00:29:51,099
Um, and then so confidence are specialized models,

567
00:29:51,099 --> 00:29:54,779
most used mostly for vision applications,

568
00:29:54,779 --> 00:29:55,980
dealing with images.

569
00:29:55,980 --> 00:29:59,579
And then we'll talk finally about sequence models.

570
00:29:59,579 --> 00:30:03,619
So sequences could be time series or sequences of

571
00:30:03,619 --> 00:30:04,940
text, uh, like words.

572
00:30:04,940 --> 00:30:07,220
So I'll start touching the transformer network,

573
00:30:07,220 --> 00:30:10,980
uh, that, you know, that power a lot of the gen.ai revolution.

574
00:30:10,980 --> 00:30:15,059
Okay. Um, and so throughout learning,

575
00:30:15,059 --> 00:30:16,740
through learning all of these things,

576
00:30:16,740 --> 00:30:21,019
I hope that you all gain a large tool chest,

577
00:30:21,019 --> 00:30:23,740
um, that will enable you to tackle

578
00:30:23,740 --> 00:30:27,339
an almost bewildering range of applications.

579
00:30:27,339 --> 00:30:30,900
I think one of the things I've most enjoyed as an AI person is,

580
00:30:30,900 --> 00:30:33,099
it turns out when you work in AI,

581
00:30:33,099 --> 00:30:37,059
there's so many other teams that, um,

582
00:30:37,059 --> 00:30:40,500
have data and that could use our hope, right?

583
00:30:40,500 --> 00:30:43,059
So I feel that as an AI person, you know,

584
00:30:43,059 --> 00:30:46,900
I somehow bizarrely had the right to play in,

585
00:30:46,900 --> 00:30:50,500
you know, building autonomous helicopters or hoping companies,

586
00:30:50,500 --> 00:30:53,380
I don't know, place more relevant ads.

587
00:30:53,380 --> 00:30:55,339
Maybe not the most inspiring thing I've worked on,

588
00:30:55,339 --> 00:30:57,259
but certainly very lucrative for some companies, right?

589
00:30:57,259 --> 00:31:01,700
Or improve web search rankings, um, or improve safety, uh, you know,

590
00:31:01,700 --> 00:31:03,900
get rid of the kind of negative toxic results

591
00:31:03,900 --> 00:31:06,420
that you may not want search results to come back on,

592
00:31:06,420 --> 00:31:08,660
or improve e-commerce retailing,

593
00:31:08,660 --> 00:31:10,740
or improve speech recognition, um,

594
00:31:10,740 --> 00:31:13,539
or help ships be more fuel-efficient, right?

595
00:31:13,539 --> 00:31:15,700
There's re- all these are real examples, um,

596
00:31:15,700 --> 00:31:16,779
or fight fraud,

597
00:31:16,779 --> 00:31:20,019
which is actually really exciting when you're fighting financial fraud,

598
00:31:20,019 --> 00:31:21,660
um, which is obviously a bad thing,

599
00:31:21,660 --> 00:31:25,380
but, uh, uh, when you- sometimes you- when you're fighting fraud,

600
00:31:25,380 --> 00:31:29,460
sometimes you wake up in the morning and your team's alerted you that there's a new scam,

601
00:31:29,460 --> 00:31:31,299
and then you just have to go and fight them

602
00:31:31,299 --> 00:31:32,660
and build algorithms in real time,

603
00:31:32,660 --> 00:31:34,339
and you know that every hour you take,

604
00:31:34,339 --> 00:31:37,059
you know, more- more money actually leads to the financial system.

605
00:31:37,059 --> 00:31:39,299
So it's kind of awful that there's financial fraud,

606
00:31:39,299 --> 00:31:41,779
but it's actually one of the most exhilarating things I've worked on,

607
00:31:41,779 --> 00:31:45,660
because literally every hour you are slower to- to,

608
00:31:45,660 --> 00:31:47,220
you know, formulate a response,

609
00:31:47,220 --> 00:31:49,779
you know more dollars are leaking up every hour,

610
00:31:49,779 --> 00:31:52,019
so, um, anyway.

611
00:31:52,019 --> 00:31:56,019
So- so somehow when you have this two sets of deep learning,

612
00:31:56,019 --> 00:32:00,700
um, you just have a bewildering right to play or ability to play

613
00:32:00,700 --> 00:32:03,980
in a huge range of applications,

614
00:32:03,980 --> 00:32:05,900
uh, that could use your help, right?

615
00:32:05,900 --> 00:32:07,579
And I think on campus too,

616
00:32:07,579 --> 00:32:09,500
there's so many departments,

617
00:32:09,500 --> 00:32:12,299
um, uh, across campus,

618
00:32:12,299 --> 00:32:16,140
um, in the sciences, engineering, humanities, business,

619
00:32:16,140 --> 00:32:20,380
uh, that have interesting data where your skill set will let you,

620
00:32:20,380 --> 00:32:24,220
if you choose, collaborate with them to do interesting projects.

621
00:32:24,220 --> 00:32:25,259
And- and I find for example,

622
00:32:25,259 --> 00:32:30,779
bizarrely, uh, some of my PhD students are working on climate science.

623
00:32:30,779 --> 00:32:32,619
It's like, what do I know about climate science, right?

624
00:32:32,619 --> 00:32:33,819
I wish I knew more,

625
00:32:33,819 --> 00:32:37,259
but using machine learning tools, you know,

626
00:32:37,259 --> 00:32:40,460
we can actually work on climate modeling and- and geoengineering,

627
00:32:40,460 --> 00:32:43,500
and- and just play in all of these important,

628
00:32:43,500 --> 00:32:47,980
um, uh, important, hopefully important and interesting places.

629
00:32:47,980 --> 00:32:51,660
I hope that you have that skill set as well by the end of this quarter.

630
00:32:51,660 --> 00:33:02,809
Yeah. Yeah, so how do you know if you know- how do you know

631
00:33:02,809 --> 00:33:05,130
if you have enough data for a neural network?

632
00:33:05,130 --> 00:33:08,569
Um, it turns out to be really difficult to know.

633
00:33:08,569 --> 00:33:12,569
Uh, so if it's a application that others have worked on,

634
00:33:12,569 --> 00:33:15,690
or that you've worked on before, then you may have a sense.

635
00:33:15,690 --> 00:33:20,890
So for example, I don't know, I- because I worked on face recognition,

636
00:33:20,890 --> 00:33:21,930
you kind of have a sense.

637
00:33:21,930 --> 00:33:24,329
You want to train a face recognition system from scratch,

638
00:33:24,329 --> 00:33:28,410
having like 50,000 images, 50,000 unique faces is pretty good, right?

639
00:33:28,410 --> 00:33:30,170
Or- or- so if you've worked on it,

640
00:33:30,170 --> 00:33:32,250
or if you read the research literature,

641
00:33:32,250 --> 00:33:33,849
for something people have worked on,

642
00:33:33,849 --> 00:33:36,569
that would give you a gut sense for how much data,

643
00:33:36,569 --> 00:33:39,130
um, could be enough to get you started.

644
00:33:39,130 --> 00:33:43,369
Uh, but then for, um, green field brand new projects

645
00:33:43,369 --> 00:33:45,769
that no one in the world has worked on before,

646
00:33:45,769 --> 00:33:49,529
um, if you can't find parallel projects that are kind of comparable,

647
00:33:49,529 --> 00:33:51,049
it could be really hard to tell.

648
00:33:51,049 --> 00:33:55,210
And so common advice for completely, um, green field-

649
00:33:55,210 --> 00:33:56,890
sorry, green field, I mean a brand new project,

650
00:33:56,890 --> 00:33:59,450
just similar than things- so for example,

651
00:33:59,450 --> 00:34:02,009
if someone has invented a new medical device,

652
00:34:02,009 --> 00:34:03,849
and no one has collected this type of,

653
00:34:03,849 --> 00:34:05,769
you know, blood specimen data before,

654
00:34:05,769 --> 00:34:07,210
it's really hard to tell.

655
00:34:07,210 --> 00:34:09,769
And in that case, the most common advice is,

656
00:34:09,769 --> 00:34:13,849
um, get a little bit of data and just try training a model.

657
00:34:13,849 --> 00:34:17,929
And the degree to which your initial model works or does not work,

658
00:34:17,929 --> 00:34:21,610
that will help you hone your perspective on how much data may be needed.

659
00:34:21,610 --> 00:34:22,969
And you may be surprised,

660
00:34:22,969 --> 00:34:25,769
maybe 100 data points is all you need, right?

661
00:34:25,769 --> 00:34:27,610
Sometimes you've been surprised by that.

662
00:34:27,610 --> 00:34:30,730
And then sometimes we've also worked on applications where,

663
00:34:30,730 --> 00:34:32,969
you know, 100 billion data points later,

664
00:34:32,969 --> 00:34:35,530
we're still trying to get a lot more data.

665
00:34:35,530 --> 00:34:37,929
Um, and I- I find it really difficult to tell.

666
00:34:37,929 --> 00:34:40,090
Yeah, good question.

667
00:34:40,889 --> 00:34:41,530
Anything else?

668
00:34:43,130 --> 00:34:46,570
Oh, so this is a good time for me to pause and take questions because,

669
00:34:46,570 --> 00:34:49,050
uh, oh, so what- what I'm going to do is,

670
00:34:49,050 --> 00:34:54,329
um, uh, right, what I'm going to do after this is,

671
00:34:54,329 --> 00:34:59,449
um, switch tracks and talk a little bit about exciting trends in AI,

672
00:34:59,449 --> 00:35:04,250
um, uh, kind of recent trends in AI that I'm excited about and how I view the AI landscape.

673
00:35:04,250 --> 00:35:07,769
But so this is actually a good breakpoint to see if people have

674
00:35:07,769 --> 00:35:10,489
other questions before I talk about some trends in AI.

675
00:35:11,530 --> 00:35:12,170
Anything else?

676
00:35:13,289 --> 00:35:13,849
Yeah, please.

677
00:35:28,550 --> 00:35:31,590
So I guess, um, let's see.

678
00:35:31,590 --> 00:35:37,510
All of these- many of these terms are blurry and kind of fuzz a little bit into each other.

679
00:35:37,510 --> 00:35:42,789
But, um, when I refer to generative AI, um, generative AI is this,

680
00:35:42,789 --> 00:35:49,590
uh, body of work that, um, generates text and sometimes also images,

681
00:35:49,590 --> 00:35:54,389
sometimes also audio, um, using deep learning algorithms in certain ways.

682
00:35:54,389 --> 00:35:57,590
So I think generative AI refers to this body of work, um,

683
00:35:57,590 --> 00:36:02,550
with most of the center of gravity on generating text, you know, maybe also images.

684
00:36:02,550 --> 00:36:06,789
And the text generation algorithms have been mostly implemented using

685
00:36:06,789 --> 00:36:09,750
transformer neural networks, uh, train on large amounts of data,

686
00:36:09,750 --> 00:36:11,429
you know, straight off the internet and elsewhere.

687
00:36:11,989 --> 00:36:15,349
So- so when I refer to generative AI, that's- I guess, uh,

688
00:36:15,349 --> 00:36:19,829
that's one particular application of deep learning models that has

689
00:36:19,829 --> 00:36:23,829
given us large language models like Chai GP and Claude and Gemini and, uh,

690
00:36:23,829 --> 00:36:25,269
MetaLamar and so on.

691
00:36:25,989 --> 00:36:26,630
That make sense?

692
00:36:27,429 --> 00:36:29,940
Yeah, cool.

693
00:36:29,940 --> 00:36:30,579
Anything else?

694
00:36:34,570 --> 00:36:35,130
Cool.

695
00:36:35,130 --> 00:36:35,530
All right.

696
00:36:36,650 --> 00:36:39,769
So let me- could- could we go to the slides, please?

697
00:36:40,809 --> 00:36:44,809
One of the nice things about this clause is Ken and I can occasionally, uh, just

698
00:36:44,809 --> 00:36:48,889
share a view of things we're seeing in the broader world.

699
00:36:48,889 --> 00:36:51,449
Hey, while- while- while we're doing that, I'm actually curious,

700
00:36:51,449 --> 00:36:56,730
how many of you use a, um, specialized AI-assisted coding tool,

701
00:36:56,730 --> 00:36:59,929
like Cloud Code, Cursor, GeminiCI, Codex, CourtWindsor?

702
00:37:01,369 --> 00:37:01,849
Awesome.

703
00:37:01,849 --> 00:37:03,449
Almost everyone, but not everyone.

704
00:37:03,449 --> 00:37:03,929
Interesting.

705
00:37:04,889 --> 00:37:06,329
Oh, interesting.

706
00:37:06,329 --> 00:37:07,690
Oh, I thought- interesting.

707
00:37:07,690 --> 00:37:08,250
Okay, cool.

708
00:37:08,889 --> 00:37:12,250
So, you know, one of the most exciting things that's happened in

709
00:37:12,250 --> 00:37:15,210
programming is AI-assisted coding.

710
00:37:15,210 --> 00:37:19,449
And I feel like, um, I personally hope I never,

711
00:37:19,449 --> 00:37:21,849
ever have to go back to coding by hand, right?

712
00:37:21,849 --> 00:37:25,690
Like, it's just, um, it's- it's actually interesting, uh,

713
00:37:25,690 --> 00:37:28,409
I often work in coffee shops on the weekend,

714
00:37:28,409 --> 00:37:31,210
and a few weekends ago, I was sitting in a coffee shop,

715
00:37:31,210 --> 00:37:35,530
and sitting next to me was someone that was, you know, coding by hand,

716
00:37:35,530 --> 00:37:36,809
and looked so strange.

717
00:37:36,809 --> 00:37:38,650
I just asked them, what are you doing?

718
00:37:39,210 --> 00:37:42,170
In a- in a respectful way, you know.

719
00:37:42,170 --> 00:37:46,489
Uh, and it turns out that- that they're- they're doing homework from

720
00:37:46,489 --> 00:37:48,969
some other university that required me to code by hand.

721
00:37:48,969 --> 00:37:54,250
Um, but one of the things I find exciting is that, um, uh,

722
00:37:54,250 --> 00:37:59,610
individual programmer productivity is much higher than it ever used to be, right?

723
00:37:59,610 --> 00:38:02,489
And maybe I want to share with you just- just one- one- one thing,

724
00:38:02,489 --> 00:38:03,449
what- what I see.

725
00:38:03,449 --> 00:38:05,929
So I find that in the software work that I do,

726
00:38:05,929 --> 00:38:08,250
I- I maybe categorize it into two buckets.

727
00:38:08,250 --> 00:38:12,170
One is building quick and dirty prototypes to see if something works,

728
00:38:12,170 --> 00:38:16,969
and then sometimes I, you know, write production-grade, enterprise-grade,

729
00:38:16,969 --> 00:38:20,090
robust, reliable software that has a scale, right?

730
00:38:20,090 --> 00:38:24,329
Um, and I find that where AI-assisted coding has made the biggest difference

731
00:38:24,329 --> 00:38:26,329
is building the quick and dirty prototypes.

732
00:38:26,329 --> 00:38:30,329
Um, whereas I think actually literally one of my collaborators, um,

733
00:38:30,329 --> 00:38:33,769
used one of the agentic coders, did I name, but I won't say which one,

734
00:38:33,769 --> 00:38:36,969
but literally this morning, he sent me a Slack message saying,

735
00:38:36,969 --> 00:38:41,289
sorry, you know, this agentic coder had a database migration error,

736
00:38:41,289 --> 00:38:44,570
and we just wiped out all of the database records.

737
00:38:44,570 --> 00:38:48,650
Uh, for- fortunately for a test application with like five users,

738
00:38:48,650 --> 00:38:49,929
uh, but- but it did happen.

739
00:38:49,929 --> 00:38:52,329
So I find that- oh, okay, thank you.

740
00:38:53,130 --> 00:38:56,650
So I find that, um, my use of the agentic coders,

741
00:38:56,650 --> 00:39:00,090
you know, for the production-grade software is more careful,

742
00:39:00,090 --> 00:39:03,530
whereas for building quick and dirty prototypes, it kind of, um,

743
00:39:04,170 --> 00:39:07,769
so unless you're not shipping software in a respo- in an irresponsible way,

744
00:39:08,409 --> 00:39:12,570
um, quick and dirty prototypes have a lot fewer dependencies.

745
00:39:12,570 --> 00:39:15,769
You usually don't need to integrate legacy data infrastructure,

746
00:39:15,769 --> 00:39:18,889
and then, you know, I'm- I'm gonna say something that I-

747
00:39:18,889 --> 00:39:21,050
that- that feels like something I'm not supposed to say,

748
00:39:21,050 --> 00:39:26,329
but I'll- but I'll say it anyway, which is, um, uh, I find that, um,

749
00:39:27,690 --> 00:39:32,250
when I am running code, I- I find that people often worry about,

750
00:39:32,250 --> 00:39:37,050
um, safety and reliability of software or security of software.

751
00:39:37,610 --> 00:39:40,170
So one thing I often say to my teams is, um,

752
00:39:40,170 --> 00:39:43,929
if you are building a prototype that only runs on your own laptop

753
00:39:44,570 --> 00:39:46,570
and doesn't use any sensitive information,

754
00:39:46,570 --> 00:39:48,250
so there's no risk of sensitive information,

755
00:39:48,809 --> 00:39:53,769
then unless you are planning to, you know, maliciously hack into your own laptop,

756
00:39:54,409 --> 00:39:57,130
right, the security requirements can be lower.

757
00:39:57,130 --> 00:40:00,969
And so I find that, um, when building quick and dirty prototypes,

758
00:40:00,969 --> 00:40:06,809
um, having a sandbox environment that lets you operate within it quickly

759
00:40:06,809 --> 00:40:09,369
means that you can just make a lot of decisions faster

760
00:40:09,369 --> 00:40:13,050
without worrying as much about scalability or security or reliability.

761
00:40:13,050 --> 00:40:16,329
So unless the sandbox environment means this stuff isn't gonna get out there

762
00:40:16,329 --> 00:40:19,050
or leak information or create a security loophole.

763
00:40:19,050 --> 00:40:22,730
So that- that's part of what lets us move much faster.

764
00:40:24,170 --> 00:40:27,449
And so I find that, um, because of the speed of prototyping,

765
00:40:28,010 --> 00:40:33,530
so unless you can do so in a responsible way, um, to pursue innovative ideas,

766
00:40:33,530 --> 00:40:38,650
my teams will increasingly, you know, try 20 things and see what sticks.

767
00:40:38,650 --> 00:40:43,849
And, um, because I- and I know that a lot of teams are lamenting

768
00:40:43,849 --> 00:40:46,809
that many proof of concepts never make it into production, right?

769
00:40:46,809 --> 00:40:48,250
You try something and it doesn't work.

770
00:40:48,250 --> 00:40:50,969
And I know some teams are feeling angst about that.

771
00:40:51,530 --> 00:40:52,809
I actually have a different view.

772
00:40:53,369 --> 00:40:56,170
I think if the cost of a proof of concept is low enough,

773
00:40:56,730 --> 00:40:59,769
then who cares if you have to do 20 of them?

774
00:40:59,769 --> 00:41:03,849
And that's the price for finding the one or two things that works really well.

775
00:41:04,570 --> 00:41:07,369
So one thing you hear about in this course is

776
00:41:07,369 --> 00:41:10,010
both when- when you're building a machine learning application,

777
00:41:10,809 --> 00:41:12,969
you usually don't know what's gonna happen.

778
00:41:14,010 --> 00:41:16,010
And there's a specific reason for that.

779
00:41:16,010 --> 00:41:19,369
The reason is the output of the machine learning algorithm,

780
00:41:19,369 --> 00:41:24,329
it depends both on the code you write as well as on the data you're training on.

781
00:41:24,889 --> 00:41:26,809
And while you control the code 100%,

782
00:41:28,489 --> 00:41:33,369
you don't really know usually what's really in the data,

783
00:41:33,369 --> 00:41:36,730
in the weird and wonderful data that the world has given you.

784
00:41:37,449 --> 00:41:40,570
So, for example, I worked on speech recognition a lot

785
00:41:40,570 --> 00:41:42,409
to multiple companies in multiple contexts.

786
00:41:42,969 --> 00:41:46,090
And even now when I work on speech recognition,

787
00:41:46,090 --> 00:41:48,889
I'm still, you know, sometimes a little bit surprised that,

788
00:41:48,889 --> 00:41:53,130
oh, this data has people of a certain accent more than I realized,

789
00:41:53,130 --> 00:41:56,090
or people somehow speak faster,

790
00:41:56,090 --> 00:42:00,170
or boy, there's a lot of background noise when people use it in a car, right?

791
00:42:00,170 --> 00:42:03,610
So even though I worked on speech recognition multiple times,

792
00:42:03,610 --> 00:42:06,650
oh, and actually one recent example of application,

793
00:42:06,650 --> 00:42:08,889
I was actually surprised by the number of background speakers.

794
00:42:08,889 --> 00:42:11,369
They talk to us, they come and talk to a different person,

795
00:42:11,369 --> 00:42:13,610
then they talk to us, and then we get confused, right?

796
00:42:13,610 --> 00:42:18,969
So I find that the data that the world gives us is often weird and wonderful.

797
00:42:19,610 --> 00:42:23,849
And so it is only by building a system

798
00:42:23,849 --> 00:42:27,210
that you then start to discover these things in the data

799
00:42:27,210 --> 00:42:28,730
that lets you make progress.

800
00:42:30,250 --> 00:42:32,489
And with a lot of software applications as well,

801
00:42:32,489 --> 00:42:34,170
separate from machine learning applications,

802
00:42:34,730 --> 00:42:37,849
a lot of what I end up having to discover is

803
00:42:37,849 --> 00:42:40,090
what do users actually want, right?

804
00:42:40,090 --> 00:42:42,170
So again, I control my code 100%.

805
00:42:42,170 --> 00:42:44,250
I can write whatever code I want, I control that.

806
00:42:44,969 --> 00:42:48,570
But you don't get to control how your users react to your system.

807
00:42:49,130 --> 00:42:53,849
And I find that our ability to build quick and dirty prototypes rapidly,

808
00:42:55,050 --> 00:42:57,210
both to discover what's in the data,

809
00:42:57,210 --> 00:42:59,849
and also to take other users to see if they like it,

810
00:42:59,849 --> 00:43:02,650
that allows us to drive faster feedback loops

811
00:43:02,650 --> 00:43:04,650
than was ever possible before

812
00:43:04,650 --> 00:43:09,210
to then help us build more and more valuable software, right?

813
00:43:10,889 --> 00:43:15,210
And I think, you know, I know that the mantra,

814
00:43:15,210 --> 00:43:17,050
move fast and break things, right?

815
00:43:17,050 --> 00:43:20,090
Got a bad rep because it broke things.

816
00:43:21,449 --> 00:43:25,610
And I find that some teams took away from this

817
00:43:25,610 --> 00:43:29,289
that we should not move fast, but I think that's a mistake.

818
00:43:29,289 --> 00:43:33,130
So what I usually tell my teams is move fast and be responsible.

819
00:43:33,130 --> 00:43:36,090
And despite all the hype about, you know,

820
00:43:36,090 --> 00:43:38,570
AI extinction risk, AI kill us all,

821
00:43:38,570 --> 00:43:42,250
all that somewhat bizarre hype, in my opinion,

822
00:43:42,250 --> 00:43:44,809
I find that when teams move really fast,

823
00:43:44,809 --> 00:43:48,170
we can then implement things, test it out in a responsible way,

824
00:43:48,170 --> 00:43:50,650
and much more quickly identify problems and fix them.

825
00:43:50,650 --> 00:43:53,369
So I find that a lot of the most responsible teams I know,

826
00:43:54,250 --> 00:43:56,250
teams able to really get stuff to work really quickly,

827
00:43:56,969 --> 00:43:58,969
they tend to be some of the fastest moving teams.

828
00:43:58,969 --> 00:44:00,969
So this is that speed of execution

829
00:44:00,969 --> 00:44:04,650
that lets you finally implement it, figure out what's in your data,

830
00:44:04,650 --> 00:44:05,769
figure out what uses one,

831
00:44:05,769 --> 00:44:08,250
and that's the best way to figure out what could actually go wrong

832
00:44:08,889 --> 00:44:12,170
to then make sure things don't actually go wrong, right?

833
00:44:12,170 --> 00:44:20,440
And somewhat related to that is AI coding assistance.

834
00:44:21,880 --> 00:44:24,599
And I assume, you know, almost everyone,

835
00:44:24,599 --> 00:44:26,519
or everyone in this class knows how to code.

836
00:44:28,280 --> 00:44:31,000
If you are, we haven't learned to code yet,

837
00:44:31,000 --> 00:44:32,920
you probably might not want to take this class yet.

838
00:44:33,880 --> 00:44:36,599
But I find that there have been people,

839
00:44:36,599 --> 00:44:39,719
including very senior, right, business leaders,

840
00:44:39,719 --> 00:44:41,320
advising others to not learn to code,

841
00:44:41,320 --> 00:44:42,840
and the grounds that AI will automate it.

842
00:44:43,639 --> 00:44:45,239
And I want to share this with you,

843
00:44:45,239 --> 00:44:47,079
not because I think you need to learn to code,

844
00:44:47,079 --> 00:44:49,239
but because I hope you help me spread the word, right?

845
00:44:49,239 --> 00:44:51,400
Go to all of your friends in other departments

846
00:44:51,400 --> 00:44:53,480
to tell them this advice is not learned to code.

847
00:44:54,599 --> 00:44:55,880
I think we'll look back on this

848
00:44:55,880 --> 00:44:58,360
as some of the worst career advice ever given.

849
00:44:59,639 --> 00:45:02,679
And the reason is when coding becomes easier,

850
00:45:02,679 --> 00:45:04,679
more people should do it rather than fewer.

851
00:45:05,480 --> 00:45:09,400
So when humanity went from punch cards to keyboard and terminal,

852
00:45:09,400 --> 00:45:11,000
that made coding easier,

853
00:45:11,000 --> 00:45:13,159
and so more people learned to code.

854
00:45:14,280 --> 00:45:16,760
When we went from assembly language to modern,

855
00:45:16,760 --> 00:45:19,480
well, at that time, modern programming languages,

856
00:45:19,480 --> 00:45:20,599
that made coding easier.

857
00:45:20,599 --> 00:45:21,960
More people learned to code.

858
00:45:21,960 --> 00:45:24,119
I went back and actually found these papers

859
00:45:24,119 --> 00:45:28,119
on these articles on when COBOL,

860
00:45:28,119 --> 00:45:31,880
very old school programming language, right, was invented.

861
00:45:31,880 --> 00:45:33,239
And there were actually people that said,

862
00:45:33,239 --> 00:45:36,440
oh, wow, now we have the COBOL programming language.

863
00:45:36,440 --> 00:45:37,559
Coding is so easy.

864
00:45:37,559 --> 00:45:39,639
Who needs programmers anymore, right?

865
00:45:39,880 --> 00:45:41,719
And obviously, the opposite happened.

866
00:45:43,239 --> 00:45:45,480
We went from text editors to IDEs,

867
00:45:45,480 --> 00:45:47,559
and then, you know, AI assisted coding.

868
00:45:48,119 --> 00:45:51,800
As coding becomes easier, people should code a lot more.

869
00:45:52,519 --> 00:45:53,960
A lot more people should learn to code.

870
00:45:54,519 --> 00:45:57,000
And the other thing I'm seeing is,

871
00:45:57,000 --> 00:45:59,800
I just add something that's been on people's minds.

872
00:45:59,800 --> 00:46:04,840
I know that unemployment of recent computer science drags

873
00:46:04,840 --> 00:46:07,480
has ticked up to higher than it's been, you know,

874
00:46:07,480 --> 00:46:09,000
compared to, I think, the last decade.

875
00:46:10,119 --> 00:46:12,440
And so I know that to people learning CS,

876
00:46:12,440 --> 00:46:15,320
that has caused some consternation.

877
00:46:15,320 --> 00:46:16,679
So I'm going to share my view on that.

878
00:46:16,679 --> 00:46:21,159
So it turns out that what I see in Silicon Valley

879
00:46:21,159 --> 00:46:24,119
and beyond Silicon Valley is we just can't find

880
00:46:24,119 --> 00:46:27,159
enough people with these skills, right?

881
00:46:27,159 --> 00:46:29,639
I know many businesses that would,

882
00:46:29,639 --> 00:46:32,199
well, I know large businesses that love to hire

883
00:46:32,199 --> 00:46:34,760
a thousand people with skills in gen AI

884
00:46:34,760 --> 00:46:36,679
and deep learning and machine learning,

885
00:46:36,679 --> 00:46:39,000
but that are struggling to find people with these skills.

886
00:46:40,599 --> 00:46:43,800
Conversely, there are still, you know, universities

887
00:46:44,840 --> 00:46:47,880
with curricula that has not changed since,

888
00:46:48,519 --> 00:46:51,719
has not changed much, right, for the last, like, I don't know,

889
00:46:51,719 --> 00:46:54,679
since 2002, before the rise of gen AI.

890
00:46:54,679 --> 00:46:58,760
And so I do see that many new CS drags,

891
00:46:58,760 --> 00:47:02,039
not from Stanford, but from, you know, around the country,

892
00:47:02,039 --> 00:47:06,280
are struggling with finding jobs because, unfortunately,

893
00:47:06,840 --> 00:47:12,119
that older non-AI-enabled skill set that is, you know,

894
00:47:12,119 --> 00:47:13,880
not as much in demand, right?

895
00:47:13,880 --> 00:47:17,400
And maybe just for myself, today I will not hire someone,

896
00:47:17,400 --> 00:47:19,159
I will not hire a software engineer that doesn't know

897
00:47:19,159 --> 00:47:20,920
how to use AI to help them copy.

898
00:47:20,920 --> 00:47:21,800
It just doesn't make sense.

899
00:47:22,440 --> 00:47:24,599
Same reason why I just won't hire someone

900
00:47:24,599 --> 00:47:27,159
that uses a punch card to the keyboard and terminal, right?

901
00:47:27,159 --> 00:47:29,800
And I think when the world evolved from punch card

902
00:47:29,800 --> 00:47:31,000
to keyboard and terminal,

903
00:47:31,559 --> 00:47:33,880
people still had punch card jobs for a while,

904
00:47:33,880 --> 00:47:36,440
but eventually the punch card jobs just went away.

905
00:47:36,440 --> 00:47:38,199
It just doesn't make sense anymore.

906
00:47:38,199 --> 00:47:41,880
So today, there are still coding by hand jobs around.

907
00:47:41,880 --> 00:47:44,519
Maybe some specialties, some very low-level coding

908
00:47:44,519 --> 00:47:45,480
where AI is not very good.

909
00:47:45,480 --> 00:47:48,119
So AI is not very good at some types of GPU programming.

910
00:47:48,920 --> 00:47:50,599
There are some niches with coding by hand,

911
00:47:50,599 --> 00:47:52,039
actually still make sense.

912
00:47:52,039 --> 00:47:55,639
But for building applications, you know,

913
00:47:57,400 --> 00:48:00,840
so I remember, it was just a few months ago now,

914
00:48:00,840 --> 00:48:03,719
maybe months ago now, where I interviewed two engineers

915
00:48:03,719 --> 00:48:04,280
back-to-back.

916
00:48:05,079 --> 00:48:08,760
One had not yet graduated from college,

917
00:48:08,760 --> 00:48:11,320
but was highly on top of Gen.EI coding.

918
00:48:11,320 --> 00:48:13,159
So, you know, spoke with that candidate,

919
00:48:13,159 --> 00:48:14,599
knew how to use AI, built privilege,

920
00:48:14,599 --> 00:48:15,480
get someone quickly.

921
00:48:16,199 --> 00:48:18,840
Right after that, I also interviewed someone

922
00:48:18,840 --> 00:48:21,320
with 10 years of experience as a full-stack engineer,

923
00:48:21,880 --> 00:48:23,960
but whose skill set was exactly the same

924
00:48:23,960 --> 00:48:25,880
as their 2002 skill set.

925
00:48:25,880 --> 00:48:28,280
Had not tried out any AI assistant coding,

926
00:48:28,280 --> 00:48:30,280
really good full-stack engineer

927
00:48:30,280 --> 00:48:31,480
with 10 years of experience.

928
00:48:32,199 --> 00:48:33,960
And it was actually really clear to me,

929
00:48:33,960 --> 00:48:36,119
I picked the fresh college grad,

930
00:48:36,119 --> 00:48:38,679
well, she was about to graduate,

931
00:48:38,679 --> 00:48:41,079
over someone with 10 years of experience, right?

932
00:48:41,079 --> 00:48:45,000
So I think making sure you master these skills

933
00:48:45,000 --> 00:48:46,119
are really important.

934
00:48:46,119 --> 00:48:52,039
And what I'm seeing is there is a very large gap

935
00:48:52,039 --> 00:48:54,199
that businesses are having a hard time filling

936
00:48:55,400 --> 00:48:57,559
for people with these skills.

937
00:48:57,559 --> 00:49:03,320
But the demand for the 2022 skill set,

938
00:49:04,440 --> 00:49:06,840
software engineering, full-stack engineering skill set,

939
00:49:06,840 --> 00:49:08,840
that is not there, right?

940
00:49:09,639 --> 00:49:15,880
So I think, and then in terms of AI assistant coding,

941
00:49:17,400 --> 00:49:21,800
I find that CS fundamentals really are important.

942
00:49:21,800 --> 00:49:24,599
So in addition, so I know I applied someone

943
00:49:24,599 --> 00:49:26,679
a fresh college grad over someone with 10 years of experience,

944
00:49:26,679 --> 00:49:27,880
that true story.

945
00:49:27,880 --> 00:49:29,960
There's actually one other part to this story,

946
00:49:29,960 --> 00:49:32,440
which is with respect to all of you

947
00:49:32,440 --> 00:49:33,639
about the graduate from college,

948
00:49:33,639 --> 00:49:34,760
the best programs that I know

949
00:49:34,760 --> 00:49:36,280
are also not fresh college grad,

950
00:49:36,280 --> 00:49:38,280
no disrespect intended to fresh college grads,

951
00:49:38,280 --> 00:49:39,800
some about the graduate from Stanford.

952
00:49:40,440 --> 00:49:41,559
The best programs I know

953
00:49:42,280 --> 00:49:44,599
are really on top of AI assistant coding

954
00:49:45,400 --> 00:49:46,760
and additionally,

955
00:49:46,760 --> 00:49:49,880
deeply understand computer science fundamentals, right?

956
00:49:49,880 --> 00:49:51,880
So it turns out,

957
00:49:51,880 --> 00:49:53,559
maybe I'll illustrate this with a quick story.

958
00:49:54,280 --> 00:49:55,639
When a student online calls,

959
00:49:56,920 --> 00:49:59,960
my team wanted to generate background pictures like this,

960
00:49:59,960 --> 00:50:00,920
just for decoration.

961
00:50:01,719 --> 00:50:04,199
So when I was working on this,

962
00:50:04,199 --> 00:50:06,199
this is of course Generative AI for Everyone,

963
00:50:06,199 --> 00:50:08,840
I was working for collaborator Tommy Nelson

964
00:50:08,840 --> 00:50:10,360
that understood art history.

965
00:50:11,000 --> 00:50:14,679
And so my collaborator knew the language of art.

966
00:50:14,679 --> 00:50:17,480
He knew the artistic genre inspiration, the palette,

967
00:50:17,480 --> 00:50:20,760
so he could prompt mid-journey AI image generation

968
00:50:20,760 --> 00:50:21,960
with the language of art.

969
00:50:21,960 --> 00:50:25,000
And so he could generate beautiful pictures like these.

970
00:50:25,639 --> 00:50:29,079
In contrast, I don't know art history,

971
00:50:29,079 --> 00:50:29,800
I wish I did.

972
00:50:30,519 --> 00:50:33,400
And so all I could do was go to mid-journey

973
00:50:33,400 --> 00:50:35,320
or AI image generation and type,

974
00:50:36,039 --> 00:50:38,599
please make pretty pictures of robots for me.

975
00:50:39,719 --> 00:50:41,960
And I could never get the control

976
00:50:41,960 --> 00:50:44,679
that my collaborator Tommy could

977
00:50:44,679 --> 00:50:46,360
to generate pictures like these,

978
00:50:46,360 --> 00:50:48,440
which is why we use all of his pictures

979
00:50:48,440 --> 00:50:49,239
and none of mine.

980
00:50:51,659 --> 00:50:54,300
And I'm seeing the same thing in computer science.

981
00:50:56,860 --> 00:50:59,579
One of the most important skills for the future

982
00:50:59,579 --> 00:51:02,780
is to understand how computers work

983
00:51:02,780 --> 00:51:04,619
and understand how Gene AI

984
00:51:04,619 --> 00:51:05,980
and deep learning and machine learning work

985
00:51:06,699 --> 00:51:09,340
so that you can use the language of AI,

986
00:51:09,340 --> 00:51:11,340
use the language of these tools

987
00:51:11,980 --> 00:51:14,460
to tell a computer exactly what you want

988
00:51:14,460 --> 00:51:16,860
so the computer can do it for you.

989
00:51:17,420 --> 00:51:20,460
And there is actually a huge difference in performance

990
00:51:20,460 --> 00:51:24,619
between someone that's learned to just prompt an LLM

991
00:51:24,619 --> 00:51:26,460
without understanding how computers

992
00:51:26,460 --> 00:51:28,699
or how AI really works versus people

993
00:51:28,699 --> 00:51:30,460
that can look at the problem, analyze it,

994
00:51:30,460 --> 00:51:31,980
and then with AI-sensitive coding,

995
00:51:32,699 --> 00:51:35,179
tell a computer how to take the next steps,

996
00:51:35,820 --> 00:51:37,099
which is why I think that

997
00:51:38,460 --> 00:51:41,420
CS fundamentals is very valuable.

998
00:51:41,420 --> 00:51:43,340
CS fundamentals, machine learning fundamentals,

999
00:51:43,340 --> 00:51:44,460
deep learning fundamentals,

1000
00:51:45,739 --> 00:51:48,460
I and my teams, we use that knowledge

1001
00:51:48,539 --> 00:51:52,940
every day in making pretty consequential decisions.

1002
00:51:54,139 --> 00:51:56,780
So I hope that you get that from this class

1003
00:51:56,780 --> 00:51:59,179
and the many other classes at Stanford as well.

1004
00:52:01,900 --> 00:52:02,300
All right.

1005
00:52:02,300 --> 00:52:04,380
I think I might leave the rest.

1006
00:52:04,380 --> 00:52:06,380
There's more I could say on trends in AI,

1007
00:52:06,380 --> 00:52:10,300
but I find that AI-sensitive.

1008
00:52:10,300 --> 00:52:11,659
Oh, but one thing I hope you do,

1009
00:52:12,780 --> 00:52:14,940
go to all your friends in all the departments

1010
00:52:14,940 --> 00:52:18,219
across campus and encourage them to be a builder.

1011
00:52:18,780 --> 00:52:19,980
The other thing I'm seeing is

1012
00:52:20,860 --> 00:52:23,179
clearly for computer science professionals,

1013
00:52:23,179 --> 00:52:25,579
use AI-sensitive coding, no CS fundamentals,

1014
00:52:26,619 --> 00:52:27,420
build cool stuff.

1015
00:52:28,300 --> 00:52:30,380
But for other disciplines as well

1016
00:52:31,099 --> 00:52:33,420
that is not computer science or not AI,

1017
00:52:33,420 --> 00:52:37,500
I'm finding that the education professional

1018
00:52:37,500 --> 00:52:41,420
or the climate scientist or the mechanical engineer,

1019
00:52:41,420 --> 00:52:43,980
the ones that know how to build software

1020
00:52:45,019 --> 00:52:47,579
are just more productive and get a lot more done.

1021
00:52:47,739 --> 00:52:49,900
And the barrier to entry to AI,

1022
00:52:49,900 --> 00:52:52,940
to coding is the lowest it's ever been in our lives.

1023
00:52:52,940 --> 00:52:54,940
And so this is a good time, frankly,

1024
00:52:54,940 --> 00:52:59,099
for I wish every single Stanford student

1025
00:52:59,099 --> 00:53:02,139
that will learn to build software with AI assistance.

1026
00:53:02,139 --> 00:53:05,340
So I hope you go help your friends across campus

1027
00:53:06,380 --> 00:53:07,820
to master those skills as well.

1028
00:53:08,539 --> 00:53:09,039
Okay.

1029
00:53:10,380 --> 00:53:10,880
Oh, yeah.

1030
00:53:11,820 --> 00:53:12,619
Any other questions?

1031
00:53:13,980 --> 00:53:14,480
Go ahead.

1032
00:53:44,179 --> 00:53:50,139
Just because they have more.

1033
00:53:50,139 --> 00:53:52,139
So let me rank productivity, right?

1034
00:53:52,139 --> 00:53:53,500
And I'll give you four levels.

1035
00:53:53,500 --> 00:53:54,780
I think, and again,

1036
00:53:54,780 --> 00:53:56,780
and I say this with a lot of respect for individuals,

1037
00:53:56,780 --> 00:53:58,139
so if I talk about productivity,

1038
00:53:58,139 --> 00:54:00,860
it's not with any disrespect or any lack of affection

1039
00:54:00,860 --> 00:54:02,619
for anyone or for their work, right?

1040
00:54:02,619 --> 00:54:04,539
But I think, you know, least productive

1041
00:54:04,539 --> 00:54:07,579
are people with no experience and don't know AI, right?

1042
00:54:08,940 --> 00:54:12,860
One step on top of that is people with less experience,

1043
00:54:12,860 --> 00:54:16,219
but on, sorry, one step on top of that

1044
00:54:16,219 --> 00:54:19,820
is people with say a decade of experience,

1045
00:54:19,900 --> 00:54:21,500
but that don't know AI.

1046
00:54:23,179 --> 00:54:24,380
On top of that,

1047
00:54:24,380 --> 00:54:27,260
I would rather take a fresh college grad that does know AI,

1048
00:54:27,900 --> 00:54:30,300
but then even more productive is someone with,

1049
00:54:30,300 --> 00:54:31,900
you know, a decade of experience

1050
00:54:31,900 --> 00:54:33,500
and also really on top of AI.

1051
00:54:34,219 --> 00:54:35,820
So I think between the two factors,

1052
00:54:36,539 --> 00:54:39,659
really understanding AI is very important,

1053
00:54:39,659 --> 00:54:41,900
but experience is also important.

1054
00:54:41,900 --> 00:54:43,500
And so the best developers I know,

1055
00:54:45,260 --> 00:54:47,019
we just work and we just ship code

1056
00:54:47,019 --> 00:54:49,900
like no one's ever done, I think,

1057
00:54:49,900 --> 00:54:51,019
even two, three years ago,

1058
00:54:51,019 --> 00:54:52,780
are very experienced developers.

1059
00:54:52,780 --> 00:54:55,179
They're also very on top of how they use

1060
00:54:55,179 --> 00:54:56,699
the latest AI technologies.

1061
00:55:00,739 --> 00:55:02,739
Oh, sorry, and just one other thing about the job market.

1062
00:55:02,739 --> 00:55:03,940
I find that a lot of employers

1063
00:55:03,940 --> 00:55:06,420
have not yet figured out how to hire appropriately.

1064
00:55:06,420 --> 00:55:07,300
This is contributing.

1065
00:55:07,300 --> 00:55:08,340
Frankly, a lot of employers,

1066
00:55:08,340 --> 00:55:10,579
you know, if a company has no one that knows gen. AI,

1067
00:55:10,579 --> 00:55:12,579
how do they even know how to interview appropriately?

1068
00:55:12,579 --> 00:55:14,659
So that is a problem that we need to solve as well.

1069
00:55:36,619 --> 00:55:37,579
Yeah, boy.

1070
00:55:37,579 --> 00:55:40,300
So CS 117, CS 111 are great.

1071
00:55:41,260 --> 00:55:43,900
So do take them if you're considering them.

1072
00:55:43,900 --> 00:55:45,980
I find that the fundamentals are important.

1073
00:55:49,659 --> 00:55:50,300
How do I put it?

1074
00:55:51,420 --> 00:55:53,099
Yeah, I'm not sure what else to say other than that.

1075
00:55:53,659 --> 00:55:56,699
I think honestly Stanford were known for,

1076
00:55:57,500 --> 00:55:59,260
CS department were known for really,

1077
00:56:00,619 --> 00:56:02,139
I know I'm biased, but I want to say

1078
00:56:02,139 --> 00:56:04,619
that probably the best entry-level CS program classes

1079
00:56:04,619 --> 00:56:05,739
of any university in the world,

1080
00:56:05,739 --> 00:56:07,820
I'm pretty biased, so I shouldn't say that.

1081
00:56:07,820 --> 00:56:09,659
But I think they're excellent courses

1082
00:56:09,659 --> 00:56:11,099
if you want to learn the fundamentals

1083
00:56:11,099 --> 00:56:12,059
in a really solid way.

1084
00:56:12,059 --> 00:56:14,699
And I know the instructors are routinely thinking

1085
00:56:14,699 --> 00:56:15,980
about how to update the curriculum

1086
00:56:15,980 --> 00:56:17,659
and realities of gen. AI.

1087
00:56:17,659 --> 00:56:20,380
So I think they do an excellent job with that mix.

1088
00:56:31,980 --> 00:56:34,059
Yeah, how do I define someone that really knows gen. AI

1089
00:56:34,059 --> 00:56:35,179
compared to someone that just uses

1090
00:56:35,179 --> 00:56:36,139
two different types of problems?

1091
00:56:36,139 --> 00:56:38,539
So I feel like in gen. AI,

1092
00:56:38,539 --> 00:56:40,059
there are two buckets of skill.

1093
00:56:40,780 --> 00:56:42,860
And again, by the way, deep learning is not gen. AI.

1094
00:56:42,860 --> 00:56:44,300
Deep learning is also a very valuable skill.

1095
00:56:44,300 --> 00:56:45,579
But since you asked about gen. AI,

1096
00:56:45,579 --> 00:56:46,380
I think there are two things.

1097
00:56:46,380 --> 00:56:48,619
One is I find it really useful

1098
00:56:48,619 --> 00:56:51,739
to know how to use AI coding assistance

1099
00:56:51,739 --> 00:56:52,780
that's really valuable.

1100
00:56:54,219 --> 00:56:58,460
But having fundamental knowledge helps you do that.

1101
00:56:58,460 --> 00:57:00,139
And then the other thing is in gen. AI,

1102
00:57:00,139 --> 00:57:01,820
there's a number of emerging tools.

1103
00:57:01,820 --> 00:57:03,260
I'm going to toss up some buzzwords, okay?

1104
00:57:03,260 --> 00:57:05,260
So if you don't know what any of these words mean,

1105
00:57:05,260 --> 00:57:05,980
don't worry about it.

1106
00:57:06,619 --> 00:57:10,539
But I think there are emerging tools like RAG,

1107
00:57:10,619 --> 00:57:13,980
ritual augmented generation, or vector databases,

1108
00:57:13,980 --> 00:57:15,980
how to do evals and error analysis,

1109
00:57:15,980 --> 00:57:17,179
how to build guardrails,

1110
00:57:17,900 --> 00:57:19,739
how to use knowledge draws,

1111
00:57:19,739 --> 00:57:21,340
interface that with your OOM,

1112
00:57:21,340 --> 00:57:22,940
maybe how to do multimodal OOMs,

1113
00:57:22,940 --> 00:57:24,139
how to fine-tune the model.

1114
00:57:25,420 --> 00:57:25,820
What else?

1115
00:57:25,820 --> 00:57:27,099
I'm probably blanking on something.

1116
00:57:27,099 --> 00:57:28,860
How to build agentic workflows.

1117
00:57:28,860 --> 00:57:31,099
But I feel like there are these categories

1118
00:57:31,099 --> 00:57:34,300
of new techniques built on top of gen. AI

1119
00:57:34,300 --> 00:57:37,659
that are like a useful bag of tools

1120
00:57:37,659 --> 00:57:39,099
for building applications.

1121
00:57:39,900 --> 00:57:41,980
Well, frankly, when I'm interviewing candidates,

1122
00:57:41,980 --> 00:57:43,340
we still do a fair amount of.

1123
00:57:43,340 --> 00:57:45,820
It is for a gen. AI role.

1124
00:57:45,820 --> 00:57:47,980
It's these skills I tend to look for.

1125
00:57:47,980 --> 00:57:50,780
This set of tools as well as AI-assisted coding.

1126
00:57:51,579 --> 00:57:52,780
And then, yeah.

1127
00:57:54,460 --> 00:57:55,420
Yeah, please.

1128
00:57:55,420 --> 00:57:56,860
I don't know if this question is best

1129
00:57:56,860 --> 00:58:09,429
if I'm considering taking 20 minutes.

1130
00:58:09,429 --> 00:58:11,510
Yeah, so let me just give one tip

1131
00:58:11,510 --> 00:58:13,110
about CS causes in general,

1132
00:58:13,110 --> 00:58:15,510
not just 239 and CS 230,

1133
00:58:15,510 --> 00:58:17,510
which is I encourage you to think of

1134
00:58:18,070 --> 00:58:22,150
AI causes at Stanford that have been like Pokemon.

1135
00:58:23,190 --> 00:58:24,309
You've got to catch them all.

1136
00:58:26,789 --> 00:58:27,989
But in all seriousness,

1137
00:58:27,989 --> 00:58:29,989
I think taking more CS causes in AI,

1138
00:58:29,989 --> 00:58:31,110
it is a good thing to do.

1139
00:58:31,110 --> 00:58:33,750
Definitely encourage you to take multiple causes.

1140
00:58:33,750 --> 00:58:34,789
I think in some years,

1141
00:58:34,789 --> 00:58:36,630
we've had students do joint projects

1142
00:58:36,630 --> 00:58:38,070
where the standard is higher,

1143
00:58:38,070 --> 00:58:39,829
higher expectations for sure.

1144
00:58:39,829 --> 00:58:43,510
But that's one option to look at.

1145
00:58:45,030 --> 00:58:46,469
All right, go for it.

1146
00:58:46,469 --> 00:59:00,039
Oh, so let's see.

1147
00:59:00,039 --> 00:59:02,039
239 and 230 are very different causes.

1148
00:59:02,920 --> 00:59:05,559
239, well, in 239,

1149
00:59:05,559 --> 00:59:06,760
we have live instructors

1150
00:59:07,960 --> 00:59:09,400
doing the lectures in person

1151
00:59:09,400 --> 00:59:10,679
rather than online content.

1152
00:59:10,679 --> 00:59:12,039
So it's not the flip classroom.

1153
00:59:12,039 --> 00:59:13,159
So in CS 230,

1154
00:59:14,280 --> 00:59:16,360
we have most of materials prepared

1155
00:59:16,360 --> 00:59:17,559
kind of in online videos,

1156
00:59:17,559 --> 00:59:18,840
highly edited online videos.

1157
00:59:19,800 --> 00:59:24,199
And then, I think the other biggest difference is

1158
00:59:24,199 --> 00:59:27,400
CS 239 is more mathematical, theoretical,

1159
00:59:27,400 --> 00:59:28,840
but it's important math, right?

1160
00:59:29,239 --> 00:59:31,960
Whereas CS 230 is more practical.

1161
00:59:31,960 --> 00:59:35,079
And so I don't know if we do even want a single,

1162
00:59:35,079 --> 00:59:37,480
maybe we do like one proof somewhere in the lectures,

1163
00:59:37,480 --> 00:59:40,840
but we just don't do a lot of math in CS 230.

1164
00:59:40,840 --> 00:59:41,559
And it's very,

1165
00:59:41,559 --> 00:59:43,320
a lot of machine learning is very empirical.

1166
00:59:43,320 --> 00:59:44,519
You try and see what works,

1167
00:59:44,519 --> 00:59:46,199
but have a disciplined approach

1168
00:59:46,199 --> 00:59:47,320
for exploring what works.

1169
00:59:47,320 --> 00:59:50,679
So we focus a lot more on that in CS 230.

1170
00:59:50,679 --> 00:59:53,719
And oh, and 239 covers a lot more techniques, right?

1171
00:59:53,719 --> 00:59:55,800
So there are a lot of machine learning techniques,

1172
00:59:55,800 --> 00:59:57,320
supervised learning, supervised learning,

1173
00:59:57,400 --> 00:59:59,960
you know, decision trees boosting,

1174
01:00:00,760 --> 01:00:02,119
k-means clustering.

1175
01:00:02,119 --> 01:00:05,079
So CS 229 covers a much broader survey

1176
01:00:05,079 --> 01:00:07,000
of a lot of machine learning techniques,

1177
01:00:07,000 --> 01:00:09,000
whereas CS 230 is just one thing.

1178
01:00:09,000 --> 01:00:11,159
Well, we go really deep into deep learning.

