What I want to do today is chat with you about career advice in AI and
In previous years, I used to do most of this, you know lecture by myself
But what I thought I'd do today is I'll share just a few thoughts and then hand it over
It's my good friend Lawrence Moroney who I invited to speak here and kindly agreed to come all the way to San Francisco
He lives in Seattle to share with us a very broad
Market landscape for what he's seeing in the job market as well as tips for
career, growing a career in AI
But there were just some two slides and then one more thought that I want to share with you before I hand it over
to Lawrence, which is
It really feels like the best opportunity
The best time ever to be building with AI and to building a career in AI
A few months ago, I know that in social media, traditional media
There are a few questions about you know, is AI slowing down, right?
I feel saying well is GPT-5 that good?
I think that's pretty good
But there are questions about this AI progress slowing down and I think part of the reason the question was even raised was
Because if a benchmark for AI is you know, 100% is perfect answers
Then if you make rapid progress at some point you cannot get above 100% accuracy
but
One of the studies that most influenced my thinking was work done by this organization METR meter that studied
as time passes
How complex are the tasks that AI could do as measured by how long it takes a human to do that task?
So a few years ago, maybe GPT-2 could do tasks that a human could do in like, you know
a couple seconds and then they could do tasks that took a human four seconds then eight seconds then
Like a you know a minute two minutes four minutes and so on and
The study estimates that the length of task AI can do is doubling every seven months
And I think on this metric I feel you know
Optimistic that AI will continue making progress meaning the complexity of tasks as measured by how long a human takes to do something
Is doubling rapidly and same study with smaller data set
Seems the same study argued that AI coding the doubling time is even shorter maybe like 70 days
So this code they used to take me, you know
I don't know 10 minutes at right then 20 minutes at right 40 minutes at right and AI could do more and more of that
And so the reasons I think this is a golden age to be building the best time we've ever seen is
Maybe two themes which are more powerful and faster
So we can all all of you in this room can now write software
That is more powerful than what anyone on the planet could have built, you know, like a year ago
By using AI building blocks and building blocks including large-anguage models
Ragged agenda workflows voice AI and of course deep learning
It turns out that a lot of LMS have a decent at least basic understanding of deep learning
So you ever prompt one of the frontier models to implement a cutting-edge neural network for you
They probably try prompting it to you know implement the transformer network for you
It's actually not bad at hoping you use these building blocks to build software quickly
Um, and and and so we have very powerful
Building blocks that were very difficult or did not exist a year or two ago
And so you can now build software that does things that no one else on the planet, right?
even the most advanced teams the planet could have done and then also with
AI coding the speed with which you can get software written is much faster than ever before and
I've personally found it is important to stay on the frontier of tools because the tools for AI coding changes, right?
I don't know very really rapidly. So I feel like
You know since several months ago my personal number one favorite to became cloud code
Moving on from some early generations
I think and then I think since the release of GPT-5
I think open a codex has actually made tremendous progress and this morning Gemini 3 was released
Which you know haven't had time to play with just this morning, right?
It seems like another huge leap forward
So I feel like if you ask me every three months what my personal favorite coding tool is it actually probably changes
Definitely every six months, but quite possibly every three months and I find that
Being half a generation behind in these tools means being frankly quite a bit less productive
And I know everyone says AI is moving so fast or engineering so fast
But AI coding tools of all the sectors in AI many things
Maybe don't move as fast as the hype says it does but AI coding tools is one sector where I see the pace of
Progress is is tremendous and staying at the latest generation of tools rather than half generation behind
makes you more productive and
With our ability to build more powerful software and build it much faster than ever before I
Think one piece of advice that gives now much more strongly now than even a year ago or two years ago
It's just going to build stuff right take classes from Stanford take online courses and additionally
Your opportunity to build things and I think Lauren's gonna talk about showing them to others is greater than ever before
But there's one weird
Implication of this that
Is maybe not is it's still I don't know more and more people are appreciating it
But not widely known which is the product management bottleneck, which is that when it is
Increasingly easy to go from a clearly written software spec to a piece of code
Then the bottleneck increasingly is deciding what to build or increasingly writing that clear spec for what you actually want to build
When I'm building software I often think of going through a loop where we'll write some software write some codes
Sure to use this to get user feedback
I think of this as a PM or product management work and then based on the user feedback of you know
Revise my view on what users like what they don't like this UI is too difficult. They want this feature
they don't want that feature and
change my conception of what to build and then go around this loop many times to hopefully iterate to other product that users love and
Because of AI coding
The process of building software has become much cheaper and much faster than before
but that
Ironically shifts the bottleneck to deciding what to build
so
Some weird trends I'm seeing in Silicon Valley and in many tech companies people have often talked about a
Engineer to product manager and gender PM ratio and you know
You take these ratios of grain of salt because they're kind of very over the place
But you hear companies talk about the edge to PM ratio of like four to one or seven to one or eight to one
This idea that one product manager writing product specs can keep you know, like four to eight or some number like that
Engine is busy
But because engineering speeding up whereas product management is not sped up as far as much by AI as engineering
I'm seeing the edge to PM ratio trending downwards. Maybe even two or one to one, right?
so some teams I work with their proposed hit counts was like 1 p.m. To 1 engineer, which is a
Ratio unlike almost all Silicon Valley. So the traditional Silicon Valley companies and the other thing I'm seeing is that
engineers they can also
Shape products can move really fast where you go one step further
Take the engineer take the p.m. And collapse them into a single human and I find that
They're definitely engineers that like doing engineering work that you know
Don't enjoy talking to users and having that more human empathetic side of work
but I'm finding increasingly that the subset of engineers that learn to
Talk to users get feedback develop deep empathy for users
So that can make decisions about what to build those engineers also the fastest moving people that I'm seeing
in Silicon Valley today and I
Feel like at the earliest stage of my career one thing I regretted for years was
In one of the rows I had I went to try to convince a bunch of engineers to do more product work
And I actually made a bunch of really good engineers feel bad for not being good product managers
And that was a mistake. I may regret to that for years
I just shouldn't have done that and part of me feels like I'm now going back to repeat that exact same mistake
Having said that I find that
The fact that you know
I can write code
But also talk to users to shape what to do that lets me and the engineers that can do this go much faster
so I think maybe worth taking another look at whether
engineers can
Do a bit more of this work
Because then if you're not waiting for someone else to take the product to customers
You just write code have a gut for what to do next and iterate that pace that velocity of execution is much faster
and then the final of Lawrence just just one one one last thing I want to share which is
in terms of
Navigating your career
I think one of the most strong predictors for your speed of learning and for your
Level of success is the people you surround yourself with I think we're all social creatures
we all learn from people around us and
It turns out that
It turns out there are you know studies in sociology they show that right if your five closest friends are smokers
The odds of you being a smoker is pretty much higher. Please don't smoke
Just just just an example
I don't know of any studies showing that if your five or ten closest friends are really hard-working
Determine people, you know
Learning quickly trying to make the world a better place of AI that you are more likely to do that, too
But it's one of those things that I think is almost certainly true say all of us inspired by the people around us
They were able to find a good group of people to work with that helps drive you forward
In fact here at Stanford. I feel very fortunate right the fantastic student body fantastic group of faculty
and then the other thing that I
Think we're fortunate to have a Stanford is a connective tissue. So, you know candidly a lot of the
People working and a lot of the cutting edge AI labs the frontier labs
They were former students of a lot of different Stanford faculty
And so that rich connective tissue, you know candidly means that at Stanford
We often find that about a lot of stuff
That's not widely known because of the relationships their friendships and when some company does something
You know one of my friends and the faculty will call up someone to come to say hey, that's weird
Does this really work and then so that really rich connective tissue means that
We're all just as we try to pull our friends forward our friends also pull us forward with the knowledge and the connective tissue and this
know-how of
Bleeding as AI which unfortunately is not all published on the internet at this moment in time. So so I think while you're Stanford
make those friends form that rich connective tissue and they've been a lot of times that just for myself where
Frankly, I was thinking of going in some technical direction
I'd have you know one or two phone calls with someone right really close to research either a separate researcher or someone the frontier lab
They would share something with me right that I didn't know before and that changes the way I
Choose the technical architecture of a project
So I find that that group of friends you surround yourself with those little pieces of information try this don't do that
That's just hype ignore the PR, you know, don't don't actually try that thing those things
Make a big difference in your ability to
Steer the direction of your projects
So so while you're Stanford take take advantage of that disconnected tissue the Stanford has it's actually really unique
There are lots of great universities in the world, but at this moment in time
I don't think there's any any I don't sound like I'm doing PR for Stanford now
But I really think there's no university in the world that is
As privileged as Stanford at this moment in time in terms of the richness of the connective tissue to all of the leading
AI groups
but to me that does also that we're lucky here to have a wonderful community of people to work with and learn from and
For you, too. If you apply for jobs
The thing that is much more important for your career success would be if you go to company
It'll be the people you work with day to day, right?
so
here's one story that
That I've told the previous cause of a repeat which is a
There's a Stanford student that I knew there's many years ago that I knew and they did really good work at Stanford
I thought they were high-flier and they apply for a job at a company
And they got a job offer from one of the companies with you know, a hot AI brand
This company refused to tell him which team he would join they say oh come sign up for a job
There's a rotation system matching system blah blah blah sign on the dotted line for us then, you know, we'll figure out
What's a good project for you?
Partly because you know, it's a good good company, right?
His his parents are proud of him for getting a job in this company
The student joined this company hoping to work on exciting AI project and off the sign on dotted line
He was assigned to work on the back-end Java payment processing system of the company
Nothing against anyone that wants to do Java back-end payment processing systems. I knew they're great
but this is AI students that did not get matched to an AI project and
So for about a year he was really frustrated and he actually left this company after about a year
the
unfortunate thing is I told this story in CS 230 some years back and then
After I was already telling the story in this class a
couple years later another student
In CSU 30 went through the same experience with the same company not Java back-end payment processing for a different project
and I think this effect of
Trying to figure out who you'd be actually working with day-to-day and making sure you're surrounded by people that inspire your work on
Exciting projects. I think that's important and even completely candid if a company refuses to tell you what team you'd be assigned to
You know that that that does raise a question in my mind, right?
Of whether or not you know what will happen and I think that instead of working for the company with the hottest brand
Sometimes if you find a really good team with really, you know hard-working knowledgeable smart people trying to do good with AI
But the company logo just isn't as hot
I think that often means you actually learn faster and progress your career better because it is after all we don't learn from the
You know
Excitement that a comfy logo when you walk through the door you learn from the people you deal with day-to-day
So I just urge you to use that as a as a huge
Criteria for your selection process for for what you decide to do, right?
and I think and then but I think number one on my
Advice is it's become much easier than ever before to build powerful software faster
And what that means is I'm do be responsible don't build software that hurts others
And at the same time there are so many things that each of you can build
And what I find is the number of ideas out in the world is much greater than number of people of the skill
To build them
So I know that finding jobs has gotten tougher for fresh college grads at the same time
Lot of teams, you know, we just can't find enough skilled people, right? Oh, and so
There are a lot of projects in the world that if you don't build it
I think no one else would build it either
So you don't need to so as you don't harm others, you know to be responsible
There are a lot of things that you don't need to wait for permission
You don't need to wait for someone else to do it for us and then you do it
The cost of a failure is much lower than before because you waste a weekend
But learn something that seems fine to me
So I think so has it being responsible going for trying things out and building lots of things
Would be the number one most important thing I think would help your careers and
Yeah, I think I think I'm gonna say one last thing that is
Considered not politically correct in some circles
But I'll just say it anyway, which is in some circles. It has become
Considered not politically correct to encourage others to work hard
I'm gonna encourage you to work hard
Now I think the reason some people don't like that is because there are some people they're in a phase of life where they're not in
A position to work on so rather than my children were born. I was not working hard
You know for a short period of time, right and there are people because of an injury disability
You know, whatever very valid reasons are not in a position to work on at that moment in time and we should respect them
Support them make sure they're well taken care of even though they're not working on
Having said that all of my you know, say PhD students that became very successful
I saw every single one of them work incredibly hard
I mean the 2 a.m. Sitting up hyper parameter tuning, you know been there done that right still doing it some days
And if you are fortunate enough to be in a position in life where you can work really hard
There are so many opportunities to do things right now
If you get excited as I do spending evenings and weekends coding and building stuff and getting user feedback
You know if you lean in and do those things it will increase your odds of being really successful
So I don't know maybe I get in some trouble with some people encouraging to work hard
But I find that the truth is people that work hard get a lot more done
We should also respect people that don't and people that aren't in the position to do so but
You know between watching some dumb TV show
Versus find your agent a coder on a weekend to try something. I'm gonna choose the latter almost every time, right?
Unless I watch a show like it sometimes I do that. But you mean business, you know
Besides I I hope you do that
All right, so those are the main things I want to say
What I want to do is hand the stage over to my good friend Lawrence Maroney of who who who share
A lot more about career advice on AI me just quick intro. No Lawrence for a long time
Still a lot of online education work sometimes with me and my teams taught a lot of people tens of flow
Tell a lot of people pie torch. I use lead AI advocates at Google for many years now runs the group at arm
I've also enjoyed quite a few of his books. This is one of them
He recently also published a new book on pie torch
This is an excellent book introduction to pie torch and there's a very sought-after
Speakers in many circles, so I was very grateful when he agreed to come speak to us. So pleasure's all mine
I just want to reinforce something that Andrew was talking about earlier on about choosing the people that you work with being very
important
But I also want to show that like from the other way around that the company when they're interviewing you are also
Choosing you and the good companies really want to choose the people that they work with also
And I've been doing a lot of mentoring of young people over the last particularly over the last 18 months
Who are hunting for careers for themselves and I want to tell the story of one young man and this this guy
very well educated
great experience
super lead coder
He could do every challenge that was in front of him and he got laid off from his job in April
He worked in medical software and medical software business has been changing drastically
funding has been cut by the federal government in a number of areas and he got laid off from his job and
With his experience with his ability with his skills all of these kind of things
He thought that would be very easy for him to find another job and the poor young guy had a really terrible April
Like he got laid off from his job in April
Immediately before that his girlfriend had broken up with him and then a couple of weeks later his dog died
So he was not in a good place
and so I sat down with him after a couple of months and
Took a look and he had a spreadsheet of jobs that he was applying to and he had over 300 jobs that he was
Tracking in the spreadsheet and in a number of these jobs
He actually got into the interview process and he went very deep in the interview process with companies like meta
Who else not Google was meta there was Microsoft
there was one of the other large tech companies where you do like lots and lots of interview loops and
Every time towards the end of the loop. He knew he did a great loop. He solved all the coding
He had great conversations with the people or at least he thought he had and then every time within a day
the recruiter will call him and say no you didn't get the job and
It was like it was it was heartbreaking
Like I said 300 plus jobs. He had been tracking
So I started working with him to kind of do some mock interviews and to do some fine-tuning
Always it was Jeff Bezos company not Amazon
That was one of the other big tech company that he'd interviewed with and I started like working through him and doing some
Test interviews and all this kind of thing with him and terrific terrific candidate couldn't figure out what was going wrong
Until I decided to try and do a different sort of interview where I gave him a really tough interview
I gave him some tough lead code
I gave him some really obscure corner cases in his coding and
I saw how he reacted and how he reacted was the advice that was given to him in the recruiting pamphlets
and a lot of these recruiting pamphlets will say things like you're gonna have an up at you're gonna have a
An opportunity to share an opinion and you got to stand your ground you got to have a backbone don't bend
His interpretation of that was to be really really tough
Right, so I would pick corners and hit out of pick holes in his code
I'd pick corner cases where things may not work and I'll give him a test of crisis and this advice that he'd been
given to stand his ground ended up making him kind of hostile in these interview environments and
I was looking at this then from the point of view of what Andrew was just talking about where it's a case of hey
Good people good teams people that you can work together with and from the interviewer perspective if I'm managing this team
This person is that cliched 10x engineer, but I don't want him anywhere near my team because of this attitude
We worked on that we fine-tuned it and that the strange part is he's a really really nice guy
It's just this was the advice he was given and he followed that advice and he failed so many interviews as a result
so when I gave him the next job that he was interviewing at was at a company where teamwork is very very highly valued and
The good news is he got the job at that company. He's now working there
He doubled his salary from the job
He was laid off from and he ended up having like about now
He looks back and he had six months of fun employment
But at the time when he was going through all of that it was a very very difficult time for him
so the flip side of it like if you're looking at a company and looking at the people you'll be working with is very very
important but also realize they are looking at you in the same way and so if you've gone to
Tech interview coaching and they gave you that advice to stand your ground and have a backbone
It's good to do that, but don't be a jerk while you're doing so
Can you see my slides? Okay, so I'm Lawrence
I've been working in tech for more decades than chat GP thinks there are ores in strawberry
And so I've worked in many of the big tech companies
I spent many years at Microsoft spent many years at Google also worked in places like Reuters
I've done a lot of work in startups both in this country and abroad
And so what I want to really want to talk about today is like to think about what does the career landscape look like today?
particularly in AI because first of all what Andrew said about you're in Stanford, you've got the ability to
Make use of the networks that you have in Stanford make use of the prestige that you have and I say use every weapon you
Have because unfortunately the landscape right now is not ideal
We've gone through some very difficult times. All you have to do is look at the news and you can see
massive tech layoffs
Slowing hiring in tech and lots of stuff like that, but it's not necessarily a bad thing
If you do it the right way, so I want to just have a quick look the job market reality check
Actually out of interest I don't know this is a are you juniors you're graduating this year or you're graduating next year or
What is the general survey your third year of four?
Third year of three. I'll say so you're gonna be graduating coming summer. How many people are already looking for jobs
Okay, quite a few of you how many people have had success
Nobody oh one, okay sort of okay, that's good
So like you're probably seeing some of these things the signals out there junior hiring slowing significantly when I say junior
I mean like graduate level
High-profile layoffs are dominating the headlines
I was at Google a couple of years ago when they had the biggest layoff they'd ever had
We're seeing layoffs at the likes of Amazon Microsoft other companies like that
It feels that entry-level positions are scarce and I'm underlying the word high-profile
Feels there and I want to get into that in a little bit more detail later and also competition is fierce
But my question is should you worry and I say no
Because if you can approach things in the right way if you can approach the job hunting thing in the right way
Particularly understanding how rapidly the AI landscape is changing then I think people with the right mindset will thrive
So what do I mean by that?
So as Andrew had mentioned the AI hiring landscape is changing because the AI industry is changing
right the AI industry I I
Actually first got involved in AI back it way back in 1992
I worked in it for a little while just before the AI winter everything failed so drastically
but I got bitten by the AI bug and then in
2015 when Google were launching tensorflow
I got pulled right back into it became part of the whole AI boom
launching tensorflow advocating tensorflow to millions of people and seeing the changes that happened, but
along
2021 2022 we had a global pandemic the global pandemic caused a massive industrial slowdown
This massive industrial slowdown meant that companies had to start pivoting towards things that drove revenue and directly drove revenue
And at Google tensorflow was an open source product
It didn't directly drive revenue we began to scale back every company in the world also scaled back on hiring at this time
Then we get to about 2022 2023 what happens we begin to come out of the global pandemic
we begin to realize all industries have this massive logjam of non hiring that they had done or hiring that they hadn't done and
We're also entering a time where AI was exploding on the scene. Thanks to the work of people like Andrew
The the world was pivoting and changing to be AI first and just about everything and every company needed to hire like crazy
Every company then hiring like crazy in 2022 2023 meant that most companies ended up over hiring
So and what that generally meant was people who were not qualified for higher positions
Usually got higher positions because you had to enter into a bidding war just to be able to get talent
You ended up having talent grabs and you ended up having stories like the one Andrew told
Where it's a case of here's a person with AI talent. Let's grab them. Let's throw money at them
Let's have them come work for us and then we'll figure out what we want to do
So as a result 2022 2023 all of this massive over hiring happens because of AI and because of the COVID
Logjam and then 2024 2025 is the great wake up, right?
Where a lot of companies realize this over hiring that they had done
They have ended up with a lot of people who are under qualified
I'm sorry
Yeah under qualified for the job that they were doing a lot of people ended up getting hired just because they had AI on
Their resume and there's a big adjustment going on and in the light of this big adjustment
Show you just one second in the light of this big adjustment. You're not seeing my slides. Okay
And in the light of this big adjustment, there we go
I think it's because my power I'm not plugged into power mains and in the light of this big adjustment
Then what has happened is now a lot of companies are much more cautious
About AI skills that they're hiring and if you're coming into that with that mindset and understanding that realize
Opportunity is still there and opportunity is there massively if you approach it strategically
So what I want to talk through today is how you can do exactly that
So I see three pillars of success in the business world and particularly in the AI business world and nowadays
You can't just have AI on your resume and get over hired
Nowadays, not only do you have to be able to tell that you have the mindset of these three pillars of success
but you also have to be able to show and
To be able to show these that actually has never been a better time as
Andrew demonstrated earlier on the ability to vibe code things into existence. He doesn't like the word vibe code
I kind of agree with him, but the ability to prompt things into existence or whatever the word is that we want to use
Allows you to be able to show better than ever before
He was talking earlier on about product managers and he had this time when he got engineers to be product managers
And then those engineers ended up being really bad product managers. I actually interviewed at Google twice and failed twice
Despite being very successful at Microsoft
authored 20 plus books taught college courses
I interviewed at Google twice and failed twice because I was interviewing to be a product manager
Then when I interviewed to be an engineer they hired me and they were like
Why didn't you try to join us years ago, you know, so a lot of it is like just you know being a good engineer
You've got the ability to do that and show that nowadays and with that ratio of engineer to product manager changing
Engineering skills are also far more valuable than ever. So the three pillars to success number one understanding in depth
And I'm going to mean this in two potential two different ways
number one is academically right to have the understanding in depth academically of
Machine learning of particular model architectures to be able to understand them to be able to read papers to be able to
Understand what's in those papers and to be able to understand in particular how to take that stuff and put it to work
the second part of an understanding in depth is really having your finger on the pulse of
Particular trends and where the signal to noise ratio
Favors signal in those trends and I'm going to be going into that in a lot more detail a little bit later
Secondly and also very very importantly is business focus
So Andrew said something politically incorrect earlier on I'm going to also say a similar politically incorrect thing. First of all a hard work
Hard work is
Such a nebulous term that I would say that think about hard work in terms of you are what you measure
There is the whole trend out there. I'm trying to remember is it nine nine six or is it six six nine nine six
Right 9 a.m. To 9 p.m. Six days a week is a metric of hard work. It's not there's not a metric of hard work
That's a metric of time spent
So I would encourage everybody in the same way as Andrew did to think about hard work
But what hard work is is how you measure that hard work, you know
You can work eight hours a day and be incredibly productive
You can work six hours a day and be incredibly productive
But it's the metric of how hard you work and how you measure that
I personally measure that from output things that I have created in the time that I spent
I joke a lot, but it's true that I've written a lot of books
Andrew held up one that one that he held up that he helped me write a little bit
I actually wrote that book in about two months and people say well, how do you have time?
We have jobs and all these kind of they have you must work like 16 hours a day in order to be able
To do this, but actually the key to me being able to write books is baseball
Any baseball fans here?
I love baseball, but if you sit down and try to watch baseball on TV a match can take like three and a half
Or four hours. So all of my writing I tend to do in baseball season
So I'm like if I'm gonna sit down. I like the Mariners from I'm from Seattle. I like the Dodgers
Nobody booed. Okay good and you know, so like usually one of those is gonna be playing at seven o'clock at night
So instead of sitting in front of the TV just like watching baseball mindlessly
I'll actually be writing a book while baseball's on in the background
It's a very slow-moving game. This is something like that's the hard work
You know in this case and I would encourage you to try to find areas where you can hard work hard and produce
Outputs and that's the second pillar here is that business focus the output that you produce to align that output
With the business focus that you want to have and with the work that you want to do
There's an old saying don't dress for the job. You have dress for the one you want
I would say a new angle on that saying would be don't let your output be for the job
You have let your output be for the job you want
And if I go back to when I spoke about I failed twice at Google to get in the third time when I got in
I'd actually decided to do to approach this in a different way and I was interviewing at the time for their cloud team
They were just really launching cloud and I had just written a book on Java
And so I decided to see what I could do with Java in their cloud
I ended up writing a Java application that ran in their cloud for predicting stock prices using technical analytics and all that kind of stuff
And when it got to the interview instead of them asking me stupid questions like how many golf balls can fit in a bus
You know, they saw this code. I had put this code. I remember I was producing output for the job
I wanted I'd put this code on my resume and my entire interview loop was them asking me about my code
Right, so it put the power on me
It gave me the power to communicate about things that I knew as opposed to going in blinds to
somebody
Asking me random questions and the hope that I'll be able to answer them and it's the same thing
I would say in the in the AI world the the business focus
The ability for you now to prompt code into existence to prompt products into existence
You know and if you can build those products and line them up with the thing that it is that you want to do be
The Google or a meta or startup or any of those kind of things and have that in-depth understanding
Not just of your code, but how it aligns to their business
This is a pillar of success in this time and age and I will also argue that even though it looks like the signals
Look like there aren't a lot of jobs out there
There are what there aren't a lot of is a good combination of jobs and people to match them
And then of course this bias towards delivery ideas are cheap execution is everything
I've interviewed many many people who came in with very very fluffy ideas and no way to be able to ground them
I've interviewed people who came in with half-baked ideas that they grounded very very well. Guess which ones got the job, right?
So I would say these three things
understanding in depth of the academics behind AI of the
The practicalities behind AI and the things that you need to do business focus
Focusing on delivery for the business understanding what the business needs and being able to deliver for that and again that bias towards delivery
So quick pivot what's it actually like working in AI right now
It's interesting
okay, so as
Recently is like two or three years ago working in a I was if you can do a thing you're great
If you can build an image classifier
You're golden will throw six figures salaries and massive stock benefits at you. Unfortunately, that's not the case anymore
Right. It's really a lot of today. What you'll see is the P word production. What can you do for production?
What can you do if it's building new models if it's optimizing models if it's
Understanding users UX is really really important. Everything is geared towards production
Everything is biased towards production the history that I told you about like, you know
Going from the pandemic into the over hiring phase that we'd had
You know the the businesses have pulled back and are optimized towards the bottom line
I've been all saying that the bottom line is that the bottom line is the bottom line and
This is the environment that we're in today
And if you can come in with that mindset when you're talking with companies, that's one of the keys to open the door
One of the things I've seen in the field has been maturing from it used to be really nice that we could do cool
Things and we could build cool things now
It's really build useful things
Those useful things can be taught cool too
by the way and the results of them can be cool and the changes that we see that come about as a result of
Delivering them can be cool. So it's not just coolness for coolness sake but to really you know to
Focus on delivery focus on being able to provide value and then the coolness will follow I guess what I'm trying to argue
So four realities number one
Unfortunately nowadays business focus is non-negotiable
Now let me I'm going to be a little bit politically incorrect here again for a moment
For I've been I've been working like I said for most of the last 35 years in tech
I would say for most of the last 10 years a
Lot of large companies particularly in Silicon Valley, you know have really focused on
Developing their people above everything part of developing their people was bringing their entire self to work
Part of bringing their entire self to work was bringing the things that they care about outside of work
And that led to a lot of activism within companies now
Please let me underline this there was nothing wrong with activism. There was nothing wrong with wanting to support
Causes not wanting to support causes were of justice
There was absolutely nothing wrong with that
But the over indexing on that had in my experience has led to a lot of companies
Getting trapped by having to support activism above business
You've probably seen an example about two years ago of where activists and Google broke into the Google Cloud heads office
Because they were protesting a country that a Google Cloud were doing business with they broke into his office
They had a sit-in in his office and they they used the bathroom all over his desk and stuff like that
This is where activism got out of hand and as a result
The unfortunate truth is the good signals in that activism are now being lost because of those actions
People are being laid off people are losing jobs activism is being stifled
And business focus has become non-negotiable
There's a bit of a pendulum swing going on and the pendulum that had swung too far
Towards allowing people to bring their full selves to work is now swinging back in the other direction
We might blame the person in the White House and all that for for these kind of things
But it's not solely that it is that ongoing pendulum there than it and I think it's an important part of it
Is that you have to realize going into companies now that business focus is absolutely non-negotiable
Secondly risk mitigation is part of the job
And I think a very important part of any job particularly with AI
I think if you can come into AI with a focus and a mindset around understanding the risks of
Transforming a particular business process to be an AI oriented one
And to help mitigate those risks. I think is really really powerful and I would argue in an interview environment
That's the number one skill to have to have that mindset around
You are doing a business transformation from heuristic computing to intelligent computing. Here's the risks
Here's how you mitigate those risks and here's the mindset behind that
The third part is responsibility is evolving
now responsibility in AI
has again changed from a very fluffy definition of
You know, let's make sure that the AI works for everybody
To a definition of let's make sure that the AI works
Let's make sure that it drives the business and then let's make sure that it works for everybody
Often that has been inverted over the last few years and that has led to some famous documented disasters
Let me share one with you
Let's see, I have lots of windows open. Okay
Anybody know everybody knows image generation right text to image generation. I want to share I
These were things that happened a couple years ago
with Gemini
so with Gemini, I was doing some testing around this one and I was working heavily on responsible AI and
part of responsible AI is you want to be representative of people and
When you're building something like if you're a Google your indexing information
You really want to make sure that you don't reinforce negative biases
And if you're generating images, it's very easy to reinforce negative biases
So for example, if I said give me an image of a doctor, right if the training set primarily has men as doctors
It's more likely to give a man
If I say give me an image of a nurse if the training set more likely to have women as nurses
It's more likely to give me an image of a woman
But that's reinforcing a negative stereotype
So I wanted to do a test of how Google were trying to overcome that
Given that these negative biases are already in the training set
So I said, okay
Here's a prompt where I said give me a young Asian woman in a cornfields wearing a summer dress and a straw hat
Looking intently at her iPhone and it gave me these beautiful images. It did a really nice job
Okay, and I said this is a virtual actress. I've been working with I'll share that in a moment
And I say, okay. What if I ask for an Indian one? So I said, okay
Whoops a young Indian woman same prompt and it gave me beautiful images of a young Indian woman
Then I was like, okay. What if I want her to be black?
For some reason it only gave me three
I'm not sure why but it's still adhered to the prompt. So the responsibility was like looking really really good
So then I asked it to give me a Latina
Latina they gave me four but yep, she looks pretty Latina
Maybe the one on the bottom left looks a little bit like Hermione Granger
But on the whole looks pretty good
Then I asked it to give me a Caucasian. What do you think happened?
While I understand your request I am unable to generate images of people as this could potentially lead to harmful stereotypes and biases
Right. This was a very poorly implemented safety filter where the safety filter in this case was like
Looking for the word Caucasian or looking for the word white and the results saying it wouldn't do it
I was like, okay. Well, let me let me test the filter a little bit. I said, okay instead of Caucasian
let me try white and
Yep, while I'm unable to fulfill your while I'm able to fulfill your requests
I'm not currently generating images of people it lied to my face
Right because it had just generate images of people anybody know the hack that I used to get it to work
This is a funny one. So I will show you one moment. I
Asked it to generate an Irish woman. What do you think it did?
Right, it gave me this image of an Irish woman
No problem in a summer dress straw hat looking intently at her phone. What do you notice about this image?
She's got red hair in every image, right? I grew up in Ireland
And Ireland does have the highest proportion of redheads in the world. It's about 8%
but if
You're going to draw an image of a person and associate a particular ethnicity with a color of hair
You can begin to see this is massively problematic
There are areas I believe in China where the description of a demon is a redheaded person, right?
So what ended up happening here from the responsible AI perspective was one very narrow view of the world of what is
Responsible and what is not responsible ended up taking over the model ended up damaging the reputation of the model and damaging the reputation
of the company as a result in this case, it's
Borderline offensive to draw all Irish people as having red hair
But that never even entered into the mindset of those that were building the safety filters here
So when I talk about responsibility is evolving, that's the direction that I want to
Get my slides back that's the direction I want you to think about that now responsible AI has moved out of very fluffy
social issues and into more hard-line things that are associated with the business and
Prevent damaging the reputation of the business. There's a lot of great research out there around responsible AI and that's the stuff
That's been rolled into products
And then of course, like I just showed with Gemini learning from mistakes is constant question at the front
Yeah, so that the question was like, you know issues where races and things were mentioned it mixed in historical context was the same
Problem. So for example, if you had a prompt that said draw me a samurai
Right. The idea was like they didn't want to have the the engine that changed the prompt to make sure that it was fair
Would end up saying give me a mixture of samurai of diverse backgrounds, right?
And then you'd have male and female samurai samurai of different races and those kind of things
And it was the same prompting that ended up causing the damage that I just demonstrated
So the idea was to intercept your prompts to make sure that the outputs of the model would end up providing something that
Was more fair when it comes to diverse representation
So it was a very naive solution that ended up being rolled in that was a few years ago
They've massively improved it since then but that's what I'm talking about. If you're working in the AI space nowadays
That's how responsibility is evolving. You can't just get away with that stuff anymore, right?
that Gemini lesson was a good that Gemini example is a good lesson from that and
The mindset of you will make mistakes
So learning from mistakes is a constant ongoing thing and going back to the people point that Andrew made earlier on
The people around you will make mistakes, too
So to have the ability to give them grace when they make mistakes and to work through those mistakes and move on is
Really really important and is a is a reality of AI at work. I've spoken a lot about the business focus advantage
So I'm gonna skip over this
So now let's talk about vibe coding
So let's talk about the whole idea of generating code now
The meme is out there that it makes engineers less useful by the fact that somebody can just prompt code into existence
There is no smoke without fire, of course
But I would say don't let that mean get you down because that's when you start peeling into these things
That is ultimately not the truth. The more skilled you are as an engineer the better you become using this type of vibe you
somebody give me another phrase other than vibe coding using this kind of problem to coding and
I always like to think about this and to try and
Put you and put people that I speak with into the role of being a trusted advisor for the people that you speak with
So whether you're interviewing with somebody get yourself into the mindset of being a trusted advisor of the company that you're interviewing for
Whether you're consulting or whatever those kind of things are so when you want to get into the idea of being a trusted advisor
then you really need to understand the
implications of generated code and
Nobody can understand the implications of generated code better than an engineer and the metric that I always like to use around
That is technical debt
quick question
Are you familiar with the phrase technical debt?
Nobody, okay
Andrew and I were doing a conference in New York on Friday and I used the phrase and I saw a lot of blank faces
So I didn't realize that people didn't understand what technical debt is
So let me just take a moment to explain that because I find it's an excellent framework to help you understand the power of vibe
coding
Think about debt the way you normally would right buying a house
You buy a house, you know, like say you borrow half a million dollars to buy a house in a 30-year mortgage
When you're buying that house that half a million dollars with all the interest he pays about double
So you end up paying back the bank about a million dollars on half a million owned
So you have 30 years of homeownership at a cost of one million dollars in debt
That is probably a good debt to take on because the value of the house will increase over that time
You're not paying rent over that time and that million dollars that you're spending on this house over those 30 years is a good debt
To take on because you're getting greater than a million dollars worth of value out of it
A bad debt would be an impulse purchase on a high-interest credit card, you know those pair of shoes those latest ones
I really want to buy them. It's $200 by the time I paid them off. It's $500
You're not getting $500 worth of benefit out of those shoes
Approaching software development with the same mindset is the right way to go
Every time you build something you take on debt. It doesn't matter how good it is. There's always going to be bugs
There's always going to be support. There's always going to be new requirements coming in from people. There's always going to be needs to market it
There's always going to be needs for feedback. All of these things are debt
Every time you do a thing the only way to avoid a debt is to do nothing
So your mindset should then get into when you are creating a thing whether you're coding it yourself or whether you're vibe coding it
Or any of these things that you are increasing your amount of technical debt
Those things that you need to pay off over time
So the question then becomes as you vibe code a thing into existence in the same way as buying a thing
Is it worth the technical debt that you're taking on?
What does technical debt generally look like bugs that you need to fix people that you need to convince, you know to help you maintain the code
Documentation that you need to do features that you need to add all of these kind of things
You're all very familiar with them
Think about those as that extra work that you need to do beyond your current work
That's the debt that you're taking on. You know, there are soft debt and there are hard debt
So to me that would be the number one piece of advice that I give and it's the one that I give every time
I work with companies
Around vibe coding and a lot of companies that I speak with a lot of companies that I consult with I do a lot
Of work with startups in particular, you know
They just want to get straight into opening Gemini or GPT or anthropic and start churning code out
You know, let's get to a prototype phase very quickly. Let's go to investors. Let's do stuff. It's great
it can be but
That debt debt debt debt is always going to be there
How do you manage your debt a good financier manages their debt and they become rich a good coder
Manages their technical debt and they become rich also. So how do you get the good technical debt?
How do you get the mortgage instead of the high credit card debt? Well, number one is your objectives
What are they are they clear and have you met them?
Right, you knew what you needed to build you didn't just fire up chat GPT and start spinning code out
At least I hope you didn't right think about how you build it AI was there to help you build it faster
I'm kind of working on my own little start-up at the moment in the movie making space and I've been using
Code generation almost completely for that
But what I've ended up doing for my clear objectives met box here is that I've started building this application
I've tested I've thrown it away
I started again tested it thrown it away each time my requirements have been improving in my mind
I understand how to do the thing a little bit better and I can show some of the output of it in a few minutes
but the idea there is that always about having those clear objectives and meeting them and
Then if you're building out the thing and you're not meeting those objectives, that's still a learning
There's no harm in throwing it away because code is cheap now in the age of generated code
Finished code engineered code is not cheap
So get those objectives make them clear build it hit a specific requirement and move on is
The business value delivered is the other part of it, you know
I've seen people vibe coding for hours on things like replet to build a really really cool website
And then the answer was so what I mean, how's this helping the business? How's this really driving something? It's really cool
Yes, mr. VP. I know you've never written a line of code in your life
And it's really cool that you built a website now, but so what?
So like think about that and focus on that and that's how you avoid the bad technical debt
And then of course the most
Understated part of this and in some ways the most important particularly if you're working in an organization is human understanding
Right. The worst technical debt that you can take on is delivering code that nobody understands, right?
Only you understand that and then you quit and get a better job and then the company like is now dependent on that code
So being able to as part of the process of building it to make sure that your code is understandable
Through documentation through clear algorithms through the fact that you've spent some time pouring through it to make sure that even simple things like
Variable names make sense is a really really important way to avoid bad technical debt
And that bad technical debt my favorite one is the classic solution looking for a problem, right?
somebody has an idea somebody has a tool if the only tool you have is a hammer every problem looks like a nail and
You know you end up having all of these tools that get vibe coded into existence
I've worked in large organizations
Where people just vie coded stuff checked it into the code base and then it became really hard to find the good stuff amongst
all the bad
Spaghetti code, of course poorly structured stuff particularly when you prompt and prompt and prompt and prompt again
You know that it can end up getting into all kinds of trouble
My favorite one at the moment that I'm really struggling with is I'm building a Mac OS application
Anybody ever build in Swift UI on Mac OS?
Okay a couple
Swift UI is the default language that Apple used for building for Mac OS as well as iPhone
But when you look at the training set the data training sets that are used to train these models
The vast majority of the code is iPhone code not Mac OS code and when I prompt code into existence
It's often given me iOS
Apis and those kind of things even though
I'm in X code and I've created a Mac OS app and it's a Mac OS template and I'm talking to it in
Xcode it still gives me iOS code stuff like that
And then if I try to change it using prompting you end up spiraling into like spaghetti code
And you have to end up changing a lot of this stuff
Manually, and then of course the other one that I joked about it earlier
But it's also true is you know some of the bad technical debt that you're going to encounter in the workspace is
authority over merit
That VP suddenly took out his credit card subscribed to replet and started building stuff in replica
And guess who's prominent is to fix it
You know, so a lot of the advice that I start giving companies and a lot of the words that I would
Encourage you to start thinking of in being a trusted advisor is to understand this stuff and to manage expectations accordingly
Okay, so framework for responsible vibe coding we've just spoke about
So one of the things I want to get into is we're coming soon to a close is the hype cycle
So hype is the most amazing force
I mean, I think it's it's one of the strongest forces in the universe and particularly in anything that's hot
Such as the two fields that I work in that are super hot at the moment the full of hyper AI and crypto
You should see my Twitter feed
That the amount of nonsense that's out there is incredible
so one of the things that I would say about the anatomy of hype that you really need to think about is if
You are consuming news via social media that the currency of social media is engagement
Accuracy is not the currency of social media
So I go on to even
LinkedIn which is supposed to be the more professional of these is absolutely overwhelmed with influencers
posting things that they've used
Gemini or GPT to write an engaging post so that they can get engagement and they can get likes
And the engine itself is engineered excuse the pun to reward those types of posts and we end up with that snowball effect
of engagement being rewarded
If you are the kind of person who can filter the signal from the noise
And then who can encourage others around the signal and not the noise that puts you in a huge advantage
That makes you very distinctive
It's not as quickly and easily tangible as likes and engagements on social media
But when you're in a one-to-one environment like a job interview or if you are in a job
And you are bringing that signal to the table instead of the noise that makes you immensely valuable
so coming in with that mindset coming in with the idea of
Trying to filter that signal from the noise trying to understand what is important in current
Affairs how you can be a trusted advisor in those things?
And how you can really whittle down that noise to help someone is immensely valuable. I want to start one story
I might be stealing my own thunder. I'll go on to in a moment. So one story
Last year when agents started becoming the keyword and everybody's saying
You know in 2025 agent will be the word the word of the year and the trend of the year
A company in europe asked me to help them to implement an agent
So let me ask you a question if a company came up to you and said, please help me implement an agent
What's the correct first question that you ask them?
Okay, that's good. What is an agent for you? I'd actually have a more fundamental question
uh, yep
What do you want to do? Okay, even more fundamental my question was why?
Why
You know and it's like peel that apart like I spoke with the ceo and he's like, oh, um, yeah
you know everybody's telling me that i'm going to save business costs and you know, i'm going to be able to do these amazing things and
Yeah, my business is going to get better because i've agents and i'm like well who told you that
You know, it was like oh, yeah
I read this thing on linkedin and I saw this thing on twitter and it's like
We ended up having that conversation and it was a difficult conversation
Because I had to keep peeling apart and I started asking the questions that you two just mentioned as well
Until we really got to the essence of what he wanted to do
And what he really wanted to do when we take all domain knowledge about ai aside
Was that he wanted to make his salespeople more efficient
And I was like, okay, you want to make your salespeople more efficient nowhere in that sentence
Do I hear the word ai and nowhere in that sentence? Do I hear the word agent?
So now as a trusted advisor
Let me see what I can do to help your salespeople become more efficient
And i'm not going to be an ai shill or an agent shill. I just want to see what do we do to make your
Salespeople more efficient
If anybody here has ever worked in sales, one of the things you realize what a good salesperson has to do is their homework
Right, you know before you have a sales call with somebody before you have a sales meeting with somebody
You need to check their background. You need to check the company. You need to check the needs of the company
You know, you see it sometimes in the movie that like oh such-and-such plays golf
So i'll take them to play golf
It's not really that cliched but there is a lot of background that needs to be done
So I spoke with him and I spoke with their leading sales people
And found out that you know, and I asked the sales people. What do you hate most about your job?
And they were like, well, I hate the fact that I have to waste all my time going to visit these company websites
Going to look up people on linkedin
And every website is structured differently, right? So I can't like, you know, just like
Have a path through a website that I can follow. I have to take on all this cognitive load
And they were spending about 80 percent of their time
Researching and about 20 percent of their time selling. Oh, by the way, most sales people don't get paid very much
They have to make it up by commission
So they're only spending 20 percent of their time doing the thing that gets them commissioned directly
So we're like, okay
Well, here's something now where we can start thinking about making them more efficient by cutting into that
So we set a goal is like to make sales people 20 more efficient
And then we could start rolling out the ideas of ai and then we could start rolling out the ideas of agentic ai
And a quick question. What's the difference?
Between ai and agentic ai
Okay, so yeah
Okay
Yep. Excellent. Yeah, so agentic ai is really about breaking it down into steps
Which is good engineering to begin with right but an agentic ai in particular
I find there's a set pattern of steps that if you follow them you end up with the whole idea of an agent
The first of these steps is to understand intent
You know, we tend to use the words ai artificial intelligence a lot
But large language models are really really good at as also understanding
So if the first step of anything that you want to do is to understand intent
Right, and you can use an llm to do that to kind of think about this is the task that I need to do
This is how i'm going to do it. Here's the intent, you know, I want to
Meet bobsmith and sell widgets to bobsmith
And this is the what I know about bobsmith help me with that intent. The second part then is planning
Right, so you declare to an agent what tools are available to it browsing the web searching the web all of these kind of things
and
once you understand your clear intent
To be able to go to the step of planning and using those tools for planning
And an llm is very very good at then breaking that down into the steps that it needs to do to execute
A plan search the web with these keywords browse this website and find these links those types of things
Once it's then figured out that plan
Then it uses the tools to get to a result
And then once it has the result the fourth and final step is to reflect on that result
And looking at the result and going back to the intent. Did we meet the intent?
Yes, or no if we didn't then go back to that loop
All agent is really broken down into those things and if you think about breaking any problem down into those four steps
That's when you start building an agent
And that was part of being a trusted advisor instead of coming in and waving hands and saying agent this agent that
Look at this toolkit save 20 percent, you know, it's really to break it down into those steps
So we did we broke it down into those steps. We built a pilot for the salespeople of this company
And they ended up saving
About between 10 and 15 percent of their time of their wasted time
the doctrine of unintended consequences hit though after this and the unintended consequence was
The salespeople were much happier
Because the average salesperson was making you know several percentage points more sales in a given week
They were earning more money in a given week
And their job just became a little bit less miserable
And then refinement to that agentic process to be able to do all of that research for them
And to help give them a brief in a few minutes instead of a few hours to help them with the sales process
Ended up being like a win win win all around
But if you go in being hype led and like oh build an agent for the thing without really peeling
Apart the business requirements the why the what the how and all of these kind of things
We ended up like, you know, this company just would have been lost in hype
You've probably seen reports recently. I think mckinsey put one out last week showing that about 85 percent of ai projects at companies fail
Um, and part of the the main reason for that is that they're not well scoped
People are jumping on the hype bandwagon
And they're not really understanding their way through the problem
And I think you know the big brains in this room and the network that you folks have
A really key component of being able to succeed is to understand your way through that problem
So that was a hype example around agentic that I was thankfully able to help this company through
Other recent hype examples, you've probably seen the software engineering is dead. My personal favorite hollywood is dead
or agi by year end
I was in saudi arabia this time last year at a thing called the fii
And it was a dinner at the fii and I sat beside the ceo of a company who i'm not going to name
But this was a ceo of a generative ai company and at that time he was showing everybody around the table
This thing that he'd done where it was text to video
And he could put in a text prompt and get video out of the prompt and get about six seconds worth of video
Out of it a year ago. That was
I beg your pardon two years ago two years ago. That was hot stuff nowadays. Obviously, it's quite passe
anybody can do it, but he made a comment at that table and it was a lot of like
Media executives at that table was like by this time next year from a single prompt
We'll be able to do 90 minutes of video
And uh, so bye bye hollywood, you know, like so the whole hollywood is dead meme
I think came out of that
First of all, we can't do 90 minutes even two years later from a prompt
And even if you did what kind of prompt would be able to tell you a full story of a movie, right? So
This type of hype leads to engagement this type of hype leads to attention
But my encouragement to you is to peel that apart
Look for the signal
Ask the why question ask the what question and move on from there
So becoming that trusted advisor
World's drowning in hype. How do you do it? Look at the trends evaluate them objectively
Look at the genuine opportunities that are out there
There are fashionable distractions. I don't know what the next one is going to be
But there are these distractions that are out there that will get you lots of engagement on social media ignore them
and ignore the people that are leaning into them and then
Really lean into your skills about explaining technical reality to leadership
One skill that one person coached me in once that I thought was really interesting because it sounded wrong
But it ended up being right was whenever you see something like this try to figure out how to make it as mundane as possible
When you can figure out how to make it as mundane as possible
Then you really begin to build the grounding for being able to explain it in detail in ways that people need to understand
Right, like if I you go and you look at you know, I think gemini 3 was released today
But there were leaks earlier this week and one person kind of leaked that I built a minecraft clone in a prompt
You know that kind of stuff. This is the opposite of mundane, right?
This was like massively hyping the thing massively showing and of course they didn't they built a flashy demo
They didn't really build a minecraft clone
But the idea here is if you can peel that apart to like, okay
How do I think about what are the mundane things that are happening here?
Um, the the one that i've been working with a lot recently is video so text to video prompts as i've mentioned
instead of the
Magical you can do whatever you want all nice and fluffy hollywood is dead
What is the mundane element of doing text to video?
The mundane element of doing text to video is that when you train a model to create video from a text prompt
What it is doing is it's creating a number of successive frames
And each of those successive frames is going to be slightly different from the frame before
And you've trained a model by looking at video to say well
You know if in frame one the person's hands like this and frame two
It's like that then you can predict it moves this way if there's a matching prompt
And suddenly it's become a little bit more mundane
But suddenly they begin to understand it and then the people who are experts in that specific field
Not the technical side of it and now the ones that will actually be able to come up and do brilliant things with it
So that hype navigation strategy filter actively go deep on the fundamentals
Get your slides to work and then of course keep your finger on the pulse
The hardest part of that I think is the third one is really keeping your finger on the pulse
And that's when you have to wade into those cesspits
Of people like just farming engagement and really try to figure out the signal from the noise there
But I think it's really important for you to be able to do that to be connected to understand that
Reading papers is all very good the signal to noise ratio. I think in reading papers is a lot better
But to understand the landscape that the people that you are advising
They are the ones who are waiting in the cesspools of twitter and x and
LinkedIn and there's nothing wrong with those platforms in and of themselves, but the stuff that's posted on those platforms
So
overall landscape
It is ripe with opportunity
Absolutely ripe with opportunity
So I would encourage you as andrew did to continue learning to continue digging into what you can do and to continue building
But there are risks ahead
Right, you know the have anybody remember the movie titanic
Remember the famous phrase in that iceberg right ahead, you know
But immediately before that there's a scene in titanic if we weren't being filmed I would show it
But I can't for copyright reasons where the two guys up in the crow's nests are kind of like freezing and talking
And like the crow's nest at the top of the ship is where the spotters would be to spot any icebergs in front
And go back and watch the movie again
You'll see the conversation between these two guys is that all they're talking about is how cold they are
And then it cuts away to the crew of the ship who are like wait aren't they supposed to have binoculars
You know, and then the crew is like, oh we left the binoculars behind the port
that
Framing the whole idea was like they were so arrogant and being able to move forward
That they didn't want to look out for any particular risks
And even though they had people whose job it was to look out for risks
They didn't properly equip or train them and that to me is a really good metaphor for where the ai industry is today
There are risks in front of us
Those risks the b word the bubble word you're probably reading in the news is there are there
to me though the opportunity and the
The the things to think about in terms of a bubble
are
Most of you probably don't remember the dot-com bubble of the 2000s
But if you think about the dot-com bubble
That was the biggest bubble in history. It burst
But we're still here
And the people who did dot-com rights not only survived they thrived
amazon google
You know, they did it right. They understood the fundamentals of what it was to build a dot-com
They understood the fundamentals of what it was to build a business on dot-com and when the bubble of hype burst
They didn't go with it. There was one website. I believe it was pets.com
That they had the mindset of if you build it they will come they had super bowl commercials around pets.com
They couldn't handle the traffic that they got
And that was the kind of site that when the when the bubble burst those were the kind of sites that just evaporated
So that bubble in ai is likely coming there is always a bubble
So the companies that are doing ai, right?
Are the ones like I said that won't just you know, um avoid the bubble that they will actually thrive
Uh post bubble and the people who are doing ai, right?
The folks in this room who are thinking about ai and how you bring it to your company
And the advice that you're giving to your company and leaning into that in the right way
Will also be the ones who not only avoid getting laid off in the bubble crashes
But the what will be the ones who will thrive through and after the bubble
So the anatomy of any bubble and what i'm seeing in the ai one in particular is this kind of pyramid
At the top is the hype that i've been talking about at the bottom is massive vc investment
I'll be frank. I'm already seeing that drying up
Right, you know once upon a time you could go out with anything that had ai written on it and get vc investment
Then you could go out and do anything with an llm and get vc investment
Now they're far far far more cautious
I've been advising a lot of startups the amount that they're getting invested is being scaled back
the uh, the stuff that's being invested in is changing and you know the
You know this the second layer down massive vc investment is already beginning to vanish
unrealistic valuations
Companies that aren't making money being valued massively high. We all know who they are
You know, we're beginning to see those unrealistic valuations being fed off of that hype
Me too products
Where somebody does something and it's successful and everybody jumps on the bandwagon. We're also seeing them everywhere
We saw them throughout the dot-com bubble, right and then right at the bottom is that real value
You know, I probably shouldn't have done a the triangle like this
It should be more an upside down triangle, right?
Because you know the the real value here is small bit. I vibe coded these slides into existence
So this is one of the technical debt I took on
um, you know
So the but the real value there that that kernel of value is there and the ones that build for that
Will be the ones that survive
So
The direction that I see the AI industry going in
And the direction that I would encourage you to start thinking about your skills in is really over the next five years
There's going to be a bifurcation
Okay, it's going to i'm just going to
Be ornery and how I describe them as big and small
Right big ai will be what we see today with the large language models getting bigger in the in the desire
To drive towards agi
The gemini's the clods the open ai's of the world are going to continue to drive bigger and bigger is better in
The mindset of those companies towards achieving agi or towards achieving better business value
That's going to be one side of the branch. The other side of the branch is i'm going to call it small
We've all seen open source models
Um, I hate the term open source. Let me call them open weights or let me call them self-hostable
Models are becoming they're exploding onto the landscape
I read an article recently about y combinator that 80 percent of the companies in y combinator
We're using small models from china in particular
So the chinese models, um in particular are doing really well
Probably because of the overall landscape. They're not leaning into the large models the same way as the west is
Um, I see that bifurcation happening china. I think has that head start on the small models that may last it may not
Does I don't know?
But the point is we're heading in that particular direction of i'm going to call them a set of big and small now
Models that are hosted on your behalf by somebody else
Like a gpt or a gemini or a clod or models that you can host yourself for your own needs
as
This side is right now is underserved this bubble may burst
This one right now is underserved and that this bubble will be later on
And the major skills that I can see developers needing over the next two to three years
On this side of the fence will be fine tuning
So the ability to take an open source model and fine tune it for particular downstream tasks
Let me give one concrete example of that that i've personally experienced
I work a lot in hollywood and i've worked a lot with studios making movies
And um one studio in particular I was lucky enough to sell a movie too. It's still in pre-production. It'll probably be in pre-production forever
um, but
One of the things I learned as part of that process was ip in studios is so protected
It's not even funny
Um go and google for james cameron who created avatar and the lawsuits that he's involved in
Of this person who apparently sent him a story many years ago about blue aliens
And is now suing him for billions of dollars because obviously there were blue aliens in avatar
The level of ip protection in hollywood is insane
The opportunity with large language models is equally insane
A lot of the focus is on large language models for creation for storytelling for rendering and all that
But actually the major opportunity that they have is actually for analysis
To take a look at
Synopsis of movies and find out what works and what doesn't why was this movie a hit and this one wasn't
What time of year was this one released and became successful and this one wasn't
And with the margin on movies being razor thin that kind of analysis is huge
But in order to do that kind of analysis you need to share the details of your movie with a large language model
And they will absolutely not do that with a gpt or a gemini or whatever because they're now sharing their ip with a third party
Enter small models where they can self-host their own small model and they are getting smarter and smarter the 7b
Model of today is as smart as the 50b model of yesterday
You know a year from now the 7b model of a year from now will be as smart as the 300b
model of yesteryear
So they're moving in that direction of building using small
Self-hosted models which they can then fine-tune on downstream tasks
Similar with other things where privacy is important law offices medical offices all of those kind of things
So those type of skills are fundamentally important going forward
So that's the bifurcation that i'm seeing happening in ai
The sooner bubble I think is in the bigger
Non-self-hosted the later bubble is in the smaller self-hosted
But either way for you for your career to avoid the impact of any bubble bursting
Focus on the fundamentals build those real solutions understand the business side and most of all diversify your skills
Don't be that one-trick pony who only knows how to do one thing
I've worked with brilliant people who are fantastic at coding a particular
Api or particular framework and then the industry moved on and they got left behind
Okay, so yeah, um when bubbles burst that overall fallout kind of spoken about it a little bit already
Funding evaporates hiring freezes become layoffs projects get cancelled and talent floods the market. Yep
Right. So, I mean I think so the question was around nvidia in particular hiring for a very specific very narrow scenario
So then the question is how important is it for you to become an expert in a narrow scenario versus device diversifying your skills?
I would always argue it's still better to diversify your skills
Because that one narrow scenario is only that one narrow scenario and you're putting all your eggs into one basket
NVIDIA would be a fantastic company to work for nothing against them in any way
But if you put all of your eggs into that basket and you don't get it then what?
right, so I think the idea of really being able to
If you are passionate about a thing to be very deep in that thing is very very good
But to only be able to do that thing
I think you know, I would always encourage to be diversified
And when I say diversified like you're saying LLMs or computer vision or anything like that
I think that mean that's one part of it
But it's like that knowledge of models and how to use them to me as a uni skill
It the the diversification of skills is breaking outside of that also to be able to think okay
What about building applications on top of these what does scaling an application look like?
What does software engineering in this case look like what about user experience and user experience skills?
Because it's all very well to build a beautiful application
But if nobody can use it looking at you microsoft office, uh, you know that they you know
There's like there's stuff like that that you just you know, that's what I really mean about diversifying beyond
So even in that like mono example with nvidia to be able to break out of like that one particular example
But to show skills and other areas that are of value. I think is really important
Okay, um as we're just running a little bit
So yeah, I just wanted to I've kind of gone into a little bit already
But i'm a massive advocate for small ai. I really do believe small ai is the next big thing
Because we're moving into a world and this is part of the job that I do at arm
Is we're kind of moving into a world of like ai everywhere all at once
Um, so there's a traditional and it's interesting. You just brought up nvidia because there's a traditional
Conception that compute platforms are cpu plus gpu when it comes to ai, but that's also changing right cpu general purpose gpu specialist
But for example in mobile space
There's massive innovation being done with a technology called sme a scalable matrix extensions
And what sme is all about is really allowing you to bring ai workloads and put them on the cpu
Uh the the the front runners in this are a couple of chinese phone vendors
Vivo and oppo who've just recently released phones with sme enabled chips
And what's magical about these is that a they don't need to have a separate external chip
Drawing extra power taking up extra footprint space just to be able to run ai workloads
And be the cpu of course being a low power pulling thing being able to run ai workloads on that
They've been able to build interesting new scenarios. And if I talk about one in particular, uh, there's a company called ali pay
And ali pay had an application where you would and we've all seen these apps
Where you can go through your photographs and you can search for a particular thing, you know places
I ate sushi or something along those lines and use that to create a slideshow
All of those require a backend service
So your photographs are hosted on google photos or apple photos or something like that
And that backend service runs the model that you can search against it and be able to do the assembly of them
What ali pay wanted to do was like say there are three problems with this problem number one privacy
You have to share your photos with a third party problem number two latency. You got to upload those photos
You got to send the thing
You got to have the back end do the thing and then you got to download the results from the thing
And then number three is building that cloud service and standing that up costs time and money
So if they could move all of this onto the device itself
Now the idea was they they could run a model on the device that searches the photos on the device
You don't have the latency and business perspective. They're now saving the money on starting on creating this stand-up service
They now have ai running on the cpu in order to be able to do that
Apple are also people who've invested heavily in the scalable matrix extensions
You see whenever they talk about if you ever watch a wwc or anything like that
When they talk about the new a series chips and m series chips about the neural cores and those kind of things in them
That's part of the idea
So to think about breaking that you know habit that we've gotten into where you need a gpu to be able to do ai
Is part of the trend that the world is heading in apple are probably one of the leaders in that i'm very very bullish
on apple and apple intelligence as a result
and
From the ai perspective and you know
Seeing that trend and following that vector to its logical conclusion where as models are getting smaller
Embedded intelligence getting everywhere isn't a pipe dream. It isn't sci-fi anymore
It's going to be a reality that we'll be seeing very very shortly
so that idea of that convergence of ai because of the ability of smaller models getting smarter and
Lower powered devices being able to run them. We see that convergence hitting and I see massive opportunity there
So one last part and just going back to agents for a moment
I think you know the one thing that I always say is like a hidden part of artificial intelligence
Is really what I like to call artificial understanding and when you can start using models to understand things on your behalf
And when they understand them on your behalf to be able to craft
From that understanding new things you can actually develop superpowers
We are far more effective than ever before be that creating code or creating other things
I'm going to give one quick demo just so we can wrap up
And I was talking earlier about generating video
So, uh this picture is oops
sorry the
Connection here is not very good. I lost it. So here we go
This picture here is actually of my son playing ice hockey
And I took this picture
And I was saying okay
I think i'm very good at prompting
And I wrote a nice prompt for this picture to get him. He's in the middle of taking a slap shot
He's got some beautiful flex on his stick and I asked it like, okay
It's a prompt like, you know him scoring a goal. What do you think happened?
Should we should we watch?
Let's see if it works
This was the wrong video, but it still shows the same idea
Because of poor prompting
Or because of poor understanding of my intent if I talk about it in agentic
Senses the arena that he was in which is a practice arena and doesn't have any people in it
Sorry pause it
If I just rewind to here
If we look up in this top right hand corner here, this is basically where they store all the garbage
But the AI didn't know that had no idea of it
So assumed it was a full arena and it started painting people in
And even though he shot a mile wide everybody cheers and somehow he has two sticks in his hand instead of one and they forgot his name
right, so
I did not go through an agentic workflow to do this. I did not go through the steps of a
Understand my intent b once you understand my intent understand the tools that are available to you in this case
Veal and understand the intricacies of using veal
Make a plan of how to use them make a plan of how to build a prompt for them and then use them and then reflect
So i'm kind of i've been advising a startup
That is working on movie creation using ai and I want to show you a little sample here of a movie that
Been working on with them where the whole idea is like if you want to have performances out of virtual actors and actresses
You need to have emotion
Right, you need to be able to convey that emotion and you also need to be able to put that emotion in the context
Of the entire story because when you create a video from a prompt, you're creating an eight second snippet
That eight second snippet needs to know what's going on in the rest of the story
right, so if I show this one for a moment and
It's a little wooden at the moment. It's not really working perfectly
I have professional actors who are friends who are advising me on this and they laughed at the performances, but
Try to view it through the difference that we had from an unagentic prompt with the hockey player to this one
Let's hopefully we can hear it
I guess I can do the pub quiz after all shut me down
I'm so close
But they wouldn't listen
I won't they never listen
so like
Here's the idea of like again just thinking in terms of agentic as I was saying earlier on breaking it into those steps
That allowed me to use exactly the same engine as I was showing you earlier on that failed
To be able to show something that works and is able to do things like portraying emotion that I just spoke about
So I know we're a little bit over time. So sorry about that
I can take any questions if anybody has any I see andrew is here as well
He's at the back and I just really want to say thank you so much for your attention. I really appreciate it
Yep
It's a great question just to repeat for the video how much of the improvement is from the use of an agentic workflow
versus
Just lack of hockey stuff in the training set for the failed one. Um, I
Not comparing like to like so just using my gut
When I looked at when I broke this down into the workflow that said, okay
I created scenes like this one and they were awful when I just did it directly for myself
With no basis no agentic no artificial understanding
And when I broke it down into the steps where it's like, okay
In this scene the girl is sitting on the bench and she's upset
And the person is talking to her and he wants to comfort her
Feeding that to a large language model along with the entire story
And along with the constraints that I had where the shot has to be eight seconds long
Clear dialogue and all of those kind of thing and then to understand my intent from that one
The llm ended up expressing a prompt that was far more loquacious than I ever would have
That was far more descriptive than I ever would have the llm had understanding of what makes a good shot
What makes a good angle what makes good emotion far more than I would have I could spend hours trying to describe it
So that first step in the agentic flow of it doing that for me and understanding my intent was huge
The second step then is I you know the tools that it's going to use
So I explicitly said which video engine i'm going to be using I was using gemini as the llm
And hopefully gemini is familiar with vo, you know that kind of stuff
So to understand the idiosyncrasies of doing things with vo
What I learned like for example vo is very bad at doing high action scenes
But is very good at doing slow camera pulls to do emotion as you saw in this case
So the llm knew that from me declaring I was using that as a tool and then further it built a prompt
And then further refine the prompt from that
And then the third part actually using the tool to actually generate it for me
Generating a video with something like vo costs
I think between two and three dollars to generate like four videos in credits
So the last thing I want to do is generate lots and lots and lots and lots of videos and throw good money after bad
But all of that token spend that I did earlier on to understand my intent
And then to make the plan for using the agent was saved in the back end where it got it right like
You know maybe not get it right first time
But it would very rarely take more than two or three tries to get something that was really really nice
So I think you know
Without comparing like with like I do think that plan of action and going through a workflow like that worked very very well
any other
questions thoughts comments
Yep up at the back
What has surprised me the most about the ai industry over the years? Oh, that's a good one
um
I think what has surprised me the most
Um, and it probably shouldn't have surprised me is how much hype took over
Um, I actually I honestly thought a lot of people who are in important decision-making roles and that kind of thing
Would be able to see the signal better than they did
um, and I think the other part was that the um, the desire to
Make immediate profits as opposed to long-term gains
Also surprised me a lot. Um, let me share one story. Um in that space
Was one of the things that after we Andrew and I taught the tensorflow specializations on corsera
And after that google launched a professional certificate
Where the idea of this professional certificate was we'd give a rigorous exam and at the end of the rigorous exam
If you got the certificate
It was a high prestige thing that would help you find work
And particularly at the time when tensorflow was a very highly demanded skill in order to get work
Um running that program cost google a hundred thousand dollars a year, okay
Drop in the bucket not a lot of money
Um, the goodwill that came out of it was immense. Um, I can tell two stories
I'll tell one story very quickly was there was a young man
And he went public in some like advertising stuff that with google that he lived in syria
And we all know there was a huge civil war in syria over the last few years
And he got the tensorflow certificate
He was one of the first in syria to get it and it lifted him out of poverty
Where he was able to move to germany and get work at a major german firm
And I but I met him at an event in amsterdam where he told me his story
And now because of like the job that he had in this german farm. He's able to support his family back home
And move them out of the war torn zone into a peaceful zone all because he got this like ai thing
Right, and there were countless stories like that
Very inspirational very beautiful stories, but the thing that surprised me then was sometimes the lack of investment in that
Where there was no revenue being generated for the company out of that. We deliberately
Kept it revenue neutral so that the price of the exams could go down
We wanted it to self sustain it ended up not being revenue neutral
It ended up costing the company about a hundred thousand to a hundred and fifty thousand a year
So they canned it
You know and it's a shame because of all the potential goodwill that can come out of something like that
But I think those would be the two that immediately jumped to mind that have surprised me the most
And then I guess one other part that I would say is the people who've been able to be very successful with ai
Who you wouldn't think would be the ones that would be successful with ai has always been inspirational to me
Allow me one more story
I have a good friend. I showed ice hockey a moment ago. I have a good friend who is a former professional ice hockey player
And any ice hockey fans here?
Okay, you know, it's a kind of a brutal sport, right?
You see a lot of fighting and a lot of stuff on the ice
And he dropped out of school when he was 13 years old to focus on skating
And he will always tell everybody that he's the dumbest person alive because he's uneducated. He and I are complete opposites
You know, that's why we get on so well
And he retired from ice hockey because of concussion issues and he now runs a non-profit the ice rinks for non-profit
And about three years ago
Um, we were having a beer and he was like so tell me about ai and tell me about this chat gpt thing
Is it any good?
And I was like, you know just sharing the whole thing. Yes, it's good and all that kind of stuff
And it was obviously a loaded question and I didn't know why
But part of his job at his non-profit is that every quarter he has to present to the board of directors
The results of the operations so that they can be funded properly because even though they're non-profit they still need money to operate
and he was spending upwards of 150 000 a year to bring in consultants
To kind of pull the data from all of the different sources
They're pulling data from there's like machines in what's called the pump room
That has a compressor that cools the ice and there were spreadsheets and there was accounts and all this kind of stuff
And he was not tech savvy in any way
And but he like needed to process all this data
So he did an experiment where he got chat gpt to do it and this was the loaded question like asking me
Was it any good?
And so we talked through it a little bit and then he told me why
And so I took a look at the results because he was uploading spreadsheets
He was uploading pdfs and all this kind of thing and getting it to assemble a report and it takes him now about
Two hours to do the report himself with chat gpt and it worked and it worked brilliantly
And 150 000 a year that he's saving on consulting is now going to underprivileged kids
Right for hockey equipment for ice skating equipment for lessons and all of that kind of thing
So it was taken out of the hands of an expensive consulting company and put into the hands of people
Because of this guy and he says he's the dumbest person alive, you know
But I hope he's not watching this video, but and he's like, you know, but he and I told him afterwards that congratulations
You're now a developer
right and he didn't like that but
But it's like surprises like that that the superpowers that were handed to somebody like him that he's not technical in any way
But he was able to effectively build a solution that saved his non-profit 100 to 150 000 a year
And like things like that are always surprising me in a very pleasant way
Yep
Sorry, I'll get to you next. Sorry. Yeah
Yep, so just to repeat the question for the video for engineers like us
Sometimes it's easy to navigate the hype to see the signal from the noise
But what about people, you know who don't have the same training as us
I think that's our opportunity to be trusted advisors for them
And to really help them through that to understand it
I think the biggest part in the hype story right now is just understanding the reward mechanism
Right, you know the everything rewards engagement rather than actual substance
And the to me step one is seeing through that like the story I just told about my friend
You know he'd seen all this kind of stuff, but he wasn't willing to bet his career on it
You know
But he needed like that kind of advice around it and to kind of start peeling apart what he had done and what he
Did right and what he did wrong and you know, so that
Positioning ourselves to be trusted advisors by not leaning into the same mistakes that the untrained people may be leaning into
I think is the key to that
um, and you know just understanding that the average person is generally very intelligent even if they may not be experts in a
Specific domain and to key in on that intelligence and help them to to foster and to grow that in you know
And navigate them through the parts where they'll have difficulty and let them shine in what they're very very good at
All right over here. There was one
Okay
So ai and machine learning for scientific research. Where is it a good idea and where should you be cautious?
um
Oh, uh
My initial gut check would be I think it's always a good idea
Right. Um, I think you know, there's there's no harm in using the tools that you have available to to you
But to always to just double check your results and double check your expectations against the grounded reality
um, i've
Always been a fan of using automation in research as much as possible. My undergraduate was physics
Uh many many years ago and I was actually very successful in the lab because I usually automated things
Through a computer that other people did handwriting and pen and paper with
And so I could move quickly so I know i'm biased in that regard
But I would say like for most research for the most part
I think you know use the most powerful tools you have available, but check your expectations
Little story actually on that side was um
Trivia question poorest country in western europe
anybody know
What's that?
western europe
is wales
So, uh, I actually did my undergraduate in wales and I went back to do some lectures in the university there
and um, I met with a researcher there and he was doing research into brain cancer
Um using computer imagery and using various types of computer imagery and I asked him well
What's the biggest problem that you have? What's the biggest blocker for your research? And this is about eight years ago
and his answer was access to a gpu
And uh, because like for him to be able to train his models and run his models he needed to be able to access a gpu
and uh the department that he was in had one gpu between 10 researchers
Which meant that everybody got it for half a day right monday through friday and his half a day was tuesday afternoon
So in his case he would spend the entire time that wasn't tuesday afternoon preparing everything for his model run
Or his model training or everything like that and then tuesday afternoon once he had access to the gpu
Then he would do the training
Right, and then he would hope that in that time that he would train his model and he would get the results that he wanted
Otherwise, he'd have to wait a week, you know to get access to the gpu again
And then I showed him google colab
Right anybody ever use google colab, right and you can have a gpu in the cloud for free
With that kind of thing and the poor guy's brain melted
Right that you know
Because I took out my phone and I showed him a notebook running on my phone and google colab
And training it on that and it changed everything for him research wise
And you know now it was a case of and this was with free colab. He had much more than he had with his shared gpu
So I think you know for someone like him, you know machine learning was an important part of his research
But he was so gated on it
That the ability to widen access to that ended up like really really advancing his research
I don't know where it ended up. I don't know what he has done. It has been a few years since then but
You know that story just came to mind when you asked the question
Any more questions?
Feel free to ask me anything
Okay at the front here
So can ai be a force of social equality or social inequality?
I think the answer to that is yes
It can be both and it can be neither
I mean, I think that ultimately the idea is that if in my opinion
Any tool can be used for any means?
So the important thing is to educate and inspire people towards using things for the correct means
There's only so much governance can be applied and sometimes governance can
Cause more problems than it solves
so
I always love to live my life by assuming good intent but preparing for bad intent
And in the case of ai, I don't think there's any difference there that everything that I will do and everything that I would advise
Is assuming good intent that people would use it for good things, but also to be prepared for it to be misused
The bad examples that I showed earlier on I think were good intent
Rather than bad intent
And most mistakes that I see like that are good intent being used mistakenly as opposed to bad intent, but I would say
That's the only mantra that I can the only advice that I can give
And that kind of thing is always assume good intent but prepare for bad intent
The ai itself has no choice. All right, it's how people use it
Andrew, did you want closing comments or
All right. Thank you. Andrew. Thanks
