What I want to do today is, um,
give an overview of this class.
Uh, I'm- I'm actually curious before we get started.
Um, this is now September 2025.
Um, how many of you, you know,
just started at Stanford?
Raise your hand. Wow, cool, awesome.
So others, pay attention to who just raised their hands and do,
say hi to them and, you know,
welcome all of the people that just joined Stanford and whatever program.
Um, CS 230 is a class that we offer in the flipped classroom format.
And what that means is that instead of listening to me or Kian,
uh, my co-instructor that you meet- that you meet next week,
instead of listening to us lecture at you for an hour,
hour 20 minutes or whatever, um,
we actually ask you to watch a lot of the video lectures online so that we
can then make use of the precious in-classroom time for much richer,
deeper discussions.
So both today and for the entire quarter, um,
I would really warmly welcome anyone raising questions, uh, raise your hand.
And in fact, I- I- I find that, um,
instead of you sitting there- oh,
and even though we have a longer session scheduled by the registrar,
uh, we'll use usually only up to an hour and 20 minutes for this course.
Um, and the goal is to- it- it turns out that a lot of Stanford students
were watching, you know, the lectures, um,
on, uh, Seagull or on the online videos anyway.
So rather than us delivering that lecture, same lecture, year after year,
we put a lot more effort to put very high-quality lecture videos online,
and we'll ask you to just watch that online,
which people are doing anyway,
but just highly edited for offline watching, um,
spend- and spend the classroom time, you know,
doing the things that make sense for us to get together in person too.
Um, so because you haven't watched any of the lectures yet,
or I assume most of you have not,
today we'll even maybe have a slightly shorter session to introduce the class,
talk over logistics, and so on.
Right? Um, as many of you know,
deep learning is one of the latest,
hottest trends technologies of computer science and AI.
Um, if we look at, you know,
say our PhD admissions or- or even NASA's admissions,
there's a very large fraction of all students that come to Stanford
or applying to come to Stanford want to work on AI.
Right? I'm not sure I'm allowed to say the numbers,
but they are, you know, extremely high, um, as you can imagine.
And so, uh, my goal and my- my co-instructor,
Kian's goals, our collective goal,
is through this quarter to help you get to near or at pretty much state of the art
with regard to deep learning, um,
and make sure that all of you walk away from this class,
highly skilled at applying deep learning.
Um, and so it turns out that a lot of progress in AI over the last,
I don't know, decade,
maybe 10-15 years was made by scaling.
And one of the reasons why deep learning was so successful
was because it's good at absorbing a lot of data.
So, you know,
if I draw a figure where on the x-axis,
I plot the amount of data we have for a problem,
um, then using more traditional machine learning algorithms,
so, you know, logistic regression, maybe decision trees,
using all the generations of AI machine learning algorithms,
um, as you gave it more and more data,
the performance or the accuracy of the more traditional algorithms with plateau, right?
It was as if- so take speech recognition.
With all the generations of algorithms,
even as you fed it more and more data,
hundreds and thousands and tens of thousands of hours of speech data,
the accuracy would often plateau,
and it was as if the older generations of algorithms
didn't know what to do with all the data that we now have.
But what we start to find about 10-15 years ago,
um, was that if you train a small neural network,
also known as a small deep learning model,
this performance would kind of maybe get better and better.
And if you train a medium-sized one,
and if you train a very large neural network,
the performance just keeps getting better and better.
And I think the reason that deep learning has
dominated the AIC for the last 10-15 years is because there is
a recipe for training very large neural networks,
um, that we could then shove a lot of data
into that results in exceptional performance.
So I think, um,
we started to see this because of some,
frankly, some Stanford research papers, um,
about 15 years ago when- when, you know,
did the first early work on using
cruder programming and GPUs to scale up deep learning.
Oh, by the way, actually, it's one fun fact.
Um, uh, the first- my first, uh,
GPU machine used to train neural networks using cruder,
which is a controversial thing at the time,
it was built by a Stanford undergrad in his dorm room, right?
His name was Ian Goodfellow.
But, um, I think that compute server
built in the Stanford undergrad dorm room,
um, allowed us at Stanford to lay
the early foundations of using cruder at that time,
a modern language for training GPUs to train large neural networks.
And then, you know, obviously,
that influenced a lot of people and helped scaling up deep learning to take off.
So I- I- I tell that story because, um,
sometimes the work that some of you can do,
you know, in a dorm room or graduate student housing or whatever,
or in a lab at Stanford, um, uh,
looking back over some number of years,
it- it can really have a huge impact.
And maybe in this class, some of you will do
work, um, as impactful as that someday as well.
But so what you start to find was that,
as you train larger and larger neural networks,
they could soak up lots of data and drive exceptional performance.
Um, and then there was a research paper out of Baidu,
which showed that as you scale up neural networks,
as you scale up deep learning algorithms,
the performance gains are actually quite predictable.
So you can forecast, if you buy this many GPUs,
so this would compute and this much data added,
what would the performance be?
Um, and then later,
OpenAI popularized the idea with a really influential paper on scaling laws,
um, and that predictability of how deep learning gets better in performance
then drove a lot of the investments, uh, in, you know,
data centers and- and building very large AI models with lots of data.
Um, and so, let's see.
In terms of where this class sits,
so in computer science,
all of us build on each other's work, right?
A lot of the way that, uh,
computer science and AI has made progress is we build on top of other ideas
that are in turn built on top of other ideas,
they're in turn- they're in turn built on top of other ideas.
So maybe I wanna give you a little map to- to- to show you,
maybe where deep learning sits.
Um, so I think there are,
you know, machine learning is built on top of computer science,
so I think it's actually helpful to learn CS fundamentals.
Uh, and even though I use and I suspect vast majority of use AI-assisted coding,
be it tools like Cloud Code or Gemini CLI or OpenAI Codecs or Cursor or Winserv or whatever,
um, I find that people that know CS fundamentals,
they really understand computer science, uh,
they really understand how computers work rather than like,
I'm gonna vibe code this, you know,
like when you understand CS fundamentals,
you get things to work much better.
But on top of CS fundamentals,
there's a set of, um, machine learning skills.
So how do you build algorithms that can learn from data?
Um, and then deep learning is a special type of machine learning.
Well, that's really the most effective type of machine learning,
as you can tell, in which we train new networks,
we train certain types of algorithms to learn from large amounts of data.
Uh, so far in the last 10 minutes,
you've probably heard me use the words deep learning and neural networks,
and I think today those two terms are almost interchangeable.
Uh, some, some purists will insist on some technical differences.
For all practical purposes, they mean the same thing.
But what happened was the term neural networks happened around for decades.
But around 10, 15 years ago,
a number of us realized that, you know,
deep learning, it was just a much better brand.
Um, and so even though neural networks have been around for decades,
starting about 10, 15 years ago,
it was deep learning that took off,
because who doesn't want learning that is really deep?
Like, it's just a good brand.
Um, but you hear me use those terms kind of interchangeably,
but, um, deep learning algorithms, neural networks,
they give us a way to take advantage of more and more and more compute,
capacity so they can build very large AI models with a lot of parameters
to soak up the large amounts of data to get more and more,
you know, intelligent or to make better and better predictions,
and generate more and more accurate outputs using
large amounts of data that's available to us.
Ever since I was a teenager,
my mom's been trying to convince me to stop mumbling.
But now many years later,
I still struggle with that.
So I'll, I'll, I'll try my best.
So please wave at me or kind of let me know if I start to drift lower again.
Yeah. I think my mother would be very happy that to practice like this now.
Um, all right.
So CS fundamentals, machine learning, deep learning,
and then the recent generative AI revolution.
You know, generative AI, um,
sorry, bad handwriting, generative AI,
which is mostly built by
a specific type of neural network called a transformer neural network,
which you learn about in this class.
You actually learn what is a transformer architecture,
um, later in this quarter as well,
is in turn built on top of deep learning, right?
So I assume all of you, you know,
are regularly prompting LMS,
large language models, to help you get work done.
Um, and what I find is that while I use LMS all the time,
for a lot of applications,
just prompting LMS, it doesn't cut it.
There are a lot of things that I cannot get to work just by prompting an LMS.
Um, and so I'll often have to go a layer
deeper into the deep learning layer of abstraction,
and fill it with deep learning algorithms in order to get certain things to work.
And in fact, so what this class covers is,
we'll try to make sure that you are,
you know, expert, near expert in deep learning by the end of this class.
But we'll also, um,
kind of dip a little bit into machine learning concepts.
We'll talk a lot about objective functions,
and tips and tricks for optimizing parameters in an efficient way.
Um, and then we'll also actually reach up a little bit to cover some GEN.AI.
In particular, we'll talk about what is a transformer network.
And then through this quarter,
Jen and I will also chat a little bit about
the job landscape as it relates to GEN.AI and deep learning,
and how to use- how deep learning is enabling certain types of GEN.AI applications.
Okay. Um, I have more to say about this,
but let me just pause for a second and see if you have any questions.
Yeah, go for it. Oh, good question.
Well, I say pre-wrecked, but, um,
congratulations, you've won the prize for
the first question asked in CS2302035.
So well done. So is machine learning a pre-wrecked to this course?
Not really. So I think two common entry points to AI at Stanford are,
um, CS- well, a few common entry points are CS129,
CS229, and CS230.
Um, if you don't know any machine learning,
this course may end up going a little bit fast,
may seem like it's going a little bit fast in the first,
uh, I don't know, two or three weeks,
but some people do pick things up quickly that way.
Uh, and, um, maybe,
actually, I should just read.
So a few causes that you may hear about.
Um, so 129 is a relatively easy entry point into machine learning
that tends to- it takes a longer time to
go through the core concepts of machine learning, right?
What's the optimization objective?
How do you implement gradient descent?
What is, um, logistic regression?
What's a very basic neural network?
So this is a relatively applied easiest of the- of- of this list.
Um, CS229, which I'm also involved in co-teaching,
is, uh, much more mathematical and theoretical,
very high-paced, very intense,
and very mathematical.
And this is less applied than 129 and 230,
but this will go over, um,
a lot more of the theory and the math derivations
behind machine learning algorithms.
So for example, if you want to learn how to do,
um, calculus, not using real numbers,
but calculus using matrices and vectors, you know,
that's a bunch of sort of, I don't know,
mildly complex math that's worth knowing.
Um, CS239 goes over that.
CS230, this class is relatively
applied and it focuses just on deep learning.
So of all the machine learning,
there are a lot of machine learning algorithms out there, right?
Supervised learning, unsupervised learning,
a lot of machine learning algorithms out there.
And many, many of them are very useful,
but- and so they're all worth learning about.
But of all the machine learning algorithms out there,
the one category that is most useful
is, you know, that's taken off the most is deep learning,
and this class focuses just on that.
But the other one is also worth learning about.
So 129 is the easiest on-ramp.
Um, but if you've done either 229 or 230,
I would probably skip 129 at that point.
But if you are getting started,
there- there are multiple on-ramps. Yeah.
Can you take 229 and 230 together?
Oh, uh, yeah. Can you take 229 and 230 together?
Yeah. Thank you. Price for the second question.
All right. If you'd like to clap,
sure, go for it. Um, yes,
you can take CS230 and CS229 together.
Um, we designed the two curricula to be relatively low in overlap.
So the very small amount of- of all the opportunities to- all right.
All right. We- we won't clap for every single question,
but yeah, go ahead.
Yeah. So will we cover the recent,
um, LM developments?
We will touch on the transformer neural network,
but, um, uh, not the,
uh, latest LM variations in this course.
Um, I think a lot of the- it turns out that when you go to get a job,
well, maybe, right, assuming you're going to work in the industry,
the number of people training LM's is actually very small, right?
Some of those jobs tend to be incredibly well-paid,
so we hear about kind of very high salaries in the news media.
But the vast majority of application builders end up,
um, sometimes work in the gen-EI level,
not that often training a transformer from scratch,
um, but then often using deep learning tools as well.
So maybe one example,
um, something that many of my teams have done is,
um, we have trained transformer model-
foundation models from scratch with relatively small ones in,
in, say, startups.
But one thing we do do quite a lot is,
um, take a pre-trained transformer network,
and then engineer our own data to further fine-tune it, right?
Sorry, if I'm using words that you may not totally understand,
you're a pre-trained fine-tuned,
you know what all those terms are by the end of this quarter.
So those are things that we actually do,
um, uh, kind of day-to-day.
This is important for getting a bunch of problems to work,
so you will gain the foundations needed to do type of work in this course.
Um, the one thing, one thing we don't do is talk a lot about how to train
the largest cutting edge transformer networks.
I think that is a very important skill set,
is a relatively niche one for which some people are,
you know, getting paid really, really well.
But the number of people doing that in the world is actually small,
whereas the number of people building applications with,
you know, this set of skills is,
is, is very large.
Uh, do I know any causes covering that?
I think Percy Liang was thinking about doing something,
but I don't remember what he's doing at this quarter.
Um, few people are thinking,
thinking about doing something like that.
Yeah. Good. So, um,
so I'm just repeating for the, for the, um,
mic for the, uh, uh, home viewers.
What portion is, uh, coding versus what proportion is, um, mathematical analysis?
This course is relatively math-lite.
Um, sorry, maybe that was too strong a statement,
but I think this, this course is very practical.
Um, I, I, I remember many years back,
I was speaking with a mathematician,
um, and, you know,
we were just chatting and he was asking,
he was just talking about his career,
why he chose to be a mathematician.
And I, I still remember, you know,
this, this, he had, he had like stars in his eyes,
when he told me that he chose his career path because he felt
his role is to pursue truth and beauty in the universe,
and that's why he became a mathematician.
In this course, I'm not going to do any truth and beauty stuff, right?
So, um, truth and beauty is good,
but you find that I, I want to take a very practical approach to,
um, talking about how to build applications and build software that works.
Anything else? Awesome.
All right. Thank you for all the questions.
Please keep them coming.
Feel free to interact with me or Kian throughout
this quarter as well with questions. I love it.
Um, so, just to,
just to flesh this out a little bit more.
This is what I see in terms of,
um, teams building practical applications.
And I was talking about applications because with
improving machine learning algorithms, deep learning algorithms,
GenEI algorithms, there are a lot of applications that you can build now
that just were, you know,
impossible or like really inaccessible,
you know, to, to any person to build even a few years ago.
Um, and so I find that when I prompt GenEI,
it works really well for a lot of text-based applications.
Um, and there's work on multi-modal LLMs,
large multi-modal models,
so making inroads into vision,
making inroads into audio,
but really GenEI algorithms,
especially transformer networks,
trained to output text, you know,
like ChaiGPD, Claude, Gemini, and so on.
Really fantastic for text-based applications, right?
Um, and I find myself,
um, regularly working with deep learning algorithms directly when I am working with,
um, audio data, image, and video data,
um, and then also, um,
a lot of structured data.
Sorry, my handwriting is awful, right?
So structured data refers to large tables of numbers, right?
Like giant, you know, Excel,
Google Sheets, spreadsheets,
so that's, that's structured data.
Unstructured data refers to text, audio, images, maybe video.
Um, and because a lot of GenEI, right,
large language models like ChaiGPD had grown up being text-in,
text-out kinds of, um, uh, machines,
they are remarkable for a lot of text processing applications.
But for all the types of data,
I end up often, you know,
dipping down directly to use various deep learning algorithms.
Um, and then it turns out that for text-based data,
if all you do is prompting,
you could usually go quite far.
So a lot of applications are built by prompting OMS.
But, um, uh, but I've been on, you know,
quite a few teams where after fiddling with the prompts for a month,
you just can't get the performance to be better just by tuning the prompts.
Um, or another good problem to have,
it turns out use of GenEI tools are relatively inexpensive when you're prototyping, right?
So, you know, a few dollars per million tokens,
you can do a lot.
Um, but sometimes,
if you're lucky enough to be on a product that, um, uh,
hits product market fit and a lot of users want to use, you know,
multiple times I've been on teams where we basically did not care about our,
um, uh, large language model bill, right?
It was like whatever, you know,
$20 a month or $100 a month was fine.
But when more and more users start using it,
then to your team's kind of positive surprise,
your AI bill really starts to skyrocket.
And then at some point,
you look at how much you're paying for your AI bill,
for the large language models,
and, um, to bend the cost curve back down,
often a lot of the techniques in deep learning become very relevant as well.
So there are, I don't know,
I'm thinking just some of our bills were really breathtaking.
I don't want to say the numbers,
but just kind of definitely more than we want to pay, you know,
as much as we love the companies providing OMS,
our bills that we're paying them were significantly larger than I wanted to pay.
Um, and then knowing how to use deep learning
to fine-tune smaller models,
that was really the critical skill set that just bend the cost curve back
and just made the whole thing affordable to keep on providing a service, right?
So, um, yeah, right.
So that's what- so that's the skill sets I hope you get from this course.
Let's see. All right.
Um, and, um, to give a-
well, actually, sorry, let me use this one.
So to give a fi- to give a quick, um, overview,
this course, the online materials is broken down into five modules.
So just to give you a overview of the five of them.
Uh, first one is on the basics of neural networks,
sorry, NN neural networks and, uh,
DL deep learning, right?
So you learn how to build a neural network or deep learning algorithm from scratch in Python.
Um, I find that sometimes if we use the frameworks like TensorFlow or PyTorch,
it hides a lot of the details.
So we actually work through, um,
how to build a basic neural network and how to build a basic deep learning algorithm
just in raw Python so you really understand it.
Um, and then the second module,
the second mini course will be on,
um, how to improve,
how to tune your neural networks.
So we have heard that when you're training a neural network,
there are a lot of parameters or we call them hyperparameters.
Hyperparameters are parameters that control the parameters, right?
So the weights of parameters,
hyperparameters are things like the learning rates or what's the size of your neural network.
And so there are actually a lot of hyperparameters that we end up tuning.
And, um, try to give you a sense of what are
the most important ones and practical skills for tuning them.
It turns out that, um,
if I look at, you know,
like my PhD students,
I think every one of them that, right?
Well, I think, I think that probably every one of them,
definitely everyone that, every PhD student I know that became great, I think,
um, at some point wound up up at 2 a.m. tuning hyperparameters, right?
Um, and I still have very clear recollections of like being in the office,
you know, 2 a.m., 3 a.m.,
filling the parameters, trying to get it to work.
And it turns out that literally your skill at tuning hyperparameters,
it really makes a difference.
So there were some evenings that I knew my skill at tuning hyperparameters,
you know, frankly, it made the difference between whether I went home to sleep at 3 a.m.
versus where I went home to sleep at 7 a.m.
Maybe there's not, maybe don't do what I do.
I'm not encouraging this type of behavior, uh,
but, but this is just my personal experiences.
But it really makes a big difference,
your practical skill at how quickly you can figure out
the recipe to get these neural networks to train.
Um, uh, and, um, and related to that is,
um, one thing we've talked a lot about in this course
is strategies for building machine learning projects.
So it turns out that if you build a complex system, you know,
let's say you build, there's one example we'll go through later this quarter.
Say you want to build a system that,
um, recognizes your face,
a camera that recognizes your face,
your friend's face, unlock a door, right?
Security, safety, whatever.
So it's something like that.
You know, I've, I've worked on something like that.
Jan's worked on something like that.
These are complex systems with multiple components.
Um, there's a camera,
there's, you know, do you subtract, clean up the image?
Do you cut out the face?
How do you register the face?
How do you compare a face?
How do you decide to take another picture before you unlock the door or just,
you know, or someone trying to fake,
uh, hold up a picture,
print on a piece of paper?
There are actually a lot of decisions.
And so what I find is that, um,
the biggest difference between a team that knows how to drive forward a project like this well,
and get it done in days rather than weeks,
or weeks rather than many months,
is the ability to drive a disciplined development process.
It turns out when you have a complex system,
less experienced teams will often almost pick things at random to work on, right?
They'll read one research paper and say,
oh, I read in the research paper we should get more data.
Yeah, well, because like some newspaper said AI needs lots of data.
So let's go spend six months to collect more data.
Turns out a lot of the time collecting more data does not help your application.
Um, but sometimes it's a huge help.
So given your application,
how do you decide?
Should you spend more time collecting data?
Maybe you should buy more GPUs.
I should definitely know people that read in the news,
a lot of GPUs are helpful, right?
And then I've literally met,
you know, fairly senior business leaders that have, um,
spent a very large amounts of money buying GPUs.
And then, you know, um, some funny stories.
And then I go talk to them and say,
what are you doing with these GPUs?
And then sometimes, you know,
there was one meeting I was in where literally a very large family run
business had bought a lot of GPUs.
And the CTO, um,
then pointed to his nephew, uh, uh, who, who, who, who is a,
who is a current college student undergrad and said,
oh, my nephew knows AI.
I'm giving him this very large budget in GPUs.
And I think he'll do AI for me.
Right. And so, but so I think that, uh, uh,
knowing how to make these decisions and not just buying to the height
that you read about in the newspapers is really important.
Um, and one thing I hope to do in this course is share with you
what driving a disciplined development process looks like,
because this is one of the things that really makes a 10x difference
in the speed with which you can get something to work.
I've literally seen teams, you know,
like take six months or 10 months pursuing an approach
that experienced engineers would go in and go, you know what?
I could have told you six months ago
that spending all this time collecting data,
this was not going to get your application to where you wanted to go.
Right. Um, but so how do you examine an application?
And figure out the diagnostics and figure out
what are the productive things to do for your application?
We actually spend a lot of time on that.
And in fact, um, I'm excited about doing some simulation exercises
in this classroom with you later this quarter,
where, um, I'll invite you later this quarter,
you know, to, to, to say in this, in this scenario,
what would you do and, and see if you could,
you know, make decisions in a more systematic way.
All right. Um, then course four,
we'll talk about convolutional networks.
Um, very useful for computer vision applications.
Um, and then so confidence are specialized models,
most used mostly for vision applications,
dealing with images.
And then we'll talk finally about sequence models.
So sequences could be time series or sequences of
text, uh, like words.
So I'll start touching the transformer network,
uh, that, you know, that power a lot of the gen.ai revolution.
Okay. Um, and so throughout learning,
through learning all of these things,
I hope that you all gain a large tool chest,
um, that will enable you to tackle
an almost bewildering range of applications.
I think one of the things I've most enjoyed as an AI person is,
it turns out when you work in AI,
there's so many other teams that, um,
have data and that could use our hope, right?
So I feel that as an AI person, you know,
I somehow bizarrely had the right to play in,
you know, building autonomous helicopters or hoping companies,
I don't know, place more relevant ads.
Maybe not the most inspiring thing I've worked on,
but certainly very lucrative for some companies, right?
Or improve web search rankings, um, or improve safety, uh, you know,
get rid of the kind of negative toxic results
that you may not want search results to come back on,
or improve e-commerce retailing,
or improve speech recognition, um,
or help ships be more fuel-efficient, right?
There's re- all these are real examples, um,
or fight fraud,
which is actually really exciting when you're fighting financial fraud,
um, which is obviously a bad thing,
but, uh, uh, when you- sometimes you- when you're fighting fraud,
sometimes you wake up in the morning and your team's alerted you that there's a new scam,
and then you just have to go and fight them
and build algorithms in real time,
and you know that every hour you take,
you know, more- more money actually leads to the financial system.
So it's kind of awful that there's financial fraud,
but it's actually one of the most exhilarating things I've worked on,
because literally every hour you are slower to- to,
you know, formulate a response,
you know more dollars are leaking up every hour,
so, um, anyway.
So- so somehow when you have this two sets of deep learning,
um, you just have a bewildering right to play or ability to play
in a huge range of applications,
uh, that could use your help, right?
And I think on campus too,
there's so many departments,
um, uh, across campus,
um, in the sciences, engineering, humanities, business,
uh, that have interesting data where your skill set will let you,
if you choose, collaborate with them to do interesting projects.
And- and I find for example,
bizarrely, uh, some of my PhD students are working on climate science.
It's like, what do I know about climate science, right?
I wish I knew more,
but using machine learning tools, you know,
we can actually work on climate modeling and- and geoengineering,
and- and just play in all of these important,
um, uh, important, hopefully important and interesting places.
I hope that you have that skill set as well by the end of this quarter.
Yeah. Yeah, so how do you know if you know- how do you know
if you have enough data for a neural network?
Um, it turns out to be really difficult to know.
Uh, so if it's a application that others have worked on,
or that you've worked on before, then you may have a sense.
So for example, I don't know, I- because I worked on face recognition,
you kind of have a sense.
You want to train a face recognition system from scratch,
having like 50,000 images, 50,000 unique faces is pretty good, right?
Or- or- so if you've worked on it,
or if you read the research literature,
for something people have worked on,
that would give you a gut sense for how much data,
um, could be enough to get you started.
Uh, but then for, um, green field brand new projects
that no one in the world has worked on before,
um, if you can't find parallel projects that are kind of comparable,
it could be really hard to tell.
And so common advice for completely, um, green field-
sorry, green field, I mean a brand new project,
just similar than things- so for example,
if someone has invented a new medical device,
and no one has collected this type of,
you know, blood specimen data before,
it's really hard to tell.
And in that case, the most common advice is,
um, get a little bit of data and just try training a model.
And the degree to which your initial model works or does not work,
that will help you hone your perspective on how much data may be needed.
And you may be surprised,
maybe 100 data points is all you need, right?
Sometimes you've been surprised by that.
And then sometimes we've also worked on applications where,
you know, 100 billion data points later,
we're still trying to get a lot more data.
Um, and I- I find it really difficult to tell.
Yeah, good question.
Anything else?
Oh, so this is a good time for me to pause and take questions because,
uh, oh, so what- what I'm going to do is,
um, uh, right, what I'm going to do after this is,
um, switch tracks and talk a little bit about exciting trends in AI,
um, uh, kind of recent trends in AI that I'm excited about and how I view the AI landscape.
But so this is actually a good breakpoint to see if people have
other questions before I talk about some trends in AI.
Anything else?
Yeah, please.
So I guess, um, let's see.
All of these- many of these terms are blurry and kind of fuzz a little bit into each other.
But, um, when I refer to generative AI, um, generative AI is this,
uh, body of work that, um, generates text and sometimes also images,
sometimes also audio, um, using deep learning algorithms in certain ways.
So I think generative AI refers to this body of work, um,
with most of the center of gravity on generating text, you know, maybe also images.
And the text generation algorithms have been mostly implemented using
transformer neural networks, uh, train on large amounts of data,
you know, straight off the internet and elsewhere.
So- so when I refer to generative AI, that's- I guess, uh,
that's one particular application of deep learning models that has
given us large language models like Chai GP and Claude and Gemini and, uh,
MetaLamar and so on.
That make sense?
Yeah, cool.
Anything else?
Cool.
All right.
So let me- could- could we go to the slides, please?
One of the nice things about this clause is Ken and I can occasionally, uh, just
share a view of things we're seeing in the broader world.
Hey, while- while- while we're doing that, I'm actually curious,
how many of you use a, um, specialized AI-assisted coding tool,
like Cloud Code, Cursor, GeminiCI, Codex, CourtWindsor?
Awesome.
Almost everyone, but not everyone.
Interesting.
Oh, interesting.
Oh, I thought- interesting.
Okay, cool.
So, you know, one of the most exciting things that's happened in
programming is AI-assisted coding.
And I feel like, um, I personally hope I never,
ever have to go back to coding by hand, right?
Like, it's just, um, it's- it's actually interesting, uh,
I often work in coffee shops on the weekend,
and a few weekends ago, I was sitting in a coffee shop,
and sitting next to me was someone that was, you know, coding by hand,
and looked so strange.
I just asked them, what are you doing?
In a- in a respectful way, you know.
Uh, and it turns out that- that they're- they're doing homework from
some other university that required me to code by hand.
Um, but one of the things I find exciting is that, um, uh,
individual programmer productivity is much higher than it ever used to be, right?
And maybe I want to share with you just- just one- one- one thing,
what- what I see.
So I find that in the software work that I do,
I- I maybe categorize it into two buckets.
One is building quick and dirty prototypes to see if something works,
and then sometimes I, you know, write production-grade, enterprise-grade,
robust, reliable software that has a scale, right?
Um, and I find that where AI-assisted coding has made the biggest difference
is building the quick and dirty prototypes.
Um, whereas I think actually literally one of my collaborators, um,
used one of the agentic coders, did I name, but I won't say which one,
but literally this morning, he sent me a Slack message saying,
sorry, you know, this agentic coder had a database migration error,
and we just wiped out all of the database records.
Uh, for- fortunately for a test application with like five users,
uh, but- but it did happen.
So I find that- oh, okay, thank you.
So I find that, um, my use of the agentic coders,
you know, for the production-grade software is more careful,
whereas for building quick and dirty prototypes, it kind of, um,
so unless you're not shipping software in a respo- in an irresponsible way,
um, quick and dirty prototypes have a lot fewer dependencies.
You usually don't need to integrate legacy data infrastructure,
and then, you know, I'm- I'm gonna say something that I-
that- that feels like something I'm not supposed to say,
but I'll- but I'll say it anyway, which is, um, uh, I find that, um,
when I am running code, I- I find that people often worry about,
um, safety and reliability of software or security of software.
So one thing I often say to my teams is, um,
if you are building a prototype that only runs on your own laptop
and doesn't use any sensitive information,
so there's no risk of sensitive information,
then unless you are planning to, you know, maliciously hack into your own laptop,
right, the security requirements can be lower.
And so I find that, um, when building quick and dirty prototypes,
um, having a sandbox environment that lets you operate within it quickly
means that you can just make a lot of decisions faster
without worrying as much about scalability or security or reliability.
So unless the sandbox environment means this stuff isn't gonna get out there
or leak information or create a security loophole.
So that- that's part of what lets us move much faster.
And so I find that, um, because of the speed of prototyping,
so unless you can do so in a responsible way, um, to pursue innovative ideas,
my teams will increasingly, you know, try 20 things and see what sticks.
And, um, because I- and I know that a lot of teams are lamenting
that many proof of concepts never make it into production, right?
You try something and it doesn't work.
And I know some teams are feeling angst about that.
I actually have a different view.
I think if the cost of a proof of concept is low enough,
then who cares if you have to do 20 of them?
And that's the price for finding the one or two things that works really well.
So one thing you hear about in this course is
both when- when you're building a machine learning application,
you usually don't know what's gonna happen.
And there's a specific reason for that.
The reason is the output of the machine learning algorithm,
it depends both on the code you write as well as on the data you're training on.
And while you control the code 100%,
you don't really know usually what's really in the data,
in the weird and wonderful data that the world has given you.
So, for example, I worked on speech recognition a lot
to multiple companies in multiple contexts.
And even now when I work on speech recognition,
I'm still, you know, sometimes a little bit surprised that,
oh, this data has people of a certain accent more than I realized,
or people somehow speak faster,
or boy, there's a lot of background noise when people use it in a car, right?
So even though I worked on speech recognition multiple times,
oh, and actually one recent example of application,
I was actually surprised by the number of background speakers.
They talk to us, they come and talk to a different person,
then they talk to us, and then we get confused, right?
So I find that the data that the world gives us is often weird and wonderful.
And so it is only by building a system
that you then start to discover these things in the data
that lets you make progress.
And with a lot of software applications as well,
separate from machine learning applications,
a lot of what I end up having to discover is
what do users actually want, right?
So again, I control my code 100%.
I can write whatever code I want, I control that.
But you don't get to control how your users react to your system.
And I find that our ability to build quick and dirty prototypes rapidly,
both to discover what's in the data,
and also to take other users to see if they like it,
that allows us to drive faster feedback loops
than was ever possible before
to then help us build more and more valuable software, right?
And I think, you know, I know that the mantra,
move fast and break things, right?
Got a bad rep because it broke things.
And I find that some teams took away from this
that we should not move fast, but I think that's a mistake.
So what I usually tell my teams is move fast and be responsible.
And despite all the hype about, you know,
AI extinction risk, AI kill us all,
all that somewhat bizarre hype, in my opinion,
I find that when teams move really fast,
we can then implement things, test it out in a responsible way,
and much more quickly identify problems and fix them.
So I find that a lot of the most responsible teams I know,
teams able to really get stuff to work really quickly,
they tend to be some of the fastest moving teams.
So this is that speed of execution
that lets you finally implement it, figure out what's in your data,
figure out what uses one,
and that's the best way to figure out what could actually go wrong
to then make sure things don't actually go wrong, right?
And somewhat related to that is AI coding assistance.
And I assume, you know, almost everyone,
or everyone in this class knows how to code.
If you are, we haven't learned to code yet,
you probably might not want to take this class yet.
But I find that there have been people,
including very senior, right, business leaders,
advising others to not learn to code,
and the grounds that AI will automate it.
And I want to share this with you,
not because I think you need to learn to code,
but because I hope you help me spread the word, right?
Go to all of your friends in other departments
to tell them this advice is not learned to code.
I think we'll look back on this
as some of the worst career advice ever given.
And the reason is when coding becomes easier,
more people should do it rather than fewer.
So when humanity went from punch cards to keyboard and terminal,
that made coding easier,
and so more people learned to code.
When we went from assembly language to modern,
well, at that time, modern programming languages,
that made coding easier.
More people learned to code.
I went back and actually found these papers
on these articles on when COBOL,
very old school programming language, right, was invented.
And there were actually people that said,
oh, wow, now we have the COBOL programming language.
Coding is so easy.
Who needs programmers anymore, right?
And obviously, the opposite happened.
We went from text editors to IDEs,
and then, you know, AI assisted coding.
As coding becomes easier, people should code a lot more.
A lot more people should learn to code.
And the other thing I'm seeing is,
I just add something that's been on people's minds.
I know that unemployment of recent computer science drags
has ticked up to higher than it's been, you know,
compared to, I think, the last decade.
And so I know that to people learning CS,
that has caused some consternation.
So I'm going to share my view on that.
So it turns out that what I see in Silicon Valley
and beyond Silicon Valley is we just can't find
enough people with these skills, right?
I know many businesses that would,
well, I know large businesses that love to hire
a thousand people with skills in gen AI
and deep learning and machine learning,
but that are struggling to find people with these skills.
Conversely, there are still, you know, universities
with curricula that has not changed since,
has not changed much, right, for the last, like, I don't know,
since 2002, before the rise of gen AI.
And so I do see that many new CS drags,
not from Stanford, but from, you know, around the country,
are struggling with finding jobs because, unfortunately,
that older non-AI-enabled skill set that is, you know,
not as much in demand, right?
And maybe just for myself, today I will not hire someone,
I will not hire a software engineer that doesn't know
how to use AI to help them copy.
It just doesn't make sense.
Same reason why I just won't hire someone
that uses a punch card to the keyboard and terminal, right?
And I think when the world evolved from punch card
to keyboard and terminal,
people still had punch card jobs for a while,
but eventually the punch card jobs just went away.
It just doesn't make sense anymore.
So today, there are still coding by hand jobs around.
Maybe some specialties, some very low-level coding
where AI is not very good.
So AI is not very good at some types of GPU programming.
There are some niches with coding by hand,
actually still make sense.
But for building applications, you know,
so I remember, it was just a few months ago now,
maybe months ago now, where I interviewed two engineers
back-to-back.
One had not yet graduated from college,
but was highly on top of Gen.EI coding.
So, you know, spoke with that candidate,
knew how to use AI, built privilege,
get someone quickly.
Right after that, I also interviewed someone
with 10 years of experience as a full-stack engineer,
but whose skill set was exactly the same
as their 2002 skill set.
Had not tried out any AI assistant coding,
really good full-stack engineer
with 10 years of experience.
And it was actually really clear to me,
I picked the fresh college grad,
well, she was about to graduate,
over someone with 10 years of experience, right?
So I think making sure you master these skills
are really important.
And what I'm seeing is there is a very large gap
that businesses are having a hard time filling
for people with these skills.
But the demand for the 2022 skill set,
software engineering, full-stack engineering skill set,
that is not there, right?
So I think, and then in terms of AI assistant coding,
I find that CS fundamentals really are important.
So in addition, so I know I applied someone
a fresh college grad over someone with 10 years of experience,
that true story.
There's actually one other part to this story,
which is with respect to all of you
about the graduate from college,
the best programs that I know
are also not fresh college grad,
no disrespect intended to fresh college grads,
some about the graduate from Stanford.
The best programs I know
are really on top of AI assistant coding
and additionally,
deeply understand computer science fundamentals, right?
So it turns out,
maybe I'll illustrate this with a quick story.
When a student online calls,
my team wanted to generate background pictures like this,
just for decoration.
So when I was working on this,
this is of course Generative AI for Everyone,
I was working for collaborator Tommy Nelson
that understood art history.
And so my collaborator knew the language of art.
He knew the artistic genre inspiration, the palette,
so he could prompt mid-journey AI image generation
with the language of art.
And so he could generate beautiful pictures like these.
In contrast, I don't know art history,
I wish I did.
And so all I could do was go to mid-journey
or AI image generation and type,
please make pretty pictures of robots for me.
And I could never get the control
that my collaborator Tommy could
to generate pictures like these,
which is why we use all of his pictures
and none of mine.
And I'm seeing the same thing in computer science.
One of the most important skills for the future
is to understand how computers work
and understand how Gene AI
and deep learning and machine learning work
so that you can use the language of AI,
use the language of these tools
to tell a computer exactly what you want
so the computer can do it for you.
And there is actually a huge difference in performance
between someone that's learned to just prompt an LLM
without understanding how computers
or how AI really works versus people
that can look at the problem, analyze it,
and then with AI-sensitive coding,
tell a computer how to take the next steps,
which is why I think that
CS fundamentals is very valuable.
CS fundamentals, machine learning fundamentals,
deep learning fundamentals,
I and my teams, we use that knowledge
every day in making pretty consequential decisions.
So I hope that you get that from this class
and the many other classes at Stanford as well.
All right.
I think I might leave the rest.
There's more I could say on trends in AI,
but I find that AI-sensitive.
Oh, but one thing I hope you do,
go to all your friends in all the departments
across campus and encourage them to be a builder.
The other thing I'm seeing is
clearly for computer science professionals,
use AI-sensitive coding, no CS fundamentals,
build cool stuff.
But for other disciplines as well
that is not computer science or not AI,
I'm finding that the education professional
or the climate scientist or the mechanical engineer,
the ones that know how to build software
are just more productive and get a lot more done.
And the barrier to entry to AI,
to coding is the lowest it's ever been in our lives.
And so this is a good time, frankly,
for I wish every single Stanford student
that will learn to build software with AI assistance.
So I hope you go help your friends across campus
to master those skills as well.
Okay.
Oh, yeah.
Any other questions?
Go ahead.
Just because they have more.
So let me rank productivity, right?
And I'll give you four levels.
I think, and again,
and I say this with a lot of respect for individuals,
so if I talk about productivity,
it's not with any disrespect or any lack of affection
for anyone or for their work, right?
But I think, you know, least productive
are people with no experience and don't know AI, right?
One step on top of that is people with less experience,
but on, sorry, one step on top of that
is people with say a decade of experience,
but that don't know AI.
On top of that,
I would rather take a fresh college grad that does know AI,
but then even more productive is someone with,
you know, a decade of experience
and also really on top of AI.
So I think between the two factors,
really understanding AI is very important,
but experience is also important.
And so the best developers I know,
we just work and we just ship code
like no one's ever done, I think,
even two, three years ago,
are very experienced developers.
They're also very on top of how they use
the latest AI technologies.
Oh, sorry, and just one other thing about the job market.
I find that a lot of employers
have not yet figured out how to hire appropriately.
This is contributing.
Frankly, a lot of employers,
you know, if a company has no one that knows gen. AI,
how do they even know how to interview appropriately?
So that is a problem that we need to solve as well.
Yeah, boy.
So CS 117, CS 111 are great.
So do take them if you're considering them.
I find that the fundamentals are important.
How do I put it?
Yeah, I'm not sure what else to say other than that.
I think honestly Stanford were known for,
CS department were known for really,
I know I'm biased, but I want to say
that probably the best entry-level CS program classes
of any university in the world,
I'm pretty biased, so I shouldn't say that.
But I think they're excellent courses
if you want to learn the fundamentals
in a really solid way.
And I know the instructors are routinely thinking
about how to update the curriculum
and realities of gen. AI.
So I think they do an excellent job with that mix.
Yeah, how do I define someone that really knows gen. AI
compared to someone that just uses
two different types of problems?
So I feel like in gen. AI,
there are two buckets of skill.
And again, by the way, deep learning is not gen. AI.
Deep learning is also a very valuable skill.
But since you asked about gen. AI,
I think there are two things.
One is I find it really useful
to know how to use AI coding assistance
that's really valuable.
But having fundamental knowledge helps you do that.
And then the other thing is in gen. AI,
there's a number of emerging tools.
I'm going to toss up some buzzwords, okay?
So if you don't know what any of these words mean,
don't worry about it.
But I think there are emerging tools like RAG,
ritual augmented generation, or vector databases,
how to do evals and error analysis,
how to build guardrails,
how to use knowledge draws,
interface that with your OOM,
maybe how to do multimodal OOMs,
how to fine-tune the model.
What else?
I'm probably blanking on something.
How to build agentic workflows.
But I feel like there are these categories
of new techniques built on top of gen. AI
that are like a useful bag of tools
for building applications.
Well, frankly, when I'm interviewing candidates,
we still do a fair amount of.
It is for a gen. AI role.
It's these skills I tend to look for.
This set of tools as well as AI-assisted coding.
And then, yeah.
Yeah, please.
I don't know if this question is best
if I'm considering taking 20 minutes.
Yeah, so let me just give one tip
about CS causes in general,
not just 239 and CS 230,
which is I encourage you to think of
AI causes at Stanford that have been like Pokemon.
You've got to catch them all.
But in all seriousness,
I think taking more CS causes in AI,
it is a good thing to do.
Definitely encourage you to take multiple causes.
I think in some years,
we've had students do joint projects
where the standard is higher,
higher expectations for sure.
But that's one option to look at.
All right, go for it.
Oh, so let's see.
239 and 230 are very different causes.
239, well, in 239,
we have live instructors
doing the lectures in person
rather than online content.
So it's not the flip classroom.
So in CS 230,
we have most of materials prepared
kind of in online videos,
highly edited online videos.
And then, I think the other biggest difference is
CS 239 is more mathematical, theoretical,
but it's important math, right?
Whereas CS 230 is more practical.
And so I don't know if we do even want a single,
maybe we do like one proof somewhere in the lectures,
but we just don't do a lot of math in CS 230.
And it's very,
a lot of machine learning is very empirical.
You try and see what works,
but have a disciplined approach
for exploring what works.
So we focus a lot more on that in CS 230.
And oh, and 239 covers a lot more techniques, right?
So there are a lot of machine learning techniques,
supervised learning, supervised learning,
you know, decision trees boosting,
k-means clustering.
So CS 229 covers a much broader survey
of a lot of machine learning techniques,
whereas CS 230 is just one thing.
Well, we go really deep into deep learning.
